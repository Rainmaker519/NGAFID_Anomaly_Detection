{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10ec2dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pyro.nn import AutoRegressiveNN\n",
    "from pyro import distributions\n",
    "import pyro\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.distributions.transforms import householder\n",
    "%matplotlib inline\n",
    "\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal as mvn\n",
    "import seaborn as sns\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "class NormalizingFlow(nn.Module):\n",
    "    def __init__(self,dim,\n",
    "                      n_flows,\n",
    "                     base_dist=lambda dim:distributions.Normal(torch.zeros(dim), torch.ones(dim)),\n",
    "                     flow_type=lambda kwargs:distributions.transforms.RadialFlow(**kwargs),\n",
    "                     args={'flow_args':{'dim':2}}):\n",
    "        super(NormalizingFlow, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.n_flows = n_flows\n",
    "        self.base_dist = base_dist(dim)\n",
    "        self.uuid = np.random.randint(low=0,high=10000,size=1)[0]\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        If the flow needs an autoregressive net, build it for every flow\n",
    "        \"\"\"\n",
    "        if 'arn_hidden' in args:\n",
    "            self.arns = nn.ModuleList([AutoRegressiveNN(dim,\n",
    "                                                        args['arn_hidden'],\n",
    "                                                        param_dims=[self.dim]*args['n_params']) for _ in range(n_flows)])\n",
    "    \n",
    "        \"\"\"\n",
    "        Initialize all flows\n",
    "        \"\"\"\n",
    "        self.nfs = []\n",
    "        for f in range(n_flows):\n",
    "            if 'autoregressive_nn' in args['flow_args']:\n",
    "                args['flow_args']['autoregressive_nn'] = self.arns[f]\n",
    "            nf = flow_type(args['flow_args'])\n",
    "            self.nfs.append(nf)\n",
    "\n",
    "        \"\"\"\n",
    "        This step assumes that nfs={f_i}_{i=1}^N and that base_dist=N(0,I)\n",
    "        Then, register the (biejctive) transformation Z=nfs(eps), eps~base_dist\n",
    "        \"\"\"\n",
    "        self.nf_dist = distributions.TransformedDistribution(self.base_dist, self.nfs)\n",
    "        \n",
    "        self._register()\n",
    "        \n",
    "    def _register(self):\n",
    "        \"\"\"\n",
    "        Register all N flows with Pyro\n",
    "        \"\"\"\n",
    "        for f in range(self.n_flows):\n",
    "            nf_module = pyro.module(\"%d_nf_%d\" %(self.uuid,f), self.nfs[f])\n",
    "\n",
    "    def target(self,x,p_z):\n",
    "        \"\"\"\n",
    "        p(x,z), but x is not required if there is a true density function (p_z in this case)\n",
    "        \n",
    "        1. Sample Z ~ p_z\n",
    "        2. Score it's likelihood against p_z\n",
    "        \"\"\"\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            p = p_z()\n",
    "            z = pyro.sample(\"latent\",p)\n",
    "            pyro.sample(\"obs\", p, obs=x.reshape(-1, self.dim))\n",
    "        \n",
    "    def model(self,x,p_z):\n",
    "        \"\"\"\n",
    "        q(z|x), once again x is not required\n",
    "        \n",
    "        1. Sample Z ~ nfs(eps), eps ~ N(0,I)\n",
    "        \n",
    "        This is the NN being trained\n",
    "        \"\"\"\n",
    "        self._register()\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            pyro.sample(\"latent\", self.nf_dist)\n",
    "\n",
    "    def sample(self,n):\n",
    "        \"\"\"\n",
    "        Sample a batch of (n,dim)\n",
    "        \n",
    "        Bug: in IAF and IAFStable, the dimensions throw an error (todo)\n",
    "        \"\"\"\n",
    "        return self.nf_dist.sample(torch.Size([n]))\n",
    "    \n",
    "    def log_prob(self,z):\n",
    "        \"\"\"\n",
    "        Returns log q(z|x) for z (assuming no x is required)\n",
    "        \"\"\"\n",
    "        return self.nf_dist.log_prob(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e1ac33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sylvester\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_40412/1984288545.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Flow not found'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m nf_obj = NormalizingFlow(dim=dim,\n\u001b[0m\u001b[0;32m     40\u001b[0m                       \u001b[0mn_flows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_flows\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m                      \u001b[0mbase_dist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_dist\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'dim'"
     ]
    }
   ],
   "source": [
    "#print(distributions.transforms)\n",
    "#flow = distributions.transforms.SylvesterFlow\n",
    "flow = distributions.transforms.Sylvester\n",
    "base_dist = lambda dim:distributions.Normal(torch.zeros(dim), torch.ones(dim))\n",
    "dim = 2\n",
    "n_flows = 3\n",
    "\n",
    "print(flow.__name__)\n",
    "\n",
    "if 'InverseAutoregressiveFlow' in flow.__name__:\n",
    "    args = {'arn_hidden':[64],\n",
    "            'n_params': 2,\n",
    "            'flow_args':{'autoregressive_nn':None}\n",
    "            }\n",
    "elif flow.__name__ == 'NeuralAutoregressive':\n",
    "    args = {'arn_hidden':[64],\n",
    "                 'n_params': 3,\n",
    "                 'flow_args':{'hidden_units':64,'autoregressive_nn':None}\n",
    "           }\n",
    "elif flow.__name__ == 'PolynomialFlow':\n",
    "    args = {'arn_hidden':[64],\n",
    "                 'n_params': 2,\n",
    "                 'flow_args':{'input_dim':dim,'autoregressive_nn':None,'count_sum':3,'count_degree':1}\n",
    "           }\n",
    "elif flow.__name__ == 'PlanarFlow':\n",
    "    args = {'flow_args':{'input_dim':dim}}\n",
    "elif flow.__name__ == 'RadialFlow':\n",
    "    args = {'flow_args':{'input_dim':dim}}\n",
    "elif flow.__name__ in ['HouseholderFlow']:\n",
    "    args = {'flow_args':{'input_dim':dim,\n",
    "                         'count_transforms':2}}\n",
    "#elif flow.__name__ in ['SylvesterFlow']:\n",
    "elif flow.__name__ in ['Sylvester']:\n",
    "    args = {'flow_args':{'input_dim':dim,\n",
    "                         'count_transforms':2}}\n",
    "else:\n",
    "    raise('Flow not found')\n",
    "    \n",
    "nf_obj = NormalizingFlow(dim=dim,\n",
    "                      n_flows=n_flows,\n",
    "                     base_dist=base_dist,\n",
    "                     flow_type=lambda kwargs:flow(**kwargs),\n",
    "                     args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3fb9c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charlie\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:1681: FutureWarning: Use `x` and `y` rather than `data` `and `data2`\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_40412/1011589351.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnf_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkdeplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_levels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshade\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m             )\n\u001b[0;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py\u001b[0m in \u001b[0;36mkdeplot\u001b[1;34m(x, y, shade, vertical, kernel, bw, gridsize, cut, clip, legend, cumulative, shade_lowest, cbar, cbar_ax, cbar_kws, ax, weights, hue, palette, hue_order, hue_norm, multiple, common_norm, common_grid, levels, thresh, bw_method, bw_adjust, log_scale, color, fill, data, data2, warn_singular, **kwargs)\u001b[0m\n\u001b[0;32m   1736\u001b[0m     \u001b[1;31m# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1738\u001b[1;33m     p = _DistributionPlotter(\n\u001b[0m\u001b[0;32m   1739\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1740\u001b[0m         \u001b[0mvariables\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_DistributionPlotter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_semantics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    109\u001b[0m     ):\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\_core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_semantic_mappings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\_core.py\u001b[0m in \u001b[0;36massign_variables\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"long\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m             plot_data, variables = self._assign_variables_longform(\n\u001b[0m\u001b[0;32m    669\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\_core.py\u001b[0m in \u001b[0;36m_assign_variables_longform\u001b[1;34m(self, data, **kwargs)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 893\u001b[1;33m                     \u001b[0mplot_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    894\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m                     \u001b[0mplot_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "samples = nf_obj.sample(1000).numpy()\n",
    "\n",
    "sns.kdeplot(data=samples[:,0],data2=samples[:,1],n_levels=60, shade=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74b6897",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedb30af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbc202c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ade201db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizingFlow(nn.Module):\n",
    "    \"\"\" A sequence of Normalizing Flows is a Normalizing Flow \"\"\"\n",
    "\n",
    "    def __init__(self, flows):\n",
    "        super().__init__()\n",
    "        self.flows = nn.ModuleList(flows)\n",
    "\n",
    "    def forward(self, x):\n",
    "        m, _ = x.shape\n",
    "        log_det = torch.zeros(m)\n",
    "        zs = [x]\n",
    "        for flow in self.flows:\n",
    "            x, ld = flow.forward(x)\n",
    "            log_det += ld\n",
    "            zs.append(x)\n",
    "        return zs, log_det\n",
    "\n",
    "    def backward(self, z):\n",
    "        m, _ = z.shape\n",
    "        log_det = torch.zeros(m)\n",
    "        xs = [z]\n",
    "        for flow in self.flows[::-1]:\n",
    "            z, ld = flow.backward(z)\n",
    "            log_det += ld\n",
    "            xs.append(z)\n",
    "        return xs, log_det\n",
    "\n",
    "class NormalizingFlowModel(nn.Module):\n",
    "    \"\"\" A Normalizing Flow Model is a (prior, flow) pair \"\"\"\n",
    "    \n",
    "    def __init__(self, prior, flows):\n",
    "        super().__init__()\n",
    "        self.prior = prior\n",
    "        self.flow = NormalizingFlow(flows)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        zs, log_det = self.flow.forward(x)\n",
    "        prior_logprob = self.prior.log_prob(zs[-1]).view(x.size(0), -1).sum(1)\n",
    "        return zs, prior_logprob, log_det\n",
    "\n",
    "    def backward(self, z):\n",
    "        xs, log_det = self.flow.backward(z)\n",
    "        return xs, log_det\n",
    "    \n",
    "    def sample(self, num_samples):\n",
    "        z = self.prior.sample((num_samples,))\n",
    "        xs, _ = self.flow.backward(z)\n",
    "        return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3c2264",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
