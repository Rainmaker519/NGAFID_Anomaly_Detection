{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05b75924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AltAGL</th>\n",
       "      <th>AltB</th>\n",
       "      <th>AltGPS</th>\n",
       "      <th>AltMSL</th>\n",
       "      <th>BaroA</th>\n",
       "      <th>E1_CHT1</th>\n",
       "      <th>E1_CHT2</th>\n",
       "      <th>E1_CHT3</th>\n",
       "      <th>E1_CHT4</th>\n",
       "      <th>E1_EGT1</th>\n",
       "      <th>...</th>\n",
       "      <th>LatAc</th>\n",
       "      <th>NormAc</th>\n",
       "      <th>OAT</th>\n",
       "      <th>Pitch</th>\n",
       "      <th>Roll</th>\n",
       "      <th>TAS</th>\n",
       "      <th>VSpd</th>\n",
       "      <th>VSpdG</th>\n",
       "      <th>WndDr</th>\n",
       "      <th>WndSpd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>855.8</td>\n",
       "      <td>745.7</td>\n",
       "      <td>833.6</td>\n",
       "      <td>30.05</td>\n",
       "      <td>231.88</td>\n",
       "      <td>224.27</td>\n",
       "      <td>243.57</td>\n",
       "      <td>245.74</td>\n",
       "      <td>1047.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>27.2</td>\n",
       "      <td>1.25</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-14.35</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>856.8</td>\n",
       "      <td>746.2</td>\n",
       "      <td>834.0</td>\n",
       "      <td>30.05</td>\n",
       "      <td>232.23</td>\n",
       "      <td>224.58</td>\n",
       "      <td>243.87</td>\n",
       "      <td>246.04</td>\n",
       "      <td>1046.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>27.2</td>\n",
       "      <td>1.23</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>855.8</td>\n",
       "      <td>746.4</td>\n",
       "      <td>834.2</td>\n",
       "      <td>30.05</td>\n",
       "      <td>232.59</td>\n",
       "      <td>224.84</td>\n",
       "      <td>244.12</td>\n",
       "      <td>246.34</td>\n",
       "      <td>1046.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>27.2</td>\n",
       "      <td>1.21</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.96</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>856.8</td>\n",
       "      <td>745.2</td>\n",
       "      <td>833.1</td>\n",
       "      <td>30.05</td>\n",
       "      <td>232.96</td>\n",
       "      <td>225.10</td>\n",
       "      <td>244.46</td>\n",
       "      <td>246.59</td>\n",
       "      <td>1046.32</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>27.2</td>\n",
       "      <td>1.22</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.95</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>856.8</td>\n",
       "      <td>745.2</td>\n",
       "      <td>833.0</td>\n",
       "      <td>30.05</td>\n",
       "      <td>233.30</td>\n",
       "      <td>225.36</td>\n",
       "      <td>244.75</td>\n",
       "      <td>246.86</td>\n",
       "      <td>1043.91</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>27.2</td>\n",
       "      <td>1.22</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.36</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5055</th>\n",
       "      <td>0.0</td>\n",
       "      <td>844.2</td>\n",
       "      <td>751.5</td>\n",
       "      <td>839.3</td>\n",
       "      <td>30.02</td>\n",
       "      <td>282.56</td>\n",
       "      <td>270.85</td>\n",
       "      <td>296.29</td>\n",
       "      <td>288.37</td>\n",
       "      <td>1041.83</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.17</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056</th>\n",
       "      <td>0.0</td>\n",
       "      <td>844.2</td>\n",
       "      <td>751.6</td>\n",
       "      <td>839.4</td>\n",
       "      <td>30.02</td>\n",
       "      <td>282.49</td>\n",
       "      <td>270.90</td>\n",
       "      <td>296.36</td>\n",
       "      <td>288.45</td>\n",
       "      <td>1036.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5057</th>\n",
       "      <td>0.0</td>\n",
       "      <td>844.2</td>\n",
       "      <td>751.7</td>\n",
       "      <td>839.5</td>\n",
       "      <td>30.02</td>\n",
       "      <td>282.43</td>\n",
       "      <td>270.93</td>\n",
       "      <td>296.42</td>\n",
       "      <td>288.52</td>\n",
       "      <td>1030.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5058</th>\n",
       "      <td>1.0</td>\n",
       "      <td>845.2</td>\n",
       "      <td>752.4</td>\n",
       "      <td>840.2</td>\n",
       "      <td>30.02</td>\n",
       "      <td>282.55</td>\n",
       "      <td>271.14</td>\n",
       "      <td>296.58</td>\n",
       "      <td>288.66</td>\n",
       "      <td>1024.47</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5059</th>\n",
       "      <td>0.0</td>\n",
       "      <td>845.2</td>\n",
       "      <td>751.0</td>\n",
       "      <td>838.8</td>\n",
       "      <td>30.02</td>\n",
       "      <td>282.44</td>\n",
       "      <td>271.07</td>\n",
       "      <td>296.52</td>\n",
       "      <td>288.66</td>\n",
       "      <td>1022.10</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5060 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AltAGL   AltB  AltGPS  AltMSL  BaroA  E1_CHT1  E1_CHT2  E1_CHT3  \\\n",
       "0        0.0  855.8   745.7   833.6  30.05   231.88   224.27   243.57   \n",
       "1        0.0  856.8   746.2   834.0  30.05   232.23   224.58   243.87   \n",
       "2        0.0  855.8   746.4   834.2  30.05   232.59   224.84   244.12   \n",
       "3        0.0  856.8   745.2   833.1  30.05   232.96   225.10   244.46   \n",
       "4        0.0  856.8   745.2   833.0  30.05   233.30   225.36   244.75   \n",
       "...      ...    ...     ...     ...    ...      ...      ...      ...   \n",
       "5055     0.0  844.2   751.5   839.3  30.02   282.56   270.85   296.29   \n",
       "5056     0.0  844.2   751.6   839.4  30.02   282.49   270.90   296.36   \n",
       "5057     0.0  844.2   751.7   839.5  30.02   282.43   270.93   296.42   \n",
       "5058     1.0  845.2   752.4   840.2  30.02   282.55   271.14   296.58   \n",
       "5059     0.0  845.2   751.0   838.8  30.02   282.44   271.07   296.52   \n",
       "\n",
       "      E1_CHT4  E1_EGT1  ...  LatAc  NormAc   OAT  Pitch  Roll  TAS   VSpd  \\\n",
       "0      245.74  1047.12  ...   0.01    0.01  27.2   1.25 -0.21  0.0 -14.35   \n",
       "1      246.04  1046.06  ...   0.01   -0.00  27.2   1.23 -0.15  0.0   0.74   \n",
       "2      246.34  1046.17  ...   0.00   -0.01  27.2   1.21 -0.14  0.0   5.96   \n",
       "3      246.59  1046.32  ...  -0.00   -0.01  27.2   1.22 -0.14  0.0   9.95   \n",
       "4      246.86  1043.91  ...   0.01   -0.01  27.2   1.22 -0.10  0.0  13.36   \n",
       "...       ...      ...  ...    ...     ...   ...    ...   ...  ...    ...   \n",
       "5055   288.37  1041.83  ...   0.00    0.04  26.0   1.45  0.00  0.0  15.17   \n",
       "5056   288.45  1036.33  ...   0.00   -0.02  26.0   1.29  0.03  0.0  15.98   \n",
       "5057   288.52  1030.14  ...   0.00    0.01  26.0   1.76  0.02  0.0  17.44   \n",
       "5058   288.66  1024.47  ...  -0.00   -0.01  26.0   1.80  0.01  0.0  25.02   \n",
       "5059   288.66  1022.10  ...  -0.00   -0.01  26.0   1.80  0.01  0.0  17.27   \n",
       "\n",
       "      VSpdG  WndDr  WndSpd  \n",
       "0      -3.9    0.0     0.0  \n",
       "1      -3.9    0.0     0.0  \n",
       "2      -3.9    0.0     0.0  \n",
       "3      -3.9    0.0     0.0  \n",
       "4      -3.9    0.0     0.0  \n",
       "...     ...    ...     ...  \n",
       "5055   -3.9    0.0     0.0  \n",
       "5056    0.0    0.0     0.0  \n",
       "5057    0.0    0.0     0.0  \n",
       "5058    0.0    0.0     0.0  \n",
       "5059    0.0    0.0     0.0  \n",
       "\n",
       "[5060 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('c172_file_1.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f844b9ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg: tensor([[0.2466]], dtype=torch.float64, grad_fn=<SplitBackward>)\n",
      "logvar: tensor([[-0.0109]], dtype=torch.float64, grad_fn=<SplitBackward>)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'log_prob'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Desktop\\NGAFID-REFERENCE\\NGAFID_Anomaly_Detection\\Charlie-Code\\real_demo.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mlocalX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m             \u001b[0mrecon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdemo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocalX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocalX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\NGAFID-REFERENCE\\NGAFID_Anomaly_Detection\\Charlie-Code\\real_demo.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;31m#now we have z0, and we pass this into the nf to get\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mnf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNormalizingFlowModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdemo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mAffineConstantFlow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[1;31m#print(\"Z: \" + str(z))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\NGAFID-REFERENCE\\NGAFID_Anomaly_Detection\\Charlie-Code\\real_demo.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[0mzs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_det\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m         \u001b[0mprior_logprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprior\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mzs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior_logprob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_det\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1129\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1130\u001b[1;33m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[0;32m   1131\u001b[0m             type(self).__name__, name))\n\u001b[0;32m   1132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'log_prob'"
     ]
    }
   ],
   "source": [
    "%run real_demo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bf5df79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4335, -1.2903]])\n",
      "tensor([[-0.8129,  0.0930]])\n",
      "tensor([[-0.3291,  1.2206]])\n",
      "tensor([[-0.0195, -0.3770]])\n",
      "tensor([[0.0592, 0.0213]])\n",
      "tensor([[-0.2812,  2.7627]])\n",
      "tensor([[0.0645, 0.2840]])\n",
      "tensor([[-0.9304,  1.2469]])\n",
      "tensor([[-0.3719, -0.3366]])\n",
      "tensor([[ 0.0206, -1.3476]])\n",
      "tensor([[-1.0824,  0.3983]])\n",
      "tensor([[ 1.1127, -0.2054]])\n",
      "tensor([[0.7136, 1.3276]])\n",
      "tensor([[ 0.4594, -0.7410]])\n",
      "tensor([[-0.0698, -0.7053]])\n",
      "tensor([[1.5173e+00, 7.9101e-04]])\n",
      "tensor([[ 0.8179, -0.4694]])\n",
      "tensor([[ 0.2670, -0.7943]])\n",
      "tensor([[ 1.4344, -1.4264]])\n",
      "tensor([[-1.2466,  2.9490]])\n",
      "tensor([[-0.0817,  0.6329]])\n",
      "tensor([[-0.1695, -0.4880]])\n",
      "tensor([[-1.6382,  0.4132]])\n",
      "tensor([[-1.1524, -0.4515]])\n",
      "tensor([[-0.7957,  0.2414]])\n",
      "tensor([[-0.4156, -0.0399]])\n",
      "tensor([[0.4025, 0.8434]])\n",
      "tensor([[ 0.2354, -0.1505]])\n",
      "tensor([[-0.3300,  1.0135]])\n",
      "tensor([[-2.1958, -0.8394]])\n",
      "tensor([[0.7890, 0.4724]])\n",
      "tensor([[1.8427, 0.3131]])\n",
      "tensor([[-0.0530, -1.3353]])\n",
      "tensor([[2.0671, 0.8311]])\n",
      "tensor([[-0.7314,  1.0718]])\n",
      "tensor([[-1.1104, -1.5810]])\n",
      "tensor([[-0.8717,  0.5572]])\n",
      "tensor([[ 1.5139, -0.9259]])\n",
      "tensor([[-0.0475, -1.6306]])\n",
      "tensor([[-0.1678,  1.1820]])\n",
      "tensor([[-1.1982, -1.1801]])\n",
      "tensor([[-0.1496, -1.2344]])\n",
      "tensor([[1.0374, 0.6863]])\n",
      "tensor([[ 0.1576, -1.2697]])\n",
      "tensor([[ 0.5909, -0.2715]])\n",
      "tensor([[-0.0395,  0.7643]])\n",
      "tensor([[-0.3051, -1.0302]])\n",
      "tensor([[-1.6915, -0.6062]])\n",
      "tensor([[1.4227, 0.4018]])\n",
      "tensor([[-0.5482, -2.2603]])\n",
      "tensor([[0.0365, 1.0649]])\n",
      "tensor([[-0.7326, -1.1500]])\n",
      "tensor([[0.9542, 0.2451]])\n",
      "tensor([[1.2457, 1.5112]])\n",
      "tensor([[-1.0256, -1.7314]])\n",
      "tensor([[ 1.0326, -0.9360]])\n",
      "tensor([[-0.5075, -1.8232]])\n",
      "tensor([[-1.2950,  0.0529]])\n",
      "tensor([[-0.6709,  0.0221]])\n",
      "tensor([[-0.6244,  0.7951]])\n",
      "tensor([[0.5808, 0.3550]])\n",
      "tensor([[ 1.6694, -1.1778]])\n",
      "tensor([[-1.5327, -0.7511]])\n",
      "tensor([[ 0.3826, -0.1753]])\n",
      "tensor([[1.2292, 0.7886]])\n",
      "tensor([[-0.1165,  0.9283]])\n",
      "tensor([[-0.9534, -0.3080]])\n",
      "tensor([[ 0.4968, -0.1127]])\n",
      "tensor([[0.1628, 0.4819]])\n",
      "tensor([[-2.0376, -1.3941]])\n",
      "tensor([[1.7294, 1.0706]])\n",
      "tensor([[0.2407, 1.5191]])\n",
      "tensor([[-0.0746, -0.7228]])\n",
      "tensor([[ 1.4400, -0.9365]])\n",
      "tensor([[-0.1364,  1.2772]])\n",
      "tensor([[-1.1110,  1.3644]])\n",
      "tensor([[-0.1076, -0.4386]])\n",
      "tensor([[-1.0444,  0.3400]])\n",
      "tensor([[0.5149, 0.9738]])\n",
      "tensor([[-0.4838,  1.8420]])\n",
      "tensor([[-0.8424,  0.3841]])\n",
      "tensor([[-1.6026, -1.1671]])\n",
      "tensor([[-0.5441, -0.5774]])\n",
      "tensor([[-0.4329,  0.4844]])\n",
      "tensor([[-0.4306,  0.9105]])\n",
      "tensor([[-1.7555, -1.1378]])\n",
      "tensor([[-0.6567, -0.0116]])\n",
      "tensor([[3.0144, 0.2408]])\n",
      "tensor([[ 0.7325, -0.5388]])\n",
      "tensor([[ 0.1308, -0.2879]])\n",
      "tensor([[-1.0473, -1.9352]])\n",
      "tensor([[ 0.6011, -0.1436]])\n",
      "tensor([[0.5974, 0.7399]])\n",
      "tensor([[-1.5904,  0.4878]])\n",
      "tensor([[-1.9569,  1.1703]])\n",
      "tensor([[-0.9827,  0.1917]])\n",
      "tensor([[-0.3049,  0.8023]])\n",
      "tensor([[ 0.0228, -0.7538]])\n",
      "tensor([[0.2934, 0.7724]])\n",
      "tensor([[-0.1148, -0.3343]])\n",
      "Epoch[1/10] Loss: 0.166\n",
      "tensor([[-0.9130,  0.7104]])\n",
      "tensor([[0.3671, 1.0461]])\n",
      "tensor([[-0.0504, -0.1220]])\n",
      "tensor([[-0.1746,  1.3656]])\n",
      "tensor([[-0.1728, -1.9725]])\n",
      "tensor([[0.3862, 1.6415]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charlie\\anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0234, -0.0794]])\n",
      "tensor([[-0.4935,  1.3243]])\n",
      "tensor([[0.8349, 1.0082]])\n",
      "tensor([[-1.5826, -0.0730]])\n",
      "tensor([[-0.4098, -0.5608]])\n",
      "tensor([[0.1999, 0.0362]])\n",
      "tensor([[0.5764, 0.2041]])\n",
      "tensor([[ 0.4655, -0.0640]])\n",
      "tensor([[0.5685, 0.9258]])\n",
      "tensor([[0.9783, 0.5587]])\n",
      "tensor([[0.4479, 0.6799]])\n",
      "tensor([[ 0.5526, -0.8646]])\n",
      "tensor([[0.7499, 1.7279]])\n",
      "tensor([[0.7054, 1.2825]])\n",
      "tensor([[-0.1915, -0.7186]])\n",
      "tensor([[-0.0974,  0.0106]])\n",
      "tensor([[ 0.9057, -1.6140]])\n",
      "tensor([[-1.4587,  0.9709]])\n",
      "tensor([[-1.2220,  0.2855]])\n",
      "tensor([[-1.6553,  1.5136]])\n",
      "tensor([[0.1266, 0.6574]])\n",
      "tensor([[-1.6127, -1.3402]])\n",
      "tensor([[0.6606, 1.2147]])\n",
      "tensor([[0.6328, 0.2407]])\n",
      "tensor([[ 1.3551, -0.8589]])\n",
      "tensor([[1.7937, 0.1266]])\n",
      "tensor([[ 0.6276, -0.4586]])\n",
      "tensor([[2.2387, 1.1541]])\n",
      "tensor([[-0.8214, -1.1020]])\n",
      "tensor([[0.2222, 0.0778]])\n",
      "tensor([[ 1.1730, -1.0869]])\n",
      "tensor([[-0.0142, -1.1974]])\n",
      "tensor([[-0.1882, -0.6341]])\n",
      "tensor([[-0.6981,  0.4863]])\n",
      "tensor([[ 0.6907, -2.0113]])\n",
      "tensor([[-0.3229,  0.7382]])\n",
      "tensor([[-0.4512, -0.0943]])\n",
      "tensor([[ 0.9603, -1.2149]])\n",
      "tensor([[0.2982, 0.3185]])\n",
      "tensor([[ 0.1470, -1.1421]])\n",
      "tensor([[0.1585, 0.7673]])\n",
      "tensor([[0.0101, 0.5331]])\n",
      "tensor([[ 0.3250, -0.2564]])\n",
      "tensor([[-0.5154,  0.7756]])\n",
      "tensor([[ 1.2618, -0.8383]])\n",
      "tensor([[0.8688, 1.0341]])\n",
      "tensor([[-1.3910, -0.9745]])\n",
      "tensor([[ 1.0237, -0.3376]])\n",
      "tensor([[-0.1397,  0.9205]])\n",
      "tensor([[-0.4210,  0.3262]])\n",
      "tensor([[ 0.9349, -0.5293]])\n",
      "tensor([[-0.1341,  1.6709]])\n",
      "tensor([[-0.5060,  0.7802]])\n",
      "tensor([[-1.7345, -0.1171]])\n",
      "tensor([[-0.1959, -0.2263]])\n",
      "tensor([[ 0.6663, -1.1262]])\n",
      "tensor([[ 1.5340, -1.4162]])\n",
      "tensor([[-0.1204, -0.0688]])\n",
      "tensor([[ 0.6933, -0.2853]])\n",
      "tensor([[0.5938, 0.7886]])\n",
      "tensor([[ 0.9618, -0.1192]])\n",
      "tensor([[ 0.4636, -0.1921]])\n",
      "tensor([[ 0.5042, -0.4469]])\n",
      "tensor([[ 0.0662, -0.2740]])\n",
      "tensor([[-0.1366, -0.6442]])\n",
      "tensor([[0.0627, 1.0569]])\n",
      "tensor([[ 0.3579, -1.2281]])\n",
      "tensor([[-1.2935,  0.3987]])\n",
      "tensor([[ 0.9205, -0.3966]])\n",
      "tensor([[-0.1861,  0.8313]])\n",
      "tensor([[1.1059, 0.5817]])\n",
      "tensor([[-2.3775, -0.7729]])\n",
      "tensor([[0.8587, 0.5779]])\n",
      "tensor([[ 0.4662, -1.2385]])\n",
      "tensor([[-0.1757, -0.3772]])\n",
      "tensor([[-0.5484, -0.4203]])\n",
      "tensor([[0.9437, 0.8093]])\n",
      "tensor([[0.3063, 0.5239]])\n",
      "tensor([[-0.1444, -1.9350]])\n",
      "tensor([[-0.8321, -0.0759]])\n",
      "tensor([[0.6597, 0.4990]])\n",
      "tensor([[-1.2591,  0.2301]])\n",
      "tensor([[2.0444, 0.3762]])\n",
      "tensor([[-1.3635,  0.1085]])\n",
      "tensor([[0.0604, 0.7108]])\n",
      "tensor([[ 0.3077, -0.9163]])\n",
      "tensor([[-0.7535, -0.8347]])\n",
      "tensor([[-0.9666, -2.0099]])\n",
      "tensor([[ 0.0647, -1.3587]])\n",
      "tensor([[-0.1473,  0.1617]])\n",
      "tensor([[1.0540, 0.1004]])\n",
      "tensor([[ 0.7534, -0.6756]])\n",
      "tensor([[-1.7539,  0.9832]])\n",
      "tensor([[-0.4232,  0.1087]])\n",
      "Epoch[1/10] Loss: 0.162\n",
      "tensor([[-1.6353, -1.1046]])\n",
      "tensor([[-2.0062, -0.8737]])\n",
      "tensor([[ 0.9375, -1.4385]])\n",
      "tensor([[-0.8911, -0.0252]])\n",
      "tensor([[-0.3021, -1.2599]])\n",
      "tensor([[-0.3443, -0.6665]])\n",
      "tensor([[-0.5163, -0.4499]])\n",
      "tensor([[0.2534, 0.2654]])\n",
      "tensor([[-0.5907, -1.5691]])\n",
      "tensor([[-1.2407,  0.1608]])\n",
      "tensor([[-0.2614,  2.3718]])\n",
      "tensor([[ 2.8503, -2.1486]])\n",
      "tensor([[0.8306, 0.0351]])\n",
      "tensor([[1.5860, 0.6267]])\n",
      "tensor([[-0.5565, -1.9227]])\n",
      "tensor([[ 0.2331, -0.4012]])\n",
      "tensor([[1.7942, 0.1406]])\n",
      "tensor([[ 1.0964, -0.3699]])\n",
      "tensor([[0.6093, 1.0536]])\n",
      "tensor([[-2.1382, -0.6457]])\n",
      "tensor([[-0.5643,  1.1852]])\n",
      "tensor([[1.2704, 1.4824]])\n",
      "tensor([[ 0.0970, -1.0246]])\n",
      "tensor([[0.8894, 1.2297]])\n",
      "tensor([[-0.5139,  0.2230]])\n",
      "tensor([[-0.3057, -0.0587]])\n",
      "tensor([[-1.0884,  0.0146]])\n",
      "tensor([[-0.7825,  0.5899]])\n",
      "tensor([[-0.6729,  1.0966]])\n",
      "tensor([[0.4127, 0.7741]])\n",
      "tensor([[-0.5793,  1.7222]])\n",
      "tensor([[-0.5693, -0.6094]])\n",
      "tensor([[ 0.0392, -0.9293]])\n",
      "tensor([[-1.1195, -1.7234]])\n",
      "tensor([[-0.9376,  0.2049]])\n",
      "tensor([[-0.7279, -0.8462]])\n",
      "tensor([[-0.4689,  1.4909]])\n",
      "tensor([[1.9389, 0.7384]])\n",
      "tensor([[ 1.0198, -1.7627]])\n",
      "tensor([[-1.5082,  1.2409]])\n",
      "tensor([[-0.3825, -1.4270]])\n",
      "tensor([[-1.4410, -0.8252]])\n",
      "tensor([[-0.5102,  1.0350]])\n",
      "tensor([[ 0.1722, -1.7448]])\n",
      "tensor([[-1.3680,  0.3546]])\n",
      "tensor([[-0.1365,  0.7101]])\n",
      "tensor([[ 0.4777, -1.6520]])\n",
      "tensor([[1.0900, 0.1336]])\n",
      "tensor([[-1.7765,  0.0425]])\n",
      "tensor([[0.8801, 0.8626]])\n",
      "tensor([[-1.6965, -0.4150]])\n",
      "tensor([[ 1.3895, -0.9640]])\n",
      "tensor([[0.0323, 1.3114]])\n",
      "tensor([[-0.5218,  0.2666]])\n",
      "tensor([[-0.9478,  1.0886]])\n",
      "tensor([[ 0.2005, -0.7400]])\n",
      "tensor([[-2.6696,  0.1588]])\n",
      "tensor([[ 0.0114, -1.6596]])\n",
      "tensor([[-1.3920,  2.1075]])\n",
      "tensor([[-0.8711,  0.5934]])\n",
      "tensor([[-0.7955, -0.7411]])\n",
      "tensor([[-0.3658, -1.7963]])\n",
      "tensor([[0.6732, 0.1260]])\n",
      "tensor([[-0.3539,  0.2594]])\n",
      "tensor([[0.0469, 0.9727]])\n",
      "tensor([[-0.3657, -1.9108]])\n",
      "tensor([[ 0.8494, -1.3714]])\n",
      "tensor([[ 1.5275, -0.5389]])\n",
      "tensor([[-0.5950, -0.0336]])\n",
      "tensor([[0.9029, 0.2831]])\n",
      "tensor([[-0.6951,  0.3687]])\n",
      "tensor([[-0.6710, -0.7417]])\n",
      "tensor([[-0.3927,  0.9371]])\n",
      "tensor([[-0.1560,  0.3509]])\n",
      "tensor([[0.8360, 0.5820]])\n",
      "tensor([[-0.4464, -0.3157]])\n",
      "tensor([[0.2735, 1.6885]])\n",
      "tensor([[-0.1988, -0.0480]])\n",
      "tensor([[1.1327, 0.1680]])\n",
      "tensor([[0.9154, 0.3138]])\n",
      "tensor([[ 0.7892, -0.0053]])\n",
      "tensor([[0.8727, 0.2680]])\n",
      "tensor([[-1.5111,  0.6018]])\n",
      "tensor([[-0.1967,  0.2282]])\n",
      "tensor([[-1.0839,  0.5246]])\n",
      "tensor([[ 0.7487, -0.3154]])\n",
      "tensor([[0.8903, 0.6400]])\n",
      "tensor([[-1.0480, -0.5318]])\n",
      "tensor([[-0.2464, -0.0253]])\n",
      "tensor([[-0.9015,  1.6094]])\n",
      "tensor([[0.6564, 0.7415]])\n",
      "tensor([[-1.5738, -0.4806]])\n",
      "tensor([[-0.5763, -0.7101]])\n",
      "tensor([[0.5676, 0.5408]])\n",
      "tensor([[-0.4590,  2.2491]])\n",
      "tensor([[-1.8551,  0.6186]])\n",
      "tensor([[ 7.3148e-04, -7.9923e-01]])\n",
      "tensor([[-0.8215,  0.5685]])\n",
      "tensor([[ 0.7946, -1.1904]])\n",
      "tensor([[-0.4254, -0.0834]])\n",
      "Epoch[1/10] Loss: 0.162\n",
      "tensor([[-0.6501,  0.7880]])\n",
      "tensor([[-0.7190,  0.7818]])\n",
      "tensor([[0.1007, 0.3247]])\n",
      "tensor([[-0.7286, -0.7048]])\n",
      "tensor([[0.3921, 1.2860]])\n",
      "tensor([[0.1339, 1.2934]])\n",
      "tensor([[-0.3906, -0.6248]])\n",
      "tensor([[-0.6980,  1.3737]])\n",
      "tensor([[0.2656, 0.0834]])\n",
      "tensor([[-0.4105, -0.6050]])\n",
      "tensor([[1.0738, 0.3713]])\n",
      "tensor([[-1.7640, -0.5105]])\n",
      "tensor([[-0.4072, -1.2062]])\n",
      "tensor([[-0.0570, -0.7935]])\n",
      "tensor([[-0.1400, -0.7859]])\n",
      "tensor([[ 0.0814, -1.3374]])\n",
      "tensor([[0.9573, 0.5921]])\n",
      "tensor([[-0.9235, -0.3737]])\n",
      "tensor([[0.5565, 0.0337]])\n",
      "tensor([[1.7642, 1.3643]])\n",
      "tensor([[-2.0850, -0.0345]])\n",
      "tensor([[-0.3351,  1.1773]])\n",
      "tensor([[-1.1743, -0.9919]])\n",
      "tensor([[2.3066, 0.4356]])\n",
      "tensor([[-1.0910,  0.0398]])\n",
      "tensor([[-2.1221,  0.0563]])\n",
      "tensor([[-0.3427, -0.7504]])\n",
      "tensor([[-2.2384, -0.9450]])\n",
      "tensor([[-0.4252,  0.7287]])\n",
      "tensor([[0.8207, 0.3871]])\n",
      "tensor([[ 0.0555, -0.0183]])\n",
      "tensor([[ 1.1206, -1.1304]])\n",
      "tensor([[0.4151, 0.1496]])\n",
      "tensor([[ 0.7437, -0.2809]])\n",
      "tensor([[ 0.9647, -0.1791]])\n",
      "tensor([[ 0.2127, -0.0737]])\n",
      "tensor([[-0.3701,  0.2838]])\n",
      "tensor([[ 0.6465, -0.8093]])\n",
      "tensor([[-1.7512, -0.8385]])\n",
      "tensor([[0.7253, 0.6477]])\n",
      "tensor([[-1.6020, -1.1862]])\n",
      "tensor([[ 0.5751, -0.8162]])\n",
      "tensor([[-0.1439,  0.1850]])\n",
      "tensor([[-1.0031, -1.4332]])\n",
      "tensor([[-0.6125, -0.0713]])\n",
      "tensor([[-1.3551, -0.9545]])\n",
      "tensor([[-2.8978, -1.4255]])\n",
      "tensor([[-0.6884, -0.4943]])\n",
      "tensor([[-1.7125,  1.4145]])\n",
      "tensor([[-1.4101,  0.6811]])\n",
      "tensor([[-1.3250, -0.4032]])\n",
      "tensor([[-0.0862,  0.3965]])\n",
      "tensor([[-0.3808, -1.2925]])\n",
      "tensor([[ 1.2035, -0.4301]])\n",
      "tensor([[-1.8239,  0.0376]])\n",
      "tensor([[-0.9800, -0.0341]])\n",
      "tensor([[-1.7850,  0.0688]])\n",
      "tensor([[-0.8651,  0.3078]])\n",
      "tensor([[-0.2830,  0.2775]])\n",
      "tensor([[0.4231, 1.4800]])\n",
      "tensor([[ 1.0619, -0.4206]])\n",
      "tensor([[0.9399, 0.3321]])\n",
      "tensor([[0.4156, 0.6047]])\n",
      "tensor([[ 0.7468, -2.5188]])\n",
      "tensor([[ 1.1654, -1.0257]])\n",
      "tensor([[-0.4495, -2.8060]])\n",
      "tensor([[-2.2259, -0.0395]])\n",
      "tensor([[-0.3201,  1.2726]])\n",
      "tensor([[1.0904, 0.2341]])\n",
      "tensor([[-1.1624,  0.1889]])\n",
      "tensor([[0.2926, 0.1866]])\n",
      "tensor([[0.4648, 0.8225]])\n",
      "tensor([[1.5705, 0.6190]])\n",
      "tensor([[ 0.5733, -1.0234]])\n",
      "tensor([[ 0.0639, -1.2916]])\n",
      "tensor([[0.1887, 0.9346]])\n",
      "tensor([[ 1.0582, -0.4983]])\n",
      "tensor([[-0.2927, -2.6299]])\n",
      "tensor([[1.7389, 0.6728]])\n",
      "tensor([[0.8072, 0.6773]])\n",
      "tensor([[0.1427, 0.0970]])\n",
      "tensor([[-0.8544,  0.0250]])\n",
      "tensor([[ 1.2257, -1.0390]])\n",
      "tensor([[ 0.8651, -1.2942]])\n",
      "tensor([[0.4903, 0.2281]])\n",
      "tensor([[-1.5318,  0.7588]])\n",
      "tensor([[-1.4367, -0.3926]])\n",
      "tensor([[-0.9708, -0.4781]])\n",
      "tensor([[1.0173, 0.7279]])\n",
      "tensor([[0.9345, 0.5593]])\n",
      "tensor([[ 0.0233, -0.3025]])\n",
      "tensor([[1.7180, 0.4952]])\n",
      "tensor([[-1.7110, -0.6264]])\n",
      "tensor([[0.3375, 1.0899]])\n",
      "tensor([[-1.6355,  0.3131]])\n",
      "tensor([[1.0889, 1.0855]])\n",
      "tensor([[ 1.2575, -0.5939]])\n",
      "tensor([[ 0.1716, -1.6470]])\n",
      "tensor([[ 0.5879, -0.4419]])\n",
      "tensor([[ 2.2458, -1.3426]])\n",
      "Epoch[1/10] Loss: 0.169\n",
      "tensor([[ 0.4793, -0.7935]])\n",
      "tensor([[ 0.1350, -1.1307]])\n",
      "tensor([[ 0.7575, -1.3730]])\n",
      "tensor([[0.9444, 0.2546]])\n",
      "tensor([[ 1.7158, -0.3837]])\n",
      "tensor([[ 0.8524, -0.7994]])\n",
      "tensor([[-1.2120,  1.1905]])\n",
      "tensor([[-0.8885, -1.5213]])\n",
      "tensor([[ 0.1854, -0.3380]])\n",
      "tensor([[-0.3204,  0.2617]])\n",
      "tensor([[ 0.0337, -0.7266]])\n",
      "tensor([[-0.6643,  0.4227]])\n",
      "tensor([[0.1994, 0.2969]])\n",
      "tensor([[-0.1276, -0.4527]])\n",
      "tensor([[-0.0498,  0.7193]])\n",
      "tensor([[0.4889, 0.1907]])\n",
      "tensor([[-0.5253,  0.5383]])\n",
      "tensor([[0.3222, 0.3378]])\n",
      "tensor([[0.1509, 1.3915]])\n",
      "tensor([[0.1691, 1.4713]])\n",
      "tensor([[ 0.7998, -0.5079]])\n",
      "tensor([[-0.1809,  2.2848]])\n",
      "tensor([[1.4413, 0.9934]])\n",
      "tensor([[-1.2327, -0.5726]])\n",
      "tensor([[-0.7993,  0.0170]])\n",
      "tensor([[1.1944, 0.1944]])\n",
      "tensor([[ 0.8367, -1.0013]])\n",
      "tensor([[-1.0209,  0.8273]])\n",
      "tensor([[ 1.7270, -0.5512]])\n",
      "tensor([[-0.8296, -0.6727]])\n",
      "tensor([[-1.5443, -0.0741]])\n",
      "tensor([[-1.0031,  0.5839]])\n",
      "tensor([[-1.8159, -1.6783]])\n",
      "tensor([[ 0.1065, -0.3044]])\n",
      "tensor([[-1.7097,  0.8581]])\n",
      "tensor([[-0.0808, -0.2558]])\n",
      "tensor([[-0.1824, -0.6900]])\n",
      "tensor([[ 0.3294, -0.4059]])\n",
      "tensor([[-1.2786,  1.5899]])\n",
      "tensor([[0.7259, 0.0891]])\n",
      "tensor([[0.0182, 0.5329]])\n",
      "tensor([[-0.8511, -0.0021]])\n",
      "tensor([[0.4719, 0.4098]])\n",
      "tensor([[-0.3673, -0.1171]])\n",
      "tensor([[-0.7073, -0.6967]])\n",
      "tensor([[ 0.2536, -0.4097]])\n",
      "tensor([[-1.1765, -1.4295]])\n",
      "tensor([[-1.1245, -0.2629]])\n",
      "tensor([[-1.0884,  0.7432]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3121, -0.3629]])\n",
      "tensor([[-0.3366,  1.6380]])\n",
      "tensor([[ 1.2645, -0.5880]])\n",
      "tensor([[-1.7149,  0.0943]])\n",
      "tensor([[1.3236, 0.9363]])\n",
      "tensor([[ 2.0951, -0.3495]])\n",
      "tensor([[-1.2494, -0.4395]])\n",
      "tensor([[ 0.3698, -0.8155]])\n",
      "tensor([[0.3844, 1.8061]])\n",
      "tensor([[-0.6159, -0.4052]])\n",
      "tensor([[-0.3523, -0.2946]])\n",
      "tensor([[-0.4566, -0.6607]])\n",
      "tensor([[-0.5474,  0.3296]])\n",
      "tensor([[1.0758, 2.3611]])\n",
      "tensor([[-0.6198, -0.8334]])\n",
      "tensor([[-1.3707, -2.0805]])\n",
      "tensor([[-0.2036,  1.1849]])\n",
      "tensor([[ 0.4988, -0.3219]])\n",
      "tensor([[-1.5220,  0.1404]])\n",
      "tensor([[-0.7198,  0.0134]])\n",
      "tensor([[ 0.0951, -0.0860]])\n",
      "tensor([[1.7889, 1.2703]])\n",
      "tensor([[0.1892, 0.1565]])\n",
      "tensor([[-0.6117,  0.2738]])\n",
      "tensor([[-0.3593, -0.7729]])\n",
      "tensor([[-0.6589, -0.5391]])\n",
      "tensor([[-0.1204, -0.6186]])\n",
      "tensor([[ 1.9733, -0.4220]])\n",
      "tensor([[0.3993, 0.0519]])\n",
      "tensor([[-0.8230, -1.4638]])\n",
      "tensor([[-0.6853, -0.6518]])\n",
      "tensor([[-0.4730, -0.9706]])\n",
      "tensor([[-0.1599, -0.4188]])\n",
      "tensor([[-0.0214, -0.0824]])\n",
      "tensor([[ 0.8817, -2.0938]])\n",
      "tensor([[0.6552, 1.1240]])\n",
      "tensor([[ 0.4164, -1.0600]])\n",
      "tensor([[-0.6907,  0.8136]])\n",
      "tensor([[-0.9678,  0.7634]])\n",
      "tensor([[0.1029, 0.0886]])\n",
      "tensor([[0.1305, 1.4222]])\n",
      "tensor([[-1.3887, -1.4539]])\n",
      "tensor([[ 0.3504, -0.5464]])\n",
      "tensor([[-0.0092,  0.1478]])\n",
      "tensor([[ 0.3707, -1.3844]])\n",
      "tensor([[-0.0646, -0.9756]])\n",
      "tensor([[-0.7435,  0.3862]])\n",
      "tensor([[ 1.5568, -1.5080]])\n",
      "tensor([[ 0.8678, -0.0839]])\n",
      "tensor([[-0.3412, -0.8031]])\n",
      "tensor([[-1.7708, -0.2862]])\n",
      "Epoch[1/10] Loss: 0.161\n",
      "tensor([[0.5754, 1.0493]])\n",
      "tensor([[-1.4833, -1.6729]])\n",
      "tensor([[0.5568, 0.2219]])\n",
      "tensor([[0.9278, 0.5611]])\n",
      "tensor([[-0.3696,  0.5143]])\n",
      "tensor([[-3.3055, -1.2900]])\n",
      "tensor([[ 0.0852, -0.3365]])\n",
      "tensor([[-0.3264, -0.1917]])\n",
      "tensor([[0.7518, 0.7560]])\n",
      "tensor([[-0.1201, -0.4413]])\n",
      "tensor([[-0.3609,  0.9496]])\n",
      "tensor([[ 1.6248, -0.3796]])\n",
      "tensor([[-0.3433,  0.4861]])\n",
      "tensor([[1.2742, 0.7266]])\n",
      "tensor([[ 0.2956, -1.3995]])\n",
      "tensor([[ 0.4490, -0.0217]])\n",
      "tensor([[-0.8181,  1.7845]])\n",
      "tensor([[0.9540, 0.7581]])\n",
      "tensor([[-0.6856, -0.5109]])\n",
      "tensor([[1.1939, 1.9057]])\n",
      "tensor([[ 0.9442, -0.1411]])\n",
      "tensor([[0.1491, 1.1086]])\n",
      "tensor([[-0.1229,  2.9019]])\n",
      "tensor([[ 1.7081e+00, -1.0729e-03]])\n",
      "tensor([[ 0.4218, -0.3767]])\n",
      "tensor([[ 1.0771, -1.9081]])\n",
      "tensor([[-0.8814,  0.2306]])\n",
      "tensor([[1.1352, 0.1902]])\n",
      "tensor([[ 1.1883, -2.2631]])\n",
      "tensor([[0.5091, 1.5871]])\n",
      "tensor([[-0.7310,  0.3755]])\n",
      "tensor([[0.1917, 1.6282]])\n",
      "tensor([[ 0.2839, -0.2090]])\n",
      "tensor([[-1.1944e+00, -3.7741e-04]])\n",
      "tensor([[0.4392, 0.5101]])\n",
      "tensor([[-1.0529,  0.2715]])\n",
      "tensor([[-0.8834, -0.7879]])\n",
      "tensor([[-0.6459,  0.8534]])\n",
      "tensor([[ 1.1120, -1.3775]])\n",
      "tensor([[-1.3297,  1.8321]])\n",
      "tensor([[-1.7527, -0.9296]])\n",
      "tensor([[ 0.5896, -0.4476]])\n",
      "tensor([[0.0988, 0.0062]])\n",
      "tensor([[-0.4604, -0.2365]])\n",
      "tensor([[ 0.2389, -0.6599]])\n",
      "tensor([[ 0.9635, -0.4873]])\n",
      "tensor([[1.9193, 0.2606]])\n",
      "tensor([[ 0.1841, -0.9194]])\n",
      "tensor([[ 0.2400, -0.1256]])\n",
      "tensor([[1.4411, 0.2410]])\n",
      "tensor([[-0.8217,  0.2155]])\n",
      "tensor([[1.8329, 0.7944]])\n",
      "tensor([[ 0.1403, -1.1890]])\n",
      "tensor([[-1.1041, -0.2863]])\n",
      "tensor([[ 0.2980, -0.2435]])\n",
      "tensor([[0.6310, 0.5431]])\n",
      "tensor([[ 0.7384, -0.9581]])\n",
      "tensor([[0.9580, 1.1371]])\n",
      "tensor([[ 1.6624, -1.3337]])\n",
      "tensor([[-1.3494,  0.8582]])\n",
      "tensor([[ 1.7632, -0.1207]])\n",
      "tensor([[ 1.8310, -1.4022]])\n",
      "tensor([[ 0.6803, -1.3199]])\n",
      "tensor([[-0.9837, -0.5192]])\n",
      "tensor([[-0.4159, -1.1996]])\n",
      "tensor([[ 1.1879, -0.6366]])\n",
      "tensor([[-0.3136, -0.7880]])\n",
      "tensor([[-0.5655, -1.4752]])\n",
      "tensor([[-2.3298,  0.5797]])\n",
      "tensor([[-1.7105, -1.9497]])\n",
      "tensor([[0.9846, 0.9714]])\n",
      "tensor([[-1.2659, -0.4789]])\n",
      "tensor([[1.4863, 0.1575]])\n",
      "tensor([[ 1.5210, -0.2922]])\n",
      "tensor([[ 2.0834, -0.5627]])\n",
      "tensor([[0.2978, 0.4747]])\n",
      "tensor([[2.5262, 1.2802]])\n",
      "tensor([[0.5839, 0.2710]])\n",
      "tensor([[-1.5352, -1.1290]])\n",
      "tensor([[-0.3720, -0.1136]])\n",
      "tensor([[ 0.9893, -0.7224]])\n",
      "tensor([[-1.7580,  1.8100]])\n",
      "tensor([[0.1724, 1.0193]])\n",
      "tensor([[ 2.1426, -1.7178]])\n",
      "tensor([[0.3514, 0.8896]])\n",
      "tensor([[-0.1979, -0.8405]])\n",
      "tensor([[ 0.3208, -0.5158]])\n",
      "tensor([[1.1368, 0.3997]])\n",
      "tensor([[ 1.7453, -0.2987]])\n",
      "tensor([[ 0.8852, -0.2335]])\n",
      "tensor([[0.0814, 1.1007]])\n",
      "tensor([[-0.2460, -0.5789]])\n",
      "tensor([[ 0.5609, -0.1438]])\n",
      "tensor([[1.5680, 0.4234]])\n",
      "tensor([[ 1.6421, -0.8943]])\n",
      "tensor([[-0.7941,  0.4664]])\n",
      "tensor([[0.1175, 0.3250]])\n",
      "tensor([[1.8008, 0.6872]])\n",
      "tensor([[0.6502, 1.7645]])\n",
      "tensor([[1.1380, 0.4487]])\n",
      "Epoch[1/10] Loss: 0.166\n",
      "tensor([[ 0.3856, -0.7039]])\n",
      "tensor([[-1.3633,  1.7094]])\n",
      "tensor([[0.5162, 0.2504]])\n",
      "tensor([[-0.3882, -1.2009]])\n",
      "tensor([[ 1.3645, -1.4356]])\n",
      "tensor([[ 0.1899, -0.1279]])\n",
      "tensor([[-0.1703,  0.3811]])\n",
      "tensor([[-0.5088,  1.1314]])\n",
      "tensor([[-0.3583, -0.6868]])\n",
      "tensor([[-1.4966,  0.3839]])\n",
      "tensor([[1.0365, 1.8395]])\n",
      "tensor([[ 2.1008, -0.2866]])\n",
      "tensor([[ 0.6588, -0.3373]])\n",
      "tensor([[-0.6030,  0.6385]])\n",
      "tensor([[0.1296, 0.0315]])\n",
      "tensor([[-0.2712,  0.7284]])\n",
      "tensor([[-0.5364, -0.4562]])\n",
      "tensor([[0.5461, 1.1007]])\n",
      "tensor([[-0.5761, -1.8144]])\n",
      "tensor([[ 0.2817, -0.8831]])\n",
      "tensor([[ 0.7606, -0.1474]])\n",
      "tensor([[0.3272, 2.0065]])\n",
      "tensor([[0.0843, 0.8850]])\n",
      "tensor([[ 1.3511, -0.9638]])\n",
      "tensor([[0.5797, 0.9061]])\n",
      "tensor([[-0.6895,  1.2641]])\n",
      "tensor([[ 0.0874, -1.7588]])\n",
      "tensor([[ 0.1762, -0.3336]])\n",
      "tensor([[-0.0814, -0.5148]])\n",
      "tensor([[ 1.1927, -1.0551]])\n",
      "tensor([[0.8529, 0.4277]])\n",
      "tensor([[1.5413, 0.7100]])\n",
      "tensor([[-1.3876, -0.5430]])\n",
      "tensor([[0.5103, 2.5145]])\n",
      "tensor([[ 0.9812, -0.2655]])\n",
      "tensor([[-0.8790, -1.3719]])\n",
      "tensor([[0.4195, 0.3450]])\n",
      "tensor([[-2.8284,  0.4019]])\n",
      "tensor([[-1.3998, -0.9358]])\n",
      "tensor([[1.0071, 1.1524]])\n",
      "tensor([[-0.8843, -0.7670]])\n",
      "tensor([[-0.1462, -0.4422]])\n",
      "tensor([[0.2355, 0.5147]])\n",
      "tensor([[ 0.9144, -1.3494]])\n",
      "tensor([[-1.6882,  2.6072]])\n",
      "tensor([[-0.5620, -0.5815]])\n",
      "tensor([[ 1.9546, -0.3213]])\n",
      "tensor([[-1.1892, -1.8131]])\n",
      "tensor([[ 0.6042, -1.3100]])\n",
      "tensor([[-0.0626, -0.3398]])\n",
      "tensor([[ 0.8391, -0.7117]])\n",
      "tensor([[-0.6815, -0.3713]])\n",
      "tensor([[ 1.3506, -1.5751]])\n",
      "tensor([[0.2541, 1.3795]])\n",
      "tensor([[ 0.7860, -0.8345]])\n",
      "tensor([[-0.4511, -0.3892]])\n",
      "tensor([[-0.4555, -0.7182]])\n",
      "tensor([[0.4225, 1.4050]])\n",
      "tensor([[ 1.5332, -1.1485]])\n",
      "tensor([[1.3117, 1.8733]])\n",
      "tensor([[-1.2595, -0.0177]])\n",
      "tensor([[-1.3474,  0.5477]])\n",
      "tensor([[ 0.8447, -2.3405]])\n",
      "tensor([[-0.7168, -1.4838]])\n",
      "tensor([[0.5460, 1.0639]])\n",
      "tensor([[ 0.4682, -0.8854]])\n",
      "tensor([[-0.9193,  0.7010]])\n",
      "tensor([[0.0784, 0.0944]])\n",
      "tensor([[0.9699, 1.9119]])\n",
      "tensor([[-1.0401, -1.8709]])\n",
      "tensor([[ 0.3058, -0.9176]])\n",
      "tensor([[ 1.0686, -1.3405]])\n",
      "tensor([[2.0929, 1.3289]])\n",
      "tensor([[ 0.1405, -0.6953]])\n",
      "tensor([[ 0.1420, -0.5787]])\n",
      "tensor([[ 0.1958, -0.2367]])\n",
      "tensor([[-1.3880, -0.6769]])\n",
      "tensor([[ 0.6732, -0.1659]])\n",
      "tensor([[2.0776, 3.4714]])\n",
      "tensor([[-0.1796, -1.7829]])\n",
      "tensor([[ 0.2549, -0.7591]])\n",
      "tensor([[-0.7612, -0.0020]])\n",
      "tensor([[ 0.7710, -1.2682]])\n",
      "tensor([[-0.6038, -0.1129]])\n",
      "tensor([[ 0.1750, -1.4611]])\n",
      "tensor([[ 0.6269, -0.8493]])\n",
      "tensor([[-0.1997, -0.7064]])\n",
      "tensor([[-0.3895, -0.4382]])\n",
      "tensor([[1.9072, 1.3011]])\n",
      "tensor([[-0.8703, -1.1619]])\n",
      "tensor([[-0.4566, -0.1049]])\n",
      "tensor([[1.8761, 0.5448]])\n",
      "tensor([[1.0765, 0.8352]])\n",
      "tensor([[0.0966, 1.7265]])\n",
      "tensor([[-1.5547,  0.6524]])\n",
      "tensor([[-1.3603, -0.5832]])\n",
      "tensor([[ 1.6012, -0.3595]])\n",
      "tensor([[1.1004, 1.0201]])\n",
      "tensor([[0.1925, 1.1752]])\n",
      "tensor([[1.4367, 1.4201]])\n",
      "Epoch[1/10] Loss: 0.152\n",
      "tensor([[0.6468, 0.2117]])\n",
      "tensor([[0.0024, 1.0449]])\n",
      "tensor([[0.5592, 0.1657]])\n",
      "tensor([[-1.0225, -1.1053]])\n",
      "tensor([[-0.0792,  0.7554]])\n",
      "tensor([[-0.5280, -0.9208]])\n",
      "tensor([[-2.0948,  1.1576]])\n",
      "tensor([[-1.1912, -0.8239]])\n",
      "tensor([[-1.1023, -0.1887]])\n",
      "tensor([[-0.4244, -1.0269]])\n",
      "tensor([[-0.2117, -1.6249]])\n",
      "tensor([[ 0.4838, -0.4287]])\n",
      "tensor([[-0.8339,  0.2988]])\n",
      "tensor([[-0.2216, -0.8223]])\n",
      "tensor([[0.3069, 0.1395]])\n",
      "tensor([[ 1.6444, -1.7688]])\n",
      "tensor([[-0.3984, -0.1990]])\n",
      "tensor([[ 1.7944, -0.8643]])\n",
      "tensor([[0.0411, 1.3765]])\n",
      "tensor([[-1.0964, -0.5368]])\n",
      "tensor([[2.1890, 0.2693]])\n",
      "tensor([[1.3362, 0.1230]])\n",
      "tensor([[-2.5162,  0.6229]])\n",
      "tensor([[ 0.9603, -0.0562]])\n",
      "tensor([[ 0.6270, -0.2371]])\n",
      "tensor([[ 1.9018, -0.1903]])\n",
      "tensor([[-1.0891,  0.3595]])\n",
      "tensor([[-0.3000, -0.5821]])\n",
      "tensor([[-0.3579, -1.0761]])\n",
      "tensor([[-0.3442,  0.4051]])\n",
      "tensor([[0.2986, 1.2051]])\n",
      "tensor([[-0.4992,  2.0102]])\n",
      "tensor([[-0.4180,  0.6615]])\n",
      "tensor([[0.0125, 0.3037]])\n",
      "tensor([[-1.3928,  1.2810]])\n",
      "tensor([[-0.0508, -0.7516]])\n",
      "tensor([[ 1.0564, -1.4593]])\n",
      "tensor([[ 0.0285, -0.6045]])\n",
      "tensor([[-0.6281,  0.2021]])\n",
      "tensor([[-1.3554, -1.0951]])\n",
      "tensor([[ 0.4817, -0.5630]])\n",
      "tensor([[-0.6480,  0.4389]])\n",
      "tensor([[-1.0875,  0.3748]])\n",
      "tensor([[-1.7095, -0.5196]])\n",
      "tensor([[ 0.2518, -0.2822]])\n",
      "tensor([[1.0178, 0.8573]])\n",
      "tensor([[0.9745, 0.8839]])\n",
      "tensor([[-1.1128, -0.3455]])\n",
      "tensor([[-0.1473,  0.6865]])\n",
      "tensor([[-1.5242, -1.0873]])\n",
      "tensor([[-0.9120,  0.6981]])\n",
      "tensor([[ 0.3477, -0.2994]])\n",
      "tensor([[ 0.0298, -1.5150]])\n",
      "tensor([[-0.4170,  1.3827]])\n",
      "tensor([[0.0692, 1.9684]])\n",
      "tensor([[-0.1519, -0.4135]])\n",
      "tensor([[-0.7818,  0.1934]])\n",
      "tensor([[ 1.2391, -1.0607]])\n",
      "tensor([[-0.3640, -0.3931]])\n",
      "tensor([[1.1632, 0.9152]])\n",
      "tensor([[-0.7806, -0.9783]])\n",
      "tensor([[0.9438, 0.5386]])\n",
      "tensor([[ 1.6588, -0.4879]])\n",
      "tensor([[-0.5219, -0.8980]])\n",
      "tensor([[ 1.2577, -0.4911]])\n",
      "tensor([[0.6302, 1.4997]])\n",
      "tensor([[0.1704, 0.8443]])\n",
      "tensor([[-0.7404, -0.5536]])\n",
      "tensor([[-0.0793,  0.8080]])\n",
      "tensor([[-0.2461, -0.4042]])\n",
      "tensor([[1.2332, 1.5878]])\n",
      "tensor([[ 0.4081, -1.0135]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1026, 0.4877]])\n",
      "tensor([[0.5601, 0.6713]])\n",
      "tensor([[-0.1498, -1.3448]])\n",
      "tensor([[ 0.3370, -0.0179]])\n",
      "tensor([[-0.1574,  1.8885]])\n",
      "tensor([[0.0776, 0.6987]])\n",
      "tensor([[0.6357, 1.5100]])\n",
      "tensor([[ 0.0287, -1.1096]])\n",
      "tensor([[ 0.5639, -0.1453]])\n",
      "tensor([[-0.1378,  0.8376]])\n",
      "tensor([[-0.2269,  0.0916]])\n",
      "tensor([[-0.4807,  0.1771]])\n",
      "tensor([[ 0.5242, -0.6890]])\n",
      "tensor([[-0.5921,  0.5618]])\n",
      "tensor([[ 0.7849, -1.2766]])\n",
      "tensor([[-0.0046, -0.5193]])\n",
      "tensor([[-0.0032, -0.9102]])\n",
      "tensor([[0.8563, 0.8429]])\n",
      "tensor([[ 0.6560, -0.5863]])\n",
      "tensor([[-1.3507,  0.0207]])\n",
      "tensor([[-1.2168, -0.4404]])\n",
      "tensor([[-0.0374,  1.3053]])\n",
      "tensor([[-1.5292,  1.0239]])\n",
      "tensor([[-0.8803, -1.5437]])\n",
      "tensor([[-0.3324, -0.4013]])\n",
      "tensor([[-0.4317,  0.6255]])\n",
      "tensor([[-0.5338, -0.5182]])\n",
      "tensor([[0.5062, 1.9069]])\n",
      "Epoch[1/10] Loss: 0.162\n",
      "tensor([[ 0.3402, -0.7139]])\n",
      "tensor([[-1.2013, -0.6244]])\n",
      "tensor([[-1.2433, -0.0774]])\n",
      "tensor([[0.1745, 0.9429]])\n",
      "tensor([[ 2.3419, -0.7014]])\n",
      "tensor([[-1.9859, -0.0899]])\n",
      "tensor([[ 0.4564, -0.8431]])\n",
      "tensor([[-0.4336,  0.1838]])\n",
      "tensor([[ 0.3328, -0.9495]])\n",
      "tensor([[-0.8538, -0.7330]])\n",
      "tensor([[ 0.4089, -0.1932]])\n",
      "tensor([[1.3408, 0.9774]])\n",
      "tensor([[-0.8975,  0.7816]])\n",
      "tensor([[-1.5994, -0.8747]])\n",
      "tensor([[-0.2610,  1.1583]])\n",
      "tensor([[ 0.5884, -0.8534]])\n",
      "tensor([[ 0.7393, -0.9469]])\n",
      "tensor([[0.3534, 0.2593]])\n",
      "tensor([[ 0.1609, -0.1259]])\n",
      "tensor([[-0.2138, -1.1317]])\n",
      "tensor([[-0.0216,  1.5272]])\n",
      "tensor([[ 0.0047, -0.6531]])\n",
      "tensor([[0.3743, 0.1455]])\n",
      "tensor([[0.7604, 1.7815]])\n",
      "tensor([[-1.0310,  0.8893]])\n",
      "tensor([[ 0.5471, -0.5551]])\n",
      "tensor([[0.3242, 0.1313]])\n",
      "tensor([[ 2.7075, -0.8232]])\n",
      "tensor([[-1.1032,  0.7438]])\n",
      "tensor([[0.8920, 1.3717]])\n",
      "tensor([[0.2072, 0.4254]])\n",
      "tensor([[-0.7120,  0.0707]])\n",
      "tensor([[ 0.6360, -0.4199]])\n",
      "tensor([[0.2972, 0.6376]])\n",
      "tensor([[1.3668, 0.9548]])\n",
      "tensor([[-1.1265,  1.3662]])\n",
      "tensor([[ 0.5293, -0.6928]])\n",
      "tensor([[0.3769, 1.9738]])\n",
      "tensor([[ 2.4564, -1.0326]])\n",
      "tensor([[-0.7727, -1.4530]])\n",
      "tensor([[-1.2863, -1.3821]])\n",
      "tensor([[-0.0569, -1.3022]])\n",
      "tensor([[2.3692, 0.7554]])\n",
      "tensor([[-0.6091, -0.2151]])\n",
      "tensor([[ 0.8009, -0.9884]])\n",
      "tensor([[-1.0463, -0.7069]])\n",
      "tensor([[ 0.9359, -1.4033]])\n",
      "tensor([[-0.0169,  0.8963]])\n",
      "tensor([[1.3311, 0.5421]])\n",
      "tensor([[-0.0665,  0.0399]])\n",
      "tensor([[1.1444, 0.9155]])\n",
      "tensor([[0.8849, 0.2000]])\n",
      "tensor([[ 1.5899, -1.6051]])\n",
      "tensor([[ 0.5782, -0.8242]])\n",
      "tensor([[0.4004, 0.6459]])\n",
      "tensor([[ 0.2968, -1.1896]])\n",
      "tensor([[-0.6818,  0.1054]])\n",
      "tensor([[-1.0281, -1.0739]])\n",
      "tensor([[ 1.2045, -1.8212]])\n",
      "tensor([[-0.1290,  0.0481]])\n",
      "tensor([[-0.2169,  0.4909]])\n",
      "tensor([[3.9530e-04, 8.6842e-01]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Desktop\\NGAFID-REFERENCE\\NGAFID_Anomaly_Detection\\Charlie-Code\\real_demo_2.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[0mlocalX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m             \u001b[0mrecon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdemo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocalX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocalX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\NGAFID-REFERENCE\\NGAFID_Anomaly_Detection\\Charlie-Code\\real_demo_2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;31m#print(\"h: \" + str(h))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreparameterize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m         \u001b[1;31m#print(\"z: \" + str(z))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\NGAFID-REFERENCE\\NGAFID_Anomaly_Detection\\Charlie-Code\\real_demo_2.py\u001b[0m in \u001b[0;36mreparameterize\u001b[1;34m(self, mu, logvar)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#std dev and mu is avg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mesp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_var\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mesp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmu\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstd\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mesp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;31m# All strings are unicode in Python 3.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_str_intern\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m_str_intern\u001b[1;34m(inp)\u001b[0m\n\u001b[0;32m    379\u001b[0m                     \u001b[0mtensor_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m                     \u001b[0mtensor_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[1;34m(self, indent)\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[0mformatter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_add_suffixes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_newline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str_with_formatter\u001b[1;34m(self, indent, summarize, formatter1, formatter2)\u001b[0m\n\u001b[0;32m    213\u001b[0m                    for i in range(len(self) - PRINT_OPTS.edgeitems, len(self))])\n\u001b[0;32m    214\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m         slices = [_tensor_str_with_formatter(self[i], indent + 1, summarize, formatter1, formatter2)\n\u001b[0m\u001b[0;32m    216\u001b[0m                   for i in range(0, self.size(0))]\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    213\u001b[0m                    for i in range(len(self) - PRINT_OPTS.edgeitems, len(self))])\n\u001b[0;32m    214\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m         slices = [_tensor_str_with_formatter(self[i], indent + 1, summarize, formatter1, formatter2)\n\u001b[0m\u001b[0;32m    216\u001b[0m                   for i in range(0, self.size(0))]\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str_with_formatter\u001b[1;34m(self, indent, summarize, formatter1, formatter2)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_vector_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mPRINT_OPTS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medgeitems\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m_vector_str\u001b[1;34m(self, indent, summarize, formatter1, formatter2)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_vector_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;31m# length includes spaces and comma between elements\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m     \u001b[0melement_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformatter1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformatter2\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;31m# width for imag_formatter + an extra j for complex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run real_demo_2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263a1cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
