{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8250272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "from itertools import chain as chain\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import math\n",
    "\n",
    "\n",
    "cudaOn = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14af85d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "715057ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"C:/Users/Charlie/Downloads/NGAFID_MC_C37/NGAFID_MC_C37.csv\"\n",
    "data = pd.read_csv(data)\n",
    "data = data.fillna(0.0)\n",
    "\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "65eae22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['volt1', 'volt2', 'amp1', 'amp2', 'FQtyL', 'FQtyR', 'E1 FFlow',\n",
       "       'E1 OilT', 'E1 OilP', 'E1 RPM', 'E1 CHT1', 'E1 CHT2', 'E1 CHT3',\n",
       "       'E1 CHT4', 'E1 EGT1', 'E1 EGT2', 'E1 EGT3', 'E1 EGT4', 'OAT', 'IAS',\n",
       "       'VSpd', 'NormAc', 'AltMSL', 'id', 'plane_id', 'split', 'date_diff',\n",
       "       'before_after'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f03075b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('date_diff',axis=1)\n",
    "dataBefore = data[(data['before_after']==0)]\n",
    "dataAfter = data[(data['before_after']==1)]\n",
    "dataBefore = dataBefore.drop('before_after',axis=1)\n",
    "dataAfter = dataAfter.drop('before_after',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c817fe20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volt1</th>\n",
       "      <th>volt2</th>\n",
       "      <th>amp1</th>\n",
       "      <th>amp2</th>\n",
       "      <th>FQtyL</th>\n",
       "      <th>FQtyR</th>\n",
       "      <th>E1 FFlow</th>\n",
       "      <th>E1 OilT</th>\n",
       "      <th>E1 OilP</th>\n",
       "      <th>E1 RPM</th>\n",
       "      <th>...</th>\n",
       "      <th>E1 EGT3</th>\n",
       "      <th>E1 EGT4</th>\n",
       "      <th>OAT</th>\n",
       "      <th>IAS</th>\n",
       "      <th>VSpd</th>\n",
       "      <th>NormAc</th>\n",
       "      <th>AltMSL</th>\n",
       "      <th>id</th>\n",
       "      <th>plane_id</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18830</th>\n",
       "      <td>27.9</td>\n",
       "      <td>27.9</td>\n",
       "      <td>14.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>21.90</td>\n",
       "      <td>20.88</td>\n",
       "      <td>2.05</td>\n",
       "      <td>153.5</td>\n",
       "      <td>56.94</td>\n",
       "      <td>1172.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1144.0</td>\n",
       "      <td>1186.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-44.22</td>\n",
       "      <td>0.01</td>\n",
       "      <td>828.0</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18831</th>\n",
       "      <td>27.9</td>\n",
       "      <td>27.9</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>21.90</td>\n",
       "      <td>20.88</td>\n",
       "      <td>2.07</td>\n",
       "      <td>153.5</td>\n",
       "      <td>57.03</td>\n",
       "      <td>1179.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1144.0</td>\n",
       "      <td>1187.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-48.10</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>842.5</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18832</th>\n",
       "      <td>27.9</td>\n",
       "      <td>27.9</td>\n",
       "      <td>14.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>21.90</td>\n",
       "      <td>20.88</td>\n",
       "      <td>2.07</td>\n",
       "      <td>153.4</td>\n",
       "      <td>57.47</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>1191.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-29.27</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18833</th>\n",
       "      <td>27.9</td>\n",
       "      <td>27.9</td>\n",
       "      <td>13.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>21.90</td>\n",
       "      <td>20.84</td>\n",
       "      <td>2.08</td>\n",
       "      <td>153.4</td>\n",
       "      <td>57.00</td>\n",
       "      <td>1171.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1147.0</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.83</td>\n",
       "      <td>0.02</td>\n",
       "      <td>841.5</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18834</th>\n",
       "      <td>27.9</td>\n",
       "      <td>27.9</td>\n",
       "      <td>13.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>21.84</td>\n",
       "      <td>20.88</td>\n",
       "      <td>2.10</td>\n",
       "      <td>153.4</td>\n",
       "      <td>56.22</td>\n",
       "      <td>1147.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.45</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>842.0</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13408311</th>\n",
       "      <td>28.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>14.35</td>\n",
       "      <td>15.85</td>\n",
       "      <td>2.29</td>\n",
       "      <td>157.9</td>\n",
       "      <td>58.40</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1071.0</td>\n",
       "      <td>1104.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.50</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>708.0</td>\n",
       "      <td>6082</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13408312</th>\n",
       "      <td>28.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>14.35</td>\n",
       "      <td>15.80</td>\n",
       "      <td>2.34</td>\n",
       "      <td>157.9</td>\n",
       "      <td>58.38</td>\n",
       "      <td>1051.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>1103.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>708.0</td>\n",
       "      <td>6082</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13408313</th>\n",
       "      <td>28.1</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>14.47</td>\n",
       "      <td>15.75</td>\n",
       "      <td>2.25</td>\n",
       "      <td>157.9</td>\n",
       "      <td>58.22</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>1104.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.31</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>707.0</td>\n",
       "      <td>6082</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13408314</th>\n",
       "      <td>28.1</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>14.47</td>\n",
       "      <td>15.70</td>\n",
       "      <td>2.27</td>\n",
       "      <td>157.9</td>\n",
       "      <td>58.20</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>1105.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.01</td>\n",
       "      <td>707.5</td>\n",
       "      <td>6082</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13408315</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6082</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8110312 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          volt1  volt2  amp1  amp2  FQtyL  FQtyR  E1 FFlow  E1 OilT  E1 OilP  \\\n",
       "18830      27.9   27.9  14.1   0.5  21.90  20.88      2.05    153.5    56.94   \n",
       "18831      27.9   27.9  14.0   0.5  21.90  20.88      2.07    153.5    57.03   \n",
       "18832      27.9   27.9  14.1   0.5  21.90  20.88      2.07    153.4    57.47   \n",
       "18833      27.9   27.9  13.8   0.5  21.90  20.84      2.08    153.4    57.00   \n",
       "18834      27.9   27.9  13.9   0.5  21.84  20.88      2.10    153.4    56.22   \n",
       "...         ...    ...   ...   ...    ...    ...       ...      ...      ...   \n",
       "13408311   28.0   28.1   0.3  -0.1  14.35  15.85      2.29    157.9    58.40   \n",
       "13408312   28.0   28.1   0.3  -0.1  14.35  15.80      2.34    157.9    58.38   \n",
       "13408313   28.1   28.1   0.3  -0.1  14.47  15.75      2.25    157.9    58.22   \n",
       "13408314   28.1   28.1   0.3  -0.0  14.47  15.70      2.27    157.9    58.20   \n",
       "13408315    0.0    0.0   0.0   0.0   0.00   0.00      0.00      0.0     0.00   \n",
       "\n",
       "          E1 RPM  ...  E1 EGT3  E1 EGT4   OAT  IAS   VSpd  NormAc  AltMSL  \\\n",
       "18830     1172.0  ...   1144.0   1186.0  28.5  0.0 -44.22    0.01   828.0   \n",
       "18831     1179.0  ...   1144.0   1187.0  28.5  0.0 -48.10   -0.02   842.5   \n",
       "18832     1180.0  ...   1145.0   1191.0  28.5  0.0 -29.27    0.03     0.0   \n",
       "18833     1171.0  ...   1147.0   1192.0  28.5  0.0   8.83    0.02   841.5   \n",
       "18834     1147.0  ...   1150.0   1195.0  28.5  0.0  14.45   -0.01   842.0   \n",
       "...          ...  ...      ...      ...   ...  ...    ...     ...     ...   \n",
       "13408311  1054.0  ...   1071.0   1104.0  26.2  0.0  -4.50   -0.03   708.0   \n",
       "13408312  1051.0  ...   1072.0   1103.0  26.2  0.0  12.29    0.00   708.0   \n",
       "13408313  1050.0  ...   1072.0   1104.0  26.2  0.0  24.31   -0.01   707.0   \n",
       "13408314  1054.0  ...   1072.0   1105.0  26.2  0.0   2.90    0.01   707.5   \n",
       "13408315     0.0  ...      0.0      0.0   0.0  0.0   0.00    0.00     0.0   \n",
       "\n",
       "            id  plane_id  split  \n",
       "18830        5        56      0  \n",
       "18831        5        56      0  \n",
       "18832        5        56      0  \n",
       "18833        5        56      0  \n",
       "18834        5        56      0  \n",
       "...        ...       ...    ...  \n",
       "13408311  6082        43      1  \n",
       "13408312  6082        43      1  \n",
       "13408313  6082        43      1  \n",
       "13408314  6082        43      1  \n",
       "13408315  6082        43      1  \n",
       "\n",
       "[8110312 rows x 26 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataBefore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36b49699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volt1</th>\n",
       "      <th>volt2</th>\n",
       "      <th>amp1</th>\n",
       "      <th>amp2</th>\n",
       "      <th>FQtyL</th>\n",
       "      <th>FQtyR</th>\n",
       "      <th>E1 FFlow</th>\n",
       "      <th>E1 OilT</th>\n",
       "      <th>E1 OilP</th>\n",
       "      <th>E1 RPM</th>\n",
       "      <th>...</th>\n",
       "      <th>E1 EGT3</th>\n",
       "      <th>E1 EGT4</th>\n",
       "      <th>OAT</th>\n",
       "      <th>IAS</th>\n",
       "      <th>VSpd</th>\n",
       "      <th>NormAc</th>\n",
       "      <th>AltMSL</th>\n",
       "      <th>id</th>\n",
       "      <th>plane_id</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.9</td>\n",
       "      <td>27.9</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>24.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>2.09</td>\n",
       "      <td>129.2</td>\n",
       "      <td>61.16</td>\n",
       "      <td>1191.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1112.0</td>\n",
       "      <td>1255.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.74</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>822.5</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.9</td>\n",
       "      <td>27.9</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>24.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>2.13</td>\n",
       "      <td>129.2</td>\n",
       "      <td>61.20</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1114.0</td>\n",
       "      <td>1257.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.13</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>822.5</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.9</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>24.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>2.07</td>\n",
       "      <td>129.2</td>\n",
       "      <td>61.03</td>\n",
       "      <td>1186.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1119.0</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.9</td>\n",
       "      <td>27.9</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>24.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>2.12</td>\n",
       "      <td>129.2</td>\n",
       "      <td>61.16</td>\n",
       "      <td>1190.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>1267.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-30.64</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>824.5</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.9</td>\n",
       "      <td>27.9</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>24.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>129.1</td>\n",
       "      <td>61.25</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>1271.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-23.95</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>825.0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13414562</th>\n",
       "      <td>26.6</td>\n",
       "      <td>26.7</td>\n",
       "      <td>-6.7</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>14.81</td>\n",
       "      <td>19.02</td>\n",
       "      <td>1.26</td>\n",
       "      <td>152.2</td>\n",
       "      <td>52.60</td>\n",
       "      <td>764.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>989.5</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.91</td>\n",
       "      <td>0.06</td>\n",
       "      <td>836.0</td>\n",
       "      <td>6083</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13414563</th>\n",
       "      <td>26.5</td>\n",
       "      <td>26.6</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>14.81</td>\n",
       "      <td>19.02</td>\n",
       "      <td>1.28</td>\n",
       "      <td>152.2</td>\n",
       "      <td>52.72</td>\n",
       "      <td>771.5</td>\n",
       "      <td>...</td>\n",
       "      <td>998.5</td>\n",
       "      <td>988.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.54</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>836.0</td>\n",
       "      <td>6083</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13414564</th>\n",
       "      <td>26.4</td>\n",
       "      <td>26.5</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>14.81</td>\n",
       "      <td>19.02</td>\n",
       "      <td>1.25</td>\n",
       "      <td>152.2</td>\n",
       "      <td>52.66</td>\n",
       "      <td>770.0</td>\n",
       "      <td>...</td>\n",
       "      <td>995.0</td>\n",
       "      <td>987.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.99</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>836.0</td>\n",
       "      <td>6083</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13414565</th>\n",
       "      <td>26.3</td>\n",
       "      <td>26.4</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>14.86</td>\n",
       "      <td>19.05</td>\n",
       "      <td>1.26</td>\n",
       "      <td>152.2</td>\n",
       "      <td>52.66</td>\n",
       "      <td>769.0</td>\n",
       "      <td>...</td>\n",
       "      <td>990.5</td>\n",
       "      <td>986.5</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.91</td>\n",
       "      <td>0.03</td>\n",
       "      <td>836.0</td>\n",
       "      <td>6083</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13414566</th>\n",
       "      <td>26.2</td>\n",
       "      <td>26.3</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>14.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-13.47</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>836.5</td>\n",
       "      <td>6083</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5304255 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          volt1  volt2  amp1  amp2  FQtyL  FQtyR  E1 FFlow  E1 OilT  E1 OilP  \\\n",
       "0          27.9   27.9   7.9   0.7  24.00  24.00      2.09    129.2    61.16   \n",
       "1          27.9   27.9   7.9   0.6  24.00  24.00      2.13    129.2    61.20   \n",
       "2          27.9   28.0   8.0   0.6  24.00  24.00      2.07    129.2    61.03   \n",
       "3          27.9   27.9   7.8   0.6  24.00  24.00      2.12    129.2    61.16   \n",
       "4          27.9   27.9   7.7   0.6  24.00  24.00      2.08    129.1    61.25   \n",
       "...         ...    ...   ...   ...    ...    ...       ...      ...      ...   \n",
       "13414562   26.6   26.7  -6.7  -0.0  14.81  19.02      1.26    152.2    52.60   \n",
       "13414563   26.5   26.6  -5.9  -0.0  14.81  19.02      1.28    152.2    52.72   \n",
       "13414564   26.4   26.5  -5.3  -0.0  14.81  19.02      1.25    152.2    52.66   \n",
       "13414565   26.3   26.4  -4.8  -0.0  14.86  19.05      1.26    152.2    52.66   \n",
       "13414566   26.2   26.3  -4.8  -0.1  14.91   1.00      0.00      0.0     0.00   \n",
       "\n",
       "          E1 RPM  ...  E1 EGT3  E1 EGT4   OAT  IAS   VSpd  NormAc  AltMSL  \\\n",
       "0         1191.0  ...   1112.0   1255.0   7.2  0.0  15.74   -0.02   822.5   \n",
       "1         1192.0  ...   1114.0   1257.0   7.2  0.0  11.13   -0.00   822.5   \n",
       "2         1186.0  ...   1119.0   1261.0   7.2  0.0  -0.85    0.00     0.0   \n",
       "3         1190.0  ...   1125.0   1267.0   7.2  0.0 -30.64   -0.03   824.5   \n",
       "4         1197.0  ...   1129.0   1271.0   7.2  0.0 -23.95   -0.02   825.0   \n",
       "...          ...  ...      ...      ...   ...  ...    ...     ...     ...   \n",
       "13414562   764.5  ...   1001.0    989.5  19.5  0.0   5.91    0.06   836.0   \n",
       "13414563   771.5  ...    998.5    988.0  19.5  0.0  15.54   -0.02   836.0   \n",
       "13414564   770.0  ...    995.0    987.0  19.5  0.0  15.99   -0.01   836.0   \n",
       "13414565   769.0  ...    990.5    986.5  19.5  0.0   7.91    0.03   836.0   \n",
       "13414566     0.0  ...      0.0      0.0  19.5  0.0 -13.47   -0.02   836.5   \n",
       "\n",
       "            id  plane_id  split  \n",
       "0            2        18      4  \n",
       "1            2        18      4  \n",
       "2            2        18      4  \n",
       "3            2        18      4  \n",
       "4            2        18      4  \n",
       "...        ...       ...    ...  \n",
       "13414562  6083        19      0  \n",
       "13414563  6083        19      0  \n",
       "13414564  6083        19      0  \n",
       "13414565  6083        19      0  \n",
       "13414566  6083        19      0  \n",
       "\n",
       "[5304255 rows x 26 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataAfter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "708cace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "numVariables = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "23747611",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b45cd691",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split and reshape the data set by step_size , use min-max or stanrdardlize method to rescale the data\n",
    "def Splitting_dataset(data, step_size, scale=True, scaler_type=MinMaxScaler):\n",
    "        l = len(data) \n",
    "        data = scaler_type().fit_transform(data)\n",
    "        Xs = []\n",
    "        Ys = []\n",
    "        for i in range(0, (len(data) - step_size)):\n",
    "            Xs.append(data[i:i+step_size])\n",
    "            Ys.append(data[i:i+step_size])\n",
    "        train_x, test_x, train_y, test_y = [np.array(x) for x in train_test_split(Xs, Ys)]\n",
    "        assert train_x.shape[2] == test_x.shape[2] == (data.shape[1] if (type(data) == np.ndarray) else len(data))\n",
    "        return  (train_x.shape[2], train_x, train_y, test_x, test_y)\n",
    "    \n",
    "    \n",
    "def get_batch(x, batch_size):\n",
    "    \"\"\"Made with taking test_x or XX as input\"\"\"\n",
    "    #make stochastic\n",
    "    t = 0\n",
    "    while t >= 0:\n",
    "        x_mod = len(x) % batch_size\n",
    "        start = random.random() * (len(x)-x_mod)\n",
    "        start = int(start)\n",
    "        if start + batch_size < len(x):\n",
    "            t = t-1\n",
    "    batch = torch.tensor(x[start:(start+batch_size)]) #!! added tensor line\n",
    "    #print(batch.shape)\n",
    "    return batch\n",
    "\n",
    "\n",
    "def to_var(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x)\n",
    "\n",
    "\n",
    "def loss_fn(recon_x, x, mu, logvar):\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, size_average=True)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu**2 -  logvar.exp())\n",
    "    return BCE + KLD\n",
    "\n",
    "    \n",
    "def tep_testing_stepped(dat,step_size):\n",
    "    res = []\n",
    "    ind = 0\n",
    "    scale = MinMaxScaler().fit(dat)\n",
    "    dat = pd.DataFrame(scale.transform(dat))\n",
    "    for i in range(int((len(dat)/step_size))):\n",
    "        if ind + step_size < len(dat):\n",
    "            step = []\n",
    "            for j in range(step_size):\n",
    "              step.append(dat.iloc(0)[ind])\n",
    "              ind = ind + 1\n",
    "            res.append(step)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "450792c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4efa905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_size=784, h_dim=27, z_dim=31, n_flow_steps=1):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(image_size, h_dim),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(h_dim, z_dim*2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(z_dim, h_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h_dim, image_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        mu.double()\n",
    "        logvar.double()\n",
    "        std = logvar.mul(0.5).exp_() \n",
    "        esp = to_var(torch.randn(*mu.size()))\n",
    "        z = mu + std * esp\n",
    "        \n",
    "        return z\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu, logvar = torch.chunk(h, 2, dim=1)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        z = model(z)\n",
    "        tensorZ = torch.tensor(z[0])\n",
    "        \n",
    "        return self.decoder(tensorZ), mu, logvar\n",
    "    \n",
    "\n",
    "class stacked_NVP(nn.Module):\n",
    "    def __init__(self, d, k, hidden, n):\n",
    "        super().__init__()\n",
    "        self.bijectors = nn.ModuleList([\n",
    "            R_NVP(d, k, hidden=hidden) for _ in range(n)\n",
    "        ])\n",
    "        self.flips = [True if i%2 else False for i in range(n)]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        log_jacobs = []\n",
    "\n",
    "        for bijector, f in zip(self.bijectors, self.flips):\n",
    "            x, log_pz, lj = bijector(x, flip=f)\n",
    "            log_jacobs.append(lj)\n",
    "        \n",
    "        return x, log_pz, sum(log_jacobs)\n",
    "    \n",
    "    def inverse(self, z):\n",
    "        for bijector, f in zip(reversed(self.bijectors), reversed(self.flips)):\n",
    "            z = bijector.inverse(z, flip=f)\n",
    "        return z\n",
    "    \n",
    "    \n",
    "class R_NVP(nn.Module):\n",
    "    def __init__(self, d, k, hidden):\n",
    "        super().__init__()\n",
    "        self.d, self.k = d, k\n",
    "        self.sig_net = nn.Sequential(\n",
    "                    nn.Linear(k, hidden),\n",
    "                    nn.LeakyReLU(),\n",
    "                    nn.Linear(hidden, d - k))\n",
    "\n",
    "        self.mu_net = nn.Sequential(\n",
    "                    nn.Linear(k, hidden),\n",
    "                    nn.LeakyReLU(),\n",
    "                    nn.Linear(hidden, d - k))\n",
    "\n",
    "        \n",
    "    def forward(self, x, flip=False):\n",
    "        x1, x2 = x[:, :self.k], x[:, self.k:] \n",
    "        \n",
    "        if flip:\n",
    "            x2, x1 = x1, x2\n",
    "            \n",
    "        sig = self.sig_net(x1)\n",
    "        z1, z2 = x1, x2 * torch.exp(sig) + self.mu_net(x1)\n",
    "        \n",
    "        if flip:\n",
    "            z2, z1 = z1, z2\n",
    "\n",
    "        z_hat = torch.cat([z1, z2], dim=-1)\n",
    "\n",
    "        log_pz = base_dist.log_prob(z_hat)\n",
    "        log_jacob = sig.sum(-1)\n",
    "        \n",
    "        return z_hat, log_pz, log_jacob\n",
    "    \n",
    "    \n",
    "    def inverse(self, Z, flip=False):\n",
    "        z1, z2 = Z[:, :self.k], Z[:, self.k:] \n",
    "        \n",
    "        if flip:\n",
    "            z2, z1 = z1, z2\n",
    "        \n",
    "        x1 = z1\n",
    "        x2 = (z2 - self.mu_net(z1)) * torch.exp(-self.sig_net(z1))\n",
    "        \n",
    "        if flip:\n",
    "            x2, x1 = x1, x2\n",
    "        return torch.cat([x1, x2], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f5ed6676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e8932e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 3\n",
    "batch = 512\n",
    "index_step_length = numVariables\n",
    "epochs = 20\n",
    "\n",
    "num = 5\n",
    "\n",
    "d = numVariables\n",
    "k = int(numVariables/2)\n",
    "\n",
    "base_mu, base_cov = torch.zeros(numVariables), torch.eye(numVariables)\n",
    "\n",
    "base_mu = torch.nn.parameter.Parameter(to_var(base_mu.double()))\n",
    "base_cov = torch.nn.parameter.Parameter(to_var(base_cov.double()))\n",
    "\n",
    "base_dist = MultivariateNormal(base_mu, base_cov)\n",
    "#---------------------------------------------------------------------------------------------------------------------------------\n",
    "labels, X, Y, XX, YY = Splitting_dataset(dataAfter, step_size)\n",
    "\n",
    "demo = VAE(index_step_length,h_dim=13,z_dim=numVariables)\n",
    "model = stacked_NVP(d, k, hidden=512,n=num)\n",
    "demo.double()\n",
    "model.double()\n",
    "    \n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-3)\n",
    "optimizer2 = torch.optim.Adam(demo.parameters(), lr=1e-3)\n",
    "optimizer3 = torch.optim.RMSprop([base_mu,base_cov], lr=1e-3)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fda6b3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "191093b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charlie\\AppData\\Local\\Temp/ipykernel_29272/2088469916.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  localX = to_var(torch.tensor(b[i]))\n",
      "C:\\Users\\Charlie\\AppData\\Local\\Temp/ipykernel_29272/3844283621.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tensorZ = torch.tensor(z[0])\n",
      "C:\\Users\\Charlie\\anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/20] Loss: 0.001\n",
      "Epoch[1/20] Loss: 0.001\n",
      "Epoch[1/20] Loss: 0.001\n",
      "Epoch[1/20] Loss: 0.001\n",
      "Epoch[1/20] Loss: 0.001\n",
      "Epoch[2/20] Loss: 0.001\n",
      "Epoch[2/20] Loss: 0.001\n",
      "Epoch[2/20] Loss: 0.001\n",
      "Epoch[2/20] Loss: 0.001\n",
      "Epoch[2/20] Loss: 0.001\n",
      "Epoch[3/20] Loss: 0.001\n",
      "Epoch[3/20] Loss: 0.001\n",
      "Epoch[3/20] Loss: 0.001\n",
      "Epoch[3/20] Loss: 0.001\n",
      "Epoch[3/20] Loss: 0.001\n",
      "Epoch[4/20] Loss: 0.001\n",
      "Epoch[4/20] Loss: 0.001\n",
      "Epoch[4/20] Loss: 0.001\n",
      "Epoch[4/20] Loss: 0.001\n",
      "Epoch[4/20] Loss: 0.001\n",
      "Epoch[5/20] Loss: 0.001\n",
      "Epoch[5/20] Loss: 0.001\n",
      "Epoch[5/20] Loss: 0.001\n",
      "Epoch[5/20] Loss: 0.001\n",
      "Epoch[5/20] Loss: 0.001\n",
      "Epoch[6/20] Loss: 0.001\n",
      "Epoch[6/20] Loss: 0.001\n",
      "Epoch[6/20] Loss: 0.001\n",
      "Epoch[6/20] Loss: 0.001\n",
      "Epoch[6/20] Loss: 0.001\n",
      "Epoch[7/20] Loss: 0.001\n",
      "Epoch[7/20] Loss: 0.001\n",
      "Epoch[7/20] Loss: 0.001\n",
      "Epoch[7/20] Loss: 0.001\n",
      "Epoch[7/20] Loss: 0.001\n",
      "Epoch[8/20] Loss: 0.001\n",
      "Epoch[8/20] Loss: 0.001\n",
      "Epoch[8/20] Loss: 0.001\n",
      "Epoch[8/20] Loss: 0.001\n",
      "Epoch[8/20] Loss: 0.001\n",
      "Epoch[9/20] Loss: 0.001\n",
      "Epoch[9/20] Loss: 0.001\n",
      "Epoch[9/20] Loss: 0.001\n",
      "Epoch[9/20] Loss: 0.001\n",
      "Epoch[9/20] Loss: 0.001\n",
      "Epoch[9/20] Loss: 0.001\n",
      "Epoch[10/20] Loss: 0.001\n",
      "Epoch[10/20] Loss: 0.001\n",
      "Epoch[10/20] Loss: 0.001\n",
      "Epoch[10/20] Loss: 0.001\n",
      "Epoch[10/20] Loss: 0.001\n",
      "Epoch[11/20] Loss: 0.001\n",
      "Epoch[11/20] Loss: 0.001\n",
      "Epoch[11/20] Loss: 0.001\n",
      "Epoch[11/20] Loss: 0.001\n",
      "Epoch[11/20] Loss: 0.001\n",
      "Epoch[12/20] Loss: 0.001\n",
      "Epoch[12/20] Loss: 0.001\n",
      "Epoch[12/20] Loss: 0.001\n",
      "Epoch[12/20] Loss: 0.001\n",
      "Epoch[12/20] Loss: 0.001\n",
      "Epoch[13/20] Loss: 0.001\n",
      "Epoch[13/20] Loss: 0.001\n",
      "Epoch[13/20] Loss: 0.001\n",
      "Epoch[13/20] Loss: 0.001\n",
      "Epoch[13/20] Loss: 0.001\n",
      "Epoch[14/20] Loss: 0.001\n",
      "Epoch[14/20] Loss: 0.001\n",
      "Epoch[14/20] Loss: 0.001\n",
      "Epoch[14/20] Loss: 0.001\n",
      "Epoch[14/20] Loss: 0.001\n",
      "Epoch[15/20] Loss: 0.001\n",
      "Epoch[15/20] Loss: 0.001\n",
      "Epoch[15/20] Loss: 0.001\n",
      "Epoch[15/20] Loss: 0.001\n",
      "Epoch[15/20] Loss: 0.001\n",
      "Epoch[16/20] Loss: 0.001\n",
      "Epoch[16/20] Loss: 0.001\n",
      "Epoch[16/20] Loss: 0.001\n",
      "Epoch[16/20] Loss: 0.001\n",
      "Epoch[16/20] Loss: 0.001\n",
      "Epoch[17/20] Loss: 0.001\n",
      "Epoch[17/20] Loss: 0.001\n",
      "Epoch[17/20] Loss: 0.001\n",
      "Epoch[17/20] Loss: 0.001\n",
      "Epoch[17/20] Loss: 0.001\n",
      "Epoch[17/20] Loss: 0.001\n",
      "Epoch[18/20] Loss: 0.001\n",
      "Epoch[18/20] Loss: 0.001\n",
      "Epoch[18/20] Loss: 0.001\n",
      "Epoch[18/20] Loss: 0.001\n",
      "Epoch[18/20] Loss: 0.001\n",
      "Epoch[19/20] Loss: 0.001\n",
      "Epoch[19/20] Loss: 0.001\n",
      "Epoch[19/20] Loss: 0.001\n",
      "Epoch[19/20] Loss: 0.001\n",
      "Epoch[19/20] Loss: 0.001\n",
      "Epoch[20/20] Loss: 0.001\n",
      "Epoch[20/20] Loss: 0.001\n",
      "Epoch[20/20] Loss: 0.001\n",
      "Epoch[20/20] Loss: 0.001\n",
      "Epoch[20/20] Loss: 0.001\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "\n",
    "anomaly_history = []\n",
    "loss_history = []\n",
    "avgSum = 0\n",
    "avgCount = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    b = get_batch(X,batch)\n",
    "    \n",
    "    for i in range(batch):\n",
    "        optimizer.zero_grad()\n",
    "        optimizer2.zero_grad()\n",
    "        optimizer3.zero_grad()\n",
    "        localX = to_var(torch.tensor(b[i]))\n",
    "        recon, mu, logvar = demo(localX)\n",
    "        loss = loss_fn(recon, localX, mu, logvar) #doing kl-divergence loss correctly\n",
    "        \"\"\"This bound (kl loss) provides a unified objective function for \n",
    "        op-timization of both the parameters θ and φ of the model and variational approximation, respectively.\"\"\"\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer2.step()\n",
    "        optimizer3.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        idx = idx + 1\n",
    "\n",
    "        avgSum = avgSum + torch.mean(loss/batch)\n",
    "        avgCount = avgCount + 1\n",
    "        anomaly_score = abs(torch.mean(localX-recon))\n",
    "\n",
    "        if idx%step_size == 0:\n",
    "            loss_history.append(avgSum/avgCount)\n",
    "            anomaly_history.append(anomaly_score)\n",
    "            avgSum = 0\n",
    "            avgCount = 0\n",
    "\n",
    "        if idx%100 == 0:\n",
    "            print(\"Epoch[{}/{}] Loss: {:.3f}\".format(epoch+1, epochs, loss.data.item()/batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a83b47fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x277a5af1ac0>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = plt.figure()\n",
    "plt.plot(loss_history,'g-',label='h 10,z 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "96acd88b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 26)) while a minimum of 1 is required by MinMaxScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29272/366307740.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataAfter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataAfter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#print(test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mstepped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtep_testing_stepped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29272/224010676.py\u001b[0m in \u001b[0;36mtep_testing_stepped\u001b[1;34m(dat, step_size)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mscale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[0mdat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[0mfirst_pass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'n_samples_seen_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m         X = self._validate_data(X, reset=first_pass,\n\u001b[0m\u001b[0;32m    397\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m                                 force_all_finite=\"allow-nan\")\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'no_validation'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 726\u001b[1;33m             raise ValueError(\"Found array with %d sample(s) (shape=%s) while a\"\n\u001b[0m\u001b[0;32m    727\u001b[0m                              \u001b[1;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 26)) while a minimum of 1 is required by MinMaxScaler."
     ]
    }
   ],
   "source": [
    "#test = dataBefore[0:50000]\n",
    "test = dataAfter[(dataAfter['id']==5)]\n",
    "print(dataAfter)\n",
    "stepped = tep_testing_stepped(test,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6334c877",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charlie\\AppData\\Local\\Temp/ipykernel_29272/3844283621.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tensorZ = torch.tensor(z[0])\n",
      "C:\\Users\\Charlie\\AppData\\Local\\Temp/ipykernel_29272/442245058.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  anomalies.append(torch.tensor(anom))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x275a1c74f70>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fileLoc = \"C:/Users/Charlie/Desktop/picsForDemo2/tepGeneratedLast/NGAFID_Test/demoResult.png\"\n",
    "\n",
    "step_start = 0\n",
    "anomalies = []\n",
    "y_nomalies = []\n",
    "vals = []\n",
    "pred_vals = []\n",
    "county = 0\n",
    "start = 0\n",
    "view = []\n",
    "for step in stepped:    \n",
    "    step = torch.tensor(step)\n",
    "    step = step.double()\n",
    "    recon,_,_ = demo(step)\n",
    "    for j in range(len(step)):\n",
    "        a = (recon[0][j] - step[0][j])\n",
    "        anom = a**2\n",
    "        anomalies.append(torch.tensor(anom))\n",
    "        pred_vals.append(torch.mean(recon))\n",
    "        vals.append(torch.mean(step))\n",
    "        step_start = step_start + 1\n",
    "        county = county + 1\n",
    "    for a in anomalies:\n",
    "        if start+1 < len(anomalies):\n",
    "            view.append(abs(anomalies[start+1].item() - a.item()))  \n",
    "            start = start + 1\n",
    "            \n",
    "p3 = plt.figure()\n",
    "plt.plot(anomalies, 'g-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd9b5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a88e781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b3cf57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d681334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
