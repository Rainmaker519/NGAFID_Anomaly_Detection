{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8250272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.autograd import Variable\n",
    "#import torch.cuda\n",
    "import random\n",
    "from itertools import chain as chain\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import math\n",
    "\n",
    "#conda activate base\n",
    "cudaOn = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14af85d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "715057ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tepLoc = \"C:/Users/Charlie/Desktop/TEP_Data/\"\n",
    "\n",
    "#tepTrain = tepLoc + \"TEP_Faulty_Training.csv\"\n",
    "#tepTrain = tepLoc + \"TEP_FaultFree_Training.csv\"\n",
    "\n",
    "#tepTest = tepLoc + \"TEP_FaultFree_Testing.csv\"\n",
    "#tepTest = tepLoc + \"TEP_Faulty_Testing.csv\"\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#data = pd.read_csv('c172_file_1.csv')\n",
    "#data = pd.read_csv(tepTrain)\n",
    "#dataTest = pd.read_csv(tepTest)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = \"C:/Users/Charlie/Downloads/NGAFID_MC_C37/NGAFID_MC_C37.csv\"\n",
    "data = pd.read_csv(data)\n",
    "data = data.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "65eae22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volt1</th>\n",
       "      <th>volt2</th>\n",
       "      <th>amp1</th>\n",
       "      <th>amp2</th>\n",
       "      <th>FQtyL</th>\n",
       "      <th>FQtyR</th>\n",
       "      <th>E1 FFlow</th>\n",
       "      <th>E1 OilT</th>\n",
       "      <th>E1 OilP</th>\n",
       "      <th>E1 RPM</th>\n",
       "      <th>...</th>\n",
       "      <th>OAT</th>\n",
       "      <th>IAS</th>\n",
       "      <th>VSpd</th>\n",
       "      <th>NormAc</th>\n",
       "      <th>AltMSL</th>\n",
       "      <th>id</th>\n",
       "      <th>plane_id</th>\n",
       "      <th>split</th>\n",
       "      <th>date_diff</th>\n",
       "      <th>before_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.9</td>\n",
       "      <td>27.9</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>24.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>2.09</td>\n",
       "      <td>129.2</td>\n",
       "      <td>61.16</td>\n",
       "      <td>1191.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.74</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>822.5</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.9</td>\n",
       "      <td>27.9</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>24.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>2.13</td>\n",
       "      <td>129.2</td>\n",
       "      <td>61.20</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.13</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>822.5</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.9</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>24.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>2.07</td>\n",
       "      <td>129.2</td>\n",
       "      <td>61.03</td>\n",
       "      <td>1186.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.9</td>\n",
       "      <td>27.9</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>24.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>2.12</td>\n",
       "      <td>129.2</td>\n",
       "      <td>61.16</td>\n",
       "      <td>1190.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-30.64</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>824.5</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.9</td>\n",
       "      <td>27.9</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>24.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>129.1</td>\n",
       "      <td>61.25</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-23.95</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>825.0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13414562</th>\n",
       "      <td>26.6</td>\n",
       "      <td>26.7</td>\n",
       "      <td>-6.7</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>14.81</td>\n",
       "      <td>19.02</td>\n",
       "      <td>1.26</td>\n",
       "      <td>152.2</td>\n",
       "      <td>52.60</td>\n",
       "      <td>764.5</td>\n",
       "      <td>...</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.91</td>\n",
       "      <td>0.06</td>\n",
       "      <td>836.0</td>\n",
       "      <td>6083</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13414563</th>\n",
       "      <td>26.5</td>\n",
       "      <td>26.6</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>14.81</td>\n",
       "      <td>19.02</td>\n",
       "      <td>1.28</td>\n",
       "      <td>152.2</td>\n",
       "      <td>52.72</td>\n",
       "      <td>771.5</td>\n",
       "      <td>...</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.54</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>836.0</td>\n",
       "      <td>6083</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13414564</th>\n",
       "      <td>26.4</td>\n",
       "      <td>26.5</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>14.81</td>\n",
       "      <td>19.02</td>\n",
       "      <td>1.25</td>\n",
       "      <td>152.2</td>\n",
       "      <td>52.66</td>\n",
       "      <td>770.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.99</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>836.0</td>\n",
       "      <td>6083</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13414565</th>\n",
       "      <td>26.3</td>\n",
       "      <td>26.4</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>14.86</td>\n",
       "      <td>19.05</td>\n",
       "      <td>1.26</td>\n",
       "      <td>152.2</td>\n",
       "      <td>52.66</td>\n",
       "      <td>769.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.91</td>\n",
       "      <td>0.03</td>\n",
       "      <td>836.0</td>\n",
       "      <td>6083</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13414566</th>\n",
       "      <td>26.2</td>\n",
       "      <td>26.3</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>14.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-13.47</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>836.5</td>\n",
       "      <td>6083</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13414567 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          volt1  volt2  amp1  amp2  FQtyL  FQtyR  E1 FFlow  E1 OilT  E1 OilP  \\\n",
       "0          27.9   27.9   7.9   0.7  24.00  24.00      2.09    129.2    61.16   \n",
       "1          27.9   27.9   7.9   0.6  24.00  24.00      2.13    129.2    61.20   \n",
       "2          27.9   28.0   8.0   0.6  24.00  24.00      2.07    129.2    61.03   \n",
       "3          27.9   27.9   7.8   0.6  24.00  24.00      2.12    129.2    61.16   \n",
       "4          27.9   27.9   7.7   0.6  24.00  24.00      2.08    129.1    61.25   \n",
       "...         ...    ...   ...   ...    ...    ...       ...      ...      ...   \n",
       "13414562   26.6   26.7  -6.7  -0.0  14.81  19.02      1.26    152.2    52.60   \n",
       "13414563   26.5   26.6  -5.9  -0.0  14.81  19.02      1.28    152.2    52.72   \n",
       "13414564   26.4   26.5  -5.3  -0.0  14.81  19.02      1.25    152.2    52.66   \n",
       "13414565   26.3   26.4  -4.8  -0.0  14.86  19.05      1.26    152.2    52.66   \n",
       "13414566   26.2   26.3  -4.8  -0.1  14.91   1.00      0.00      0.0     0.00   \n",
       "\n",
       "          E1 RPM  ...   OAT  IAS   VSpd  NormAc  AltMSL    id  plane_id  \\\n",
       "0         1191.0  ...   7.2  0.0  15.74   -0.02   822.5     2        18   \n",
       "1         1192.0  ...   7.2  0.0  11.13   -0.00   822.5     2        18   \n",
       "2         1186.0  ...   7.2  0.0  -0.85    0.00     0.0     2        18   \n",
       "3         1190.0  ...   7.2  0.0 -30.64   -0.03   824.5     2        18   \n",
       "4         1197.0  ...   7.2  0.0 -23.95   -0.02   825.0     2        18   \n",
       "...          ...  ...   ...  ...    ...     ...     ...   ...       ...   \n",
       "13414562   764.5  ...  19.5  0.0   5.91    0.06   836.0  6083        19   \n",
       "13414563   771.5  ...  19.5  0.0  15.54   -0.02   836.0  6083        19   \n",
       "13414564   770.0  ...  19.5  0.0  15.99   -0.01   836.0  6083        19   \n",
       "13414565   769.0  ...  19.5  0.0   7.91    0.03   836.0  6083        19   \n",
       "13414566     0.0  ...  19.5  0.0 -13.47   -0.02   836.5  6083        19   \n",
       "\n",
       "          split  date_diff  before_after  \n",
       "0             4         -2             1  \n",
       "1             4         -2             1  \n",
       "2             4         -2             1  \n",
       "3             4         -2             1  \n",
       "4             4         -2             1  \n",
       "...         ...        ...           ...  \n",
       "13414562      0         -1             1  \n",
       "13414563      0         -1             1  \n",
       "13414564      0         -1             1  \n",
       "13414565      0         -1             1  \n",
       "13414566      0         -1             1  \n",
       "\n",
       "[13414567 rows x 28 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lookie = dataTest[dataTest['simulationRun']==112]\n",
    "#print(lookie[lookie['faultNumber']==5])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f03075b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volt1</th>\n",
       "      <th>volt2</th>\n",
       "      <th>amp1</th>\n",
       "      <th>amp2</th>\n",
       "      <th>FQtyL</th>\n",
       "      <th>FQtyR</th>\n",
       "      <th>E1 FFlow</th>\n",
       "      <th>E1 OilT</th>\n",
       "      <th>E1 OilP</th>\n",
       "      <th>E1 RPM</th>\n",
       "      <th>...</th>\n",
       "      <th>E1 EGT3</th>\n",
       "      <th>E1 EGT4</th>\n",
       "      <th>OAT</th>\n",
       "      <th>IAS</th>\n",
       "      <th>VSpd</th>\n",
       "      <th>NormAc</th>\n",
       "      <th>AltMSL</th>\n",
       "      <th>id</th>\n",
       "      <th>plane_id</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.9</td>\n",
       "      <td>27.9</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>24.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>2.09</td>\n",
       "      <td>129.2</td>\n",
       "      <td>61.16</td>\n",
       "      <td>1191.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1112.0</td>\n",
       "      <td>1255.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.74</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>822.5</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.9</td>\n",
       "      <td>27.9</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>24.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>2.13</td>\n",
       "      <td>129.2</td>\n",
       "      <td>61.20</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1114.0</td>\n",
       "      <td>1257.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.13</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>822.5</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.9</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>24.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>2.07</td>\n",
       "      <td>129.2</td>\n",
       "      <td>61.03</td>\n",
       "      <td>1186.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1119.0</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.9</td>\n",
       "      <td>27.9</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>24.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>2.12</td>\n",
       "      <td>129.2</td>\n",
       "      <td>61.16</td>\n",
       "      <td>1190.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>1267.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-30.64</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>824.5</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.9</td>\n",
       "      <td>27.9</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>24.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>129.1</td>\n",
       "      <td>61.25</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>1271.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-23.95</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>825.0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13414562</th>\n",
       "      <td>26.6</td>\n",
       "      <td>26.7</td>\n",
       "      <td>-6.7</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>14.81</td>\n",
       "      <td>19.02</td>\n",
       "      <td>1.26</td>\n",
       "      <td>152.2</td>\n",
       "      <td>52.60</td>\n",
       "      <td>764.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>989.5</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.91</td>\n",
       "      <td>0.06</td>\n",
       "      <td>836.0</td>\n",
       "      <td>6083</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13414563</th>\n",
       "      <td>26.5</td>\n",
       "      <td>26.6</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>14.81</td>\n",
       "      <td>19.02</td>\n",
       "      <td>1.28</td>\n",
       "      <td>152.2</td>\n",
       "      <td>52.72</td>\n",
       "      <td>771.5</td>\n",
       "      <td>...</td>\n",
       "      <td>998.5</td>\n",
       "      <td>988.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.54</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>836.0</td>\n",
       "      <td>6083</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13414564</th>\n",
       "      <td>26.4</td>\n",
       "      <td>26.5</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>14.81</td>\n",
       "      <td>19.02</td>\n",
       "      <td>1.25</td>\n",
       "      <td>152.2</td>\n",
       "      <td>52.66</td>\n",
       "      <td>770.0</td>\n",
       "      <td>...</td>\n",
       "      <td>995.0</td>\n",
       "      <td>987.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.99</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>836.0</td>\n",
       "      <td>6083</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13414565</th>\n",
       "      <td>26.3</td>\n",
       "      <td>26.4</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>14.86</td>\n",
       "      <td>19.05</td>\n",
       "      <td>1.26</td>\n",
       "      <td>152.2</td>\n",
       "      <td>52.66</td>\n",
       "      <td>769.0</td>\n",
       "      <td>...</td>\n",
       "      <td>990.5</td>\n",
       "      <td>986.5</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.91</td>\n",
       "      <td>0.03</td>\n",
       "      <td>836.0</td>\n",
       "      <td>6083</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13414566</th>\n",
       "      <td>26.2</td>\n",
       "      <td>26.3</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>14.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-13.47</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>836.5</td>\n",
       "      <td>6083</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13414567 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          volt1  volt2  amp1  amp2  FQtyL  FQtyR  E1 FFlow  E1 OilT  E1 OilP  \\\n",
       "0          27.9   27.9   7.9   0.7  24.00  24.00      2.09    129.2    61.16   \n",
       "1          27.9   27.9   7.9   0.6  24.00  24.00      2.13    129.2    61.20   \n",
       "2          27.9   28.0   8.0   0.6  24.00  24.00      2.07    129.2    61.03   \n",
       "3          27.9   27.9   7.8   0.6  24.00  24.00      2.12    129.2    61.16   \n",
       "4          27.9   27.9   7.7   0.6  24.00  24.00      2.08    129.1    61.25   \n",
       "...         ...    ...   ...   ...    ...    ...       ...      ...      ...   \n",
       "13414562   26.6   26.7  -6.7  -0.0  14.81  19.02      1.26    152.2    52.60   \n",
       "13414563   26.5   26.6  -5.9  -0.0  14.81  19.02      1.28    152.2    52.72   \n",
       "13414564   26.4   26.5  -5.3  -0.0  14.81  19.02      1.25    152.2    52.66   \n",
       "13414565   26.3   26.4  -4.8  -0.0  14.86  19.05      1.26    152.2    52.66   \n",
       "13414566   26.2   26.3  -4.8  -0.1  14.91   1.00      0.00      0.0     0.00   \n",
       "\n",
       "          E1 RPM  ...  E1 EGT3  E1 EGT4   OAT  IAS   VSpd  NormAc  AltMSL  \\\n",
       "0         1191.0  ...   1112.0   1255.0   7.2  0.0  15.74   -0.02   822.5   \n",
       "1         1192.0  ...   1114.0   1257.0   7.2  0.0  11.13   -0.00   822.5   \n",
       "2         1186.0  ...   1119.0   1261.0   7.2  0.0  -0.85    0.00     0.0   \n",
       "3         1190.0  ...   1125.0   1267.0   7.2  0.0 -30.64   -0.03   824.5   \n",
       "4         1197.0  ...   1129.0   1271.0   7.2  0.0 -23.95   -0.02   825.0   \n",
       "...          ...  ...      ...      ...   ...  ...    ...     ...     ...   \n",
       "13414562   764.5  ...   1001.0    989.5  19.5  0.0   5.91    0.06   836.0   \n",
       "13414563   771.5  ...    998.5    988.0  19.5  0.0  15.54   -0.02   836.0   \n",
       "13414564   770.0  ...    995.0    987.0  19.5  0.0  15.99   -0.01   836.0   \n",
       "13414565   769.0  ...    990.5    986.5  19.5  0.0   7.91    0.03   836.0   \n",
       "13414566     0.0  ...      0.0      0.0  19.5  0.0 -13.47   -0.02   836.5   \n",
       "\n",
       "            id  plane_id  split  \n",
       "0            2        18      4  \n",
       "1            2        18      4  \n",
       "2            2        18      4  \n",
       "3            2        18      4  \n",
       "4            2        18      4  \n",
       "...        ...       ...    ...  \n",
       "13414562  6083        19      0  \n",
       "13414563  6083        19      0  \n",
       "13414564  6083        19      0  \n",
       "13414565  6083        19      0  \n",
       "13414566  6083        19      0  \n",
       "\n",
       "[13414567 rows x 26 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = data.drop('Unnamed: 0',axis=1)\n",
    "data = data.drop('before_after',axis=1)\n",
    "data = data.drop('date_diff',axis=1)\n",
    "#data = data.drop('simulationRun',axis=1)\n",
    "#data = data.drop('sample',axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c817fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataTest = dataTest[dataTest['simulationRun']==218]\n",
    "#faultNumbersT = dataTest.get('faultNumber')\n",
    "#\n",
    "#dataTest = dataTest.drop('Unnamed: 0',axis=1)\n",
    "#dataTest = dataTest.drop('faultNumber',axis=1)\n",
    "#dataTest = dataTest.drop('simulationRun',axis=1)\n",
    "#dataTest = dataTest.drop('sample',axis=1)\n",
    "#dataTest = data\n",
    "#dataTest = dataTest.iloc(0)[0:19500] #test A and B\n",
    "#dataTest = dataTest.iloc(0)[19500:38500] #test C and D\n",
    "#dataTest = dataTest.iloc(0)[39000:58000]\n",
    "\n",
    "#faultNumbersTest = []\n",
    "#for i in faultNumbersT:\n",
    "    #faultNumbersTest.append(i)\n",
    "\n",
    "#data = data.astype('float64')\n",
    "#dataTest = dataTest.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "36b49699",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_length = 960\n",
    "#num = 960\n",
    "#for i in range(int(len(faultNumbersTest)/run_length)):\n",
    "    #print(str(i*run_length) + \": \" + str(faultNumbersTest[i*run_length]))\n",
    "#print(faultNumbersTest[10000:10100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "708cace7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          volt1  volt2  amp1  amp2  FQtyL  FQtyR  E1 FFlow  E1 OilT  E1 OilP  \\\n",
      "0          27.9   27.9   7.9   0.7  24.00  24.00      2.09    129.2    61.16   \n",
      "1          27.9   27.9   7.9   0.6  24.00  24.00      2.13    129.2    61.20   \n",
      "2          27.9   28.0   8.0   0.6  24.00  24.00      2.07    129.2    61.03   \n",
      "3          27.9   27.9   7.8   0.6  24.00  24.00      2.12    129.2    61.16   \n",
      "4          27.9   27.9   7.7   0.6  24.00  24.00      2.08    129.1    61.25   \n",
      "...         ...    ...   ...   ...    ...    ...       ...      ...      ...   \n",
      "13414562   26.6   26.7  -6.7  -0.0  14.81  19.02      1.26    152.2    52.60   \n",
      "13414563   26.5   26.6  -5.9  -0.0  14.81  19.02      1.28    152.2    52.72   \n",
      "13414564   26.4   26.5  -5.3  -0.0  14.81  19.02      1.25    152.2    52.66   \n",
      "13414565   26.3   26.4  -4.8  -0.0  14.86  19.05      1.26    152.2    52.66   \n",
      "13414566   26.2   26.3  -4.8  -0.1  14.91   1.00      0.00      0.0     0.00   \n",
      "\n",
      "          E1 RPM  ...  E1 EGT3  E1 EGT4   OAT  IAS   VSpd  NormAc  AltMSL  \\\n",
      "0         1191.0  ...   1112.0   1255.0   7.2  0.0  15.74   -0.02   822.5   \n",
      "1         1192.0  ...   1114.0   1257.0   7.2  0.0  11.13   -0.00   822.5   \n",
      "2         1186.0  ...   1119.0   1261.0   7.2  0.0  -0.85    0.00     0.0   \n",
      "3         1190.0  ...   1125.0   1267.0   7.2  0.0 -30.64   -0.03   824.5   \n",
      "4         1197.0  ...   1129.0   1271.0   7.2  0.0 -23.95   -0.02   825.0   \n",
      "...          ...  ...      ...      ...   ...  ...    ...     ...     ...   \n",
      "13414562   764.5  ...   1001.0    989.5  19.5  0.0   5.91    0.06   836.0   \n",
      "13414563   771.5  ...    998.5    988.0  19.5  0.0  15.54   -0.02   836.0   \n",
      "13414564   770.0  ...    995.0    987.0  19.5  0.0  15.99   -0.01   836.0   \n",
      "13414565   769.0  ...    990.5    986.5  19.5  0.0   7.91    0.03   836.0   \n",
      "13414566     0.0  ...      0.0      0.0  19.5  0.0 -13.47   -0.02   836.5   \n",
      "\n",
      "            id  plane_id  split  \n",
      "0            2        18      4  \n",
      "1            2        18      4  \n",
      "2            2        18      4  \n",
      "3            2        18      4  \n",
      "4            2        18      4  \n",
      "...        ...       ...    ...  \n",
      "13414562  6083        19      0  \n",
      "13414563  6083        19      0  \n",
      "13414564  6083        19      0  \n",
      "13414565  6083        19      0  \n",
      "13414566  6083        19      0  \n",
      "\n",
      "[13414567 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "numVariables = 26#52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "23747611",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b45cd691",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split and reshape the data set by step_size , use min-max or stanrdardlize method to rescale the data\n",
    "def Splitting_dataset(data, step_size, scale=True, scaler_type=MinMaxScaler):\n",
    "        l = len(data) \n",
    "        data = scaler_type().fit_transform(data)\n",
    "        Xs = []\n",
    "        Ys = []\n",
    "        for i in range(0, (len(data) - step_size)):\n",
    "            Xs.append(data[i:i+step_size])\n",
    "            Ys.append(data[i:i+step_size])\n",
    "        train_x, test_x, train_y, test_y = [np.array(x) for x in train_test_split(Xs, Ys)]\n",
    "        assert train_x.shape[2] == test_x.shape[2] == (data.shape[1] if (type(data) == np.ndarray) else len(data))\n",
    "        return  (train_x.shape[2], train_x, train_y, test_x, test_y)\n",
    "    \n",
    "def get_batch(x, batch_size):\n",
    "    \"\"\"Made with taking test_x or XX as input\"\"\"\n",
    "    #make stochastic\n",
    "    t = 0\n",
    "    while t >= 0:\n",
    "        x_mod = len(x) % batch_size\n",
    "        start = random.random() * (len(x)-x_mod)\n",
    "        start = int(start)\n",
    "        if start + batch_size < len(x):\n",
    "            t = t-1\n",
    "    batch = torch.tensor(x[start:(start+batch_size)]) #!! added tensor line\n",
    "    #print(batch.shape)\n",
    "    return batch\n",
    "\n",
    "def to_var(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x)\n",
    "\n",
    "def loss_fn(recon_x, x, mu, logvar):\n",
    "    #rec = torch.nan_to_num(recon_x)\n",
    "    #print(recon_x)\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, size_average=True)\n",
    "    \n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu**2 -  logvar.exp())\n",
    "    return BCE + KLD\n",
    "    \n",
    "def tep_testing_stepped(dat,step_size):\n",
    "    res = []\n",
    "    ind = 0\n",
    "    scale = MinMaxScaler().fit(dat)\n",
    "    dat = pd.DataFrame(scale.transform(dat))\n",
    "    #print(int((len(data)/step_size)))\n",
    "    for i in range(int((len(dat)/step_size))):\n",
    "        if ind + step_size < len(dat):\n",
    "            step = []\n",
    "            for j in range(step_size):\n",
    "              #print(data.iloc(0)[ind])#[ind])\n",
    "              step.append(dat.iloc(0)[ind])\n",
    "              ind = ind + 1\n",
    "            res.append(step)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "450792c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4efa905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_size=784, h_dim=27, z_dim=31, n_flow_steps=1):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(image_size, h_dim),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(h_dim, z_dim*2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(z_dim, h_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h_dim, image_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        mu.double()\n",
    "        logvar.double()\n",
    "        std = logvar.mul(0.5).exp_() \n",
    "        esp = to_var(torch.randn(*mu.size()))\n",
    "        z = mu + std * esp\n",
    "        return z\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #print(\"------------------\")\n",
    "        #print(x)\n",
    "        h = self.encoder(x)\n",
    "        #print(h)\n",
    "        #print(\"------------------\")\n",
    "        mu, logvar = torch.chunk(h, 2, dim=1)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        #print(z)\n",
    "        z = model(z)\n",
    "        tensorZ = torch.tensor(z[0])#torch.tensor(z[0])\n",
    "        #print(str(tensorZ.shape) + str(\" YYY\"))\n",
    "        #print(z[0])\n",
    "        #print(\"--\" + str(self.decoder(tensorZ).shape))\n",
    "        \n",
    "        return self.decoder(tensorZ), mu, logvar\n",
    "        #return self.decoder(z), mu, logvar\n",
    "    \n",
    "\n",
    "class stacked_NVP(nn.Module):\n",
    "    def __init__(self, d, k, hidden, n):\n",
    "        super().__init__()\n",
    "        self.bijectors = nn.ModuleList([\n",
    "            R_NVP(d, k, hidden=hidden) for _ in range(n)\n",
    "        ])\n",
    "        self.flips = [True if i%2 else False for i in range(n)]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        log_jacobs = []\n",
    "\n",
    "        for bijector, f in zip(self.bijectors, self.flips):\n",
    "            x, log_pz, lj = bijector(x, flip=f)\n",
    "            log_jacobs.append(lj)\n",
    "        \n",
    "        return x, log_pz, sum(log_jacobs)\n",
    "    \n",
    "    def inverse(self, z):\n",
    "        for bijector, f in zip(reversed(self.bijectors), reversed(self.flips)):\n",
    "            z = bijector.inverse(z, flip=f)\n",
    "        return z\n",
    "    \n",
    "class R_NVP(nn.Module):\n",
    "    def __init__(self, d, k, hidden):\n",
    "        super().__init__()\n",
    "        self.d, self.k = d, k\n",
    "        self.sig_net = nn.Sequential(\n",
    "                    nn.Linear(k, hidden),\n",
    "                    nn.LeakyReLU(),\n",
    "                    nn.Linear(hidden, d - k))\n",
    "\n",
    "        self.mu_net = nn.Sequential(\n",
    "                    nn.Linear(k, hidden),\n",
    "                    nn.LeakyReLU(),\n",
    "                    nn.Linear(hidden, d - k))\n",
    "\n",
    "    def forward(self, x, flip=False):\n",
    "        x1, x2 = x[:, :self.k], x[:, self.k:] \n",
    "        #print(\"t\")\n",
    "        if flip:\n",
    "            x2, x1 = x1, x2\n",
    "        \n",
    "        # forward\n",
    "        sig = self.sig_net(x1)\n",
    "        #print(\"x1: \" + str(x1.shape))\n",
    "        #print(\"x2: \" + str(x2.shape))\n",
    "        z1, z2 = x1, x2 * torch.exp(sig) + self.mu_net(x1)\n",
    "        \n",
    "        if flip:\n",
    "            z2, z1 = z1, z2\n",
    "        \n",
    "        z_hat = torch.cat([z1, z2], dim=-1)\n",
    "\n",
    "        log_pz = base_dist.log_prob(z_hat)\n",
    "        log_jacob = sig.sum(-1)\n",
    "        \n",
    "        return z_hat, log_pz, log_jacob\n",
    "    \n",
    "    def inverse(self, Z, flip=False):\n",
    "        z1, z2 = Z[:, :self.k], Z[:, self.k:] \n",
    "        \n",
    "        if flip:\n",
    "            z2, z1 = z1, z2\n",
    "        \n",
    "        x1 = z1\n",
    "        x2 = (z2 - self.mu_net(z1)) * torch.exp(-self.sig_net(z1))\n",
    "        \n",
    "        if flip:\n",
    "            x2, x1 = x1, x2\n",
    "        return torch.cat([x1, x2], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f5ed6676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e8932e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 1.]], dtype=torch.float64,\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "step_size = 3\n",
    "batch = 512\n",
    "index_step_length = numVariables\n",
    "epochs = 20\n",
    "\n",
    "num = 5\n",
    "\n",
    "d = numVariables\n",
    "k = int(numVariables/2)\n",
    "\n",
    "base_mu, base_cov = torch.zeros(numVariables), torch.eye(numVariables)\n",
    "\n",
    "base_mu = torch.nn.parameter.Parameter(to_var(base_mu.double()))\n",
    "base_cov = torch.nn.parameter.Parameter(to_var(base_cov.double()))\n",
    "#base_mu = torch.nn.parameter.Parameter(base_mu,requires_grad=True)\n",
    "#base_cov = torch.nn.parameter.Parameter(base_cov,requires_grad=True)\n",
    "print(base_mu)\n",
    "print(base_cov)\n",
    "base_dist = MultivariateNormal(base_mu, base_cov)\n",
    "#---------------------------------------------------------------------------------------------------------------------------------\n",
    "labels, X, Y, XX, YY = Splitting_dataset(data, step_size)\n",
    "#XX.cuda()\n",
    "demo = VAE(index_step_length,h_dim=13,z_dim=numVariables)\n",
    "model = stacked_NVP(d, k, hidden=512,n=num)#hidden -> 512\n",
    "demo.double()\n",
    "model.double()\n",
    "    \n",
    "#next set of tests should be with n=3, last set was with n=1\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-3)\n",
    "optimizer2 = torch.optim.Adam(demo.parameters(), lr=1e-3)\n",
    "optimizer3 = torch.optim.RMSprop([base_mu,base_cov], lr=1e-3)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.999)\n",
    "#scheduler2 = torch.optim.lr_scheduler.ExponentialLR(optimizer2, 0.999)\n",
    "\n",
    "if torch.cuda.is_available() & cudaOn:\n",
    "    demo.cuda()\n",
    "    print(\"demo done\")\n",
    "    model.cuda()\n",
    "    print(\"model done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fda6b3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "191093b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charlie\\AppData\\Local\\Temp/ipykernel_12608/62241503.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  localX = to_var(torch.tensor(b[i]))\n",
      "C:\\Users\\Charlie\\AppData\\Local\\Temp/ipykernel_12608/4031463872.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tensorZ = torch.tensor(z[0])#torch.tensor(z[0])\n",
      "C:\\Users\\Charlie\\anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/20] Loss: 0.001\n",
      "Epoch[1/20] Loss: 0.001\n",
      "Epoch[1/20] Loss: 0.001\n",
      "Epoch[1/20] Loss: 0.001\n",
      "Epoch[1/20] Loss: 0.001\n",
      "Epoch[2/20] Loss: 0.001\n",
      "Epoch[2/20] Loss: 0.001\n",
      "Epoch[2/20] Loss: 0.001\n",
      "Epoch[2/20] Loss: 0.001\n",
      "Epoch[2/20] Loss: 0.001\n",
      "Epoch[3/20] Loss: 0.001\n",
      "Epoch[3/20] Loss: 0.001\n",
      "Epoch[3/20] Loss: 0.001\n",
      "Epoch[3/20] Loss: 0.001\n",
      "Epoch[3/20] Loss: 0.001\n",
      "Epoch[4/20] Loss: 0.001\n",
      "Epoch[4/20] Loss: 0.001\n",
      "Epoch[4/20] Loss: 0.001\n",
      "Epoch[4/20] Loss: 0.001\n",
      "Epoch[4/20] Loss: 0.001\n",
      "Epoch[5/20] Loss: 0.001\n",
      "Epoch[5/20] Loss: 0.001\n",
      "Epoch[5/20] Loss: 0.001\n",
      "Epoch[5/20] Loss: 0.001\n",
      "Epoch[5/20] Loss: 0.001\n",
      "Epoch[6/20] Loss: 0.001\n",
      "Epoch[6/20] Loss: 0.001\n",
      "Epoch[6/20] Loss: 0.001\n",
      "Epoch[6/20] Loss: 0.001\n",
      "Epoch[6/20] Loss: 0.001\n",
      "Epoch[7/20] Loss: 0.001\n",
      "Epoch[7/20] Loss: 0.001\n",
      "Epoch[7/20] Loss: 0.001\n",
      "Epoch[7/20] Loss: 0.001\n",
      "Epoch[7/20] Loss: 0.001\n",
      "Epoch[8/20] Loss: 0.001\n",
      "Epoch[8/20] Loss: 0.001\n",
      "Epoch[8/20] Loss: 0.001\n",
      "Epoch[8/20] Loss: 0.001\n",
      "Epoch[8/20] Loss: 0.001\n",
      "Epoch[9/20] Loss: 0.001\n",
      "Epoch[9/20] Loss: 0.001\n",
      "Epoch[9/20] Loss: 0.001\n",
      "Epoch[9/20] Loss: 0.001\n",
      "Epoch[9/20] Loss: 0.001\n",
      "Epoch[9/20] Loss: 0.001\n",
      "Epoch[10/20] Loss: 0.002\n",
      "Epoch[10/20] Loss: 0.001\n",
      "Epoch[10/20] Loss: 0.001\n",
      "Epoch[10/20] Loss: 0.001\n",
      "Epoch[10/20] Loss: 0.001\n",
      "Epoch[11/20] Loss: 0.001\n",
      "Epoch[11/20] Loss: 0.001\n",
      "Epoch[11/20] Loss: 0.001\n",
      "Epoch[11/20] Loss: 0.001\n",
      "Epoch[11/20] Loss: 0.001\n",
      "Epoch[12/20] Loss: 0.001\n",
      "Epoch[12/20] Loss: 0.001\n",
      "Epoch[12/20] Loss: 0.001\n",
      "Epoch[12/20] Loss: 0.001\n",
      "Epoch[12/20] Loss: 0.001\n",
      "Epoch[13/20] Loss: 0.001\n",
      "Epoch[13/20] Loss: 0.001\n",
      "Epoch[13/20] Loss: 0.001\n",
      "Epoch[13/20] Loss: 0.001\n",
      "Epoch[13/20] Loss: 0.001\n",
      "Epoch[14/20] Loss: 0.001\n",
      "Epoch[14/20] Loss: 0.001\n",
      "Epoch[14/20] Loss: 0.001\n",
      "Epoch[14/20] Loss: 0.001\n",
      "Epoch[14/20] Loss: 0.001\n",
      "Epoch[15/20] Loss: 0.001\n",
      "Epoch[15/20] Loss: 0.001\n",
      "Epoch[15/20] Loss: 0.001\n",
      "Epoch[15/20] Loss: 0.001\n",
      "Epoch[15/20] Loss: 0.001\n",
      "Epoch[16/20] Loss: 0.001\n",
      "Epoch[16/20] Loss: 0.001\n",
      "Epoch[16/20] Loss: 0.001\n",
      "Epoch[16/20] Loss: 0.001\n",
      "Epoch[16/20] Loss: 0.001\n",
      "Epoch[17/20] Loss: 0.001\n",
      "Epoch[17/20] Loss: 0.001\n",
      "Epoch[17/20] Loss: 0.001\n",
      "Epoch[17/20] Loss: 0.001\n",
      "Epoch[17/20] Loss: 0.001\n",
      "Epoch[17/20] Loss: 0.001\n",
      "Epoch[18/20] Loss: 0.001\n",
      "Epoch[18/20] Loss: 0.001\n",
      "Epoch[18/20] Loss: 0.001\n",
      "Epoch[18/20] Loss: 0.001\n",
      "Epoch[18/20] Loss: 0.001\n",
      "Epoch[19/20] Loss: 0.001\n",
      "Epoch[19/20] Loss: 0.001\n",
      "Epoch[19/20] Loss: 0.001\n",
      "Epoch[19/20] Loss: 0.001\n",
      "Epoch[19/20] Loss: 0.001\n",
      "Epoch[20/20] Loss: 0.001\n",
      "Epoch[20/20] Loss: 0.001\n",
      "Epoch[20/20] Loss: 0.001\n",
      "Epoch[20/20] Loss: 0.001\n",
      "Epoch[20/20] Loss: 0.001\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "\n",
    "anomaly_history = []\n",
    "loss_history = []\n",
    "avgSum = 0\n",
    "avgCount = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    b = get_batch(X,batch)\n",
    "    for i in range(batch):\n",
    "        #print(i)\n",
    "        optimizer.zero_grad()\n",
    "        optimizer2.zero_grad()\n",
    "        optimizer3.zero_grad()\n",
    "        localX = to_var(torch.tensor(b[i]))\n",
    "        recon, mu, logvar = demo(localX)\n",
    "        #print(recon.shape)\n",
    "        #print(localX.shape)\n",
    "        loss = loss_fn(recon, localX, mu, logvar) #doing kl-divergence loss correctly\n",
    "        \"\"\"This bound (kl loss) provides a unified objective function for \n",
    "        op-timization of both the parameters θ and φ of the model and variational approximation, respectively.\"\"\"\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        #demo.double()\n",
    "        #model.double()\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer2.step()\n",
    "        optimizer3.step()\n",
    "        scheduler.step()\n",
    "        #scheduler2.step()\n",
    "        idx = idx + 1\n",
    "\n",
    "        avgSum = avgSum + torch.mean(loss/batch)\n",
    "        avgCount = avgCount + 1\n",
    "        anomaly_score = abs(torch.mean(localX-recon))\n",
    "\n",
    "        if idx%step_size == 0:\n",
    "            loss_history.append(avgSum/avgCount)\n",
    "            anomaly_history.append(anomaly_score)\n",
    "            avgSum = 0\n",
    "            avgCount = 0\n",
    "\n",
    "        if idx%100 == 0:\n",
    "            print(\"Epoch[{}/{}] Loss: {:.3f}\".format(epoch+1, epochs, loss.data.item()/batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a83b47fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d3ee5e0910>]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = plt.figure()\n",
    "plt.plot(loss_history,'g-',label='h 10,z 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "96acd88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stepped = tep_testing_stepped(data,3)\n",
    "#test = pd.read_csv(\"C:/Users/Charlie/Documents/big_old_data_files/ngafid2.0-main/ngafid2.0-main/example_data/C172/log_110812_095915_KCKN.csv\")\n",
    "test = data[10000:50000]\n",
    "stepped = tep_testing_stepped(test,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "198a9d82",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12608/1862952016.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstepped\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \"\"\"\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "fileLoc = \"C:/Users/Charlie/Desktop/picsForDemo2/tepGeneratedLast/NGAFID_Test/testpic.png\"\n",
    "\n",
    "for step in stepped:\n",
    "    step = torch.tensor(step)\n",
    "    print(step.shape)\n",
    "\n",
    "\"\"\"\n",
    "step_start = 0\n",
    "anomalies = []\n",
    "y_nomalies = []\n",
    "vals = []\n",
    "pred_vals = []\n",
    "county = 0\n",
    "for step in stepped:    \n",
    "    recon,_,_ = demo(step)\n",
    "    for j in range(len(step)):\n",
    "        a = (recon[0][j] - step[0][j])\n",
    "        anom = a**2\n",
    "        anom2 = torch.mean(torch.tensor(faultNumbersTest[(setNum*strtOfTwo)+(county*step_size):(setNum*strtOfTwo)+(county*step_size+step_size)],dtype=torch.float64))\n",
    "        anomalies.append(torch.tensor(anom))\n",
    "        #anomalies.append(torch.tensor(abs(anom)))\n",
    "        y_nomalies.append(anom2)\n",
    "        pred_vals.append(torch.mean(recon))\n",
    "        vals.append(torch.mean(step))\n",
    "        step_start = step_start + 1\n",
    "        county = county + 1\n",
    "    for a in anomalies:\n",
    "        if start+1 < len(anomalies):\n",
    "            view.append(abs(anomalies[start+1].item() - a.item()))  \n",
    "            start = start + 1\n",
    "            \n",
    "p3 = plt.figure()\n",
    "plt.plot(anomalies, 'g-')\n",
    "plt.savefig(fileLoc)\n",
    "p4 = plt.figure()\n",
    "#plt.plot(y_nomalies, 'b-')\n",
    "plt.plot(vals, 'b-')\n",
    "p5 = plt.figure()\n",
    "plt.plot(pred_vals, 'r-')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd9b5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = \"C:/Users/Charlie/Desktop/picsForDemo2/tepGeneratedLast/\"\n",
    "\n",
    "strtOfTwo = int(len(dataTest)/20)\n",
    "sets = []\n",
    "runNum = 0 \n",
    "print(len(faultNumbersTest))\n",
    "\n",
    "print(\"////////////////////\")\n",
    "for i in range(20):\n",
    "    print(str(strtOfTwo*runNum) + \" : \" + str((strtOfTwo*runNum)+run_length))\n",
    "    #print(faultNumbersTest[strtOfTwo*runNum])\n",
    "    dt = dataTest[strtOfTwo*runNum:(strtOfTwo*runNum)+run_length]\n",
    "    t1 = tep_testing_stepped(dt,step_size)\n",
    "    sets.append(t1)\n",
    "    runNum = runNum + 1\n",
    "print(\"////////////////////\")\n",
    "\n",
    "setNum = 0\n",
    "for set in sets:\n",
    "    setName = \"anom\" + str(setNum+1) + \"Faulty_Flow_111\"\n",
    "    fileLoc = loc + setName + \".png\"\n",
    "    step_start = 0\n",
    "    anomalies = []\n",
    "    y_nomalies = []\n",
    "    vals = []\n",
    "    pred_vals = []\n",
    "    county = 0\n",
    "    for step in set:\n",
    "        step = to_var(torch.tensor(step,dtype=torch.float64))\n",
    "        recon,_,_ = demo(step)\n",
    "        for j in range(len(step)):\n",
    "            a = (recon[0][j] - step[0][j])\n",
    "            anom = a**2\n",
    "            anom2 = torch.mean(torch.tensor(faultNumbersTest[(setNum*strtOfTwo)+(county*step_size):(setNum*strtOfTwo)+(county*step_size+step_size)],dtype=torch.float64))\n",
    "            anomalies.append(torch.tensor(anom))\n",
    "            #anomalies.append(torch.tensor(abs(anom)))\n",
    "            y_nomalies.append(anom2)\n",
    "            pred_vals.append(torch.mean(recon))\n",
    "            vals.append(torch.mean(step))\n",
    "            step_start = step_start + 1\n",
    "            county = county + 1\n",
    "    setNum = setNum + 1\n",
    "    start = 0\n",
    "    view = []\n",
    "    max = -99999\n",
    "    min = 99999\n",
    "    maxA = -99999\n",
    "    minA = 99999\n",
    "\n",
    "    print(len(anomalies))\n",
    "\n",
    "    for a in anomalies:\n",
    "        if start+1 < len(anomalies):\n",
    "            view.append(abs(anomalies[start+1].item() - a.item()))  \n",
    "            start = start + 1\n",
    "\n",
    "    for i in range(len(view)):\n",
    "        j = i + 1\n",
    "        if view[i] > max:\n",
    "            max = a.item()\n",
    "        if view[i] < min:\n",
    "            min = a.item()\n",
    "        if i < len(view)-1:\n",
    "            #print(\"i: \" + str(view[i]))\n",
    "            #print(\"j: \" + str(view[j]))\n",
    "            v = abs(view[i]-view[j])\n",
    "            #print(\"v: \" + str(v))\n",
    "            if v > maxA:\n",
    "                maxA = v\n",
    "            if v < minA:\n",
    "                minA = v\n",
    "\n",
    "    print()\n",
    "    print(max)\n",
    "    print(maxA)\n",
    "    print(minA)\n",
    "\n",
    "    #could get loc min and max given a step size rather than literally between individual points\n",
    "\n",
    "    #ADD LINEAR REGRESSION LINE\n",
    "    \n",
    "    p3 = plt.figure()\n",
    "    plt.plot(anomalies, 'g-')\n",
    "    plt.savefig(fileLoc)\n",
    "    p4 = plt.figure()\n",
    "    #plt.plot(y_nomalies, 'b-')\n",
    "    plt.plot(vals, 'b-')\n",
    "    p5 = plt.figure()\n",
    "    plt.plot(pred_vals, 'r-')\n",
    "    print(\"-------------------------------------------------------------------------------------\")\n",
    "    print(\"-------------------------------------------------------------------------------------\")\n",
    "    print(\"-------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a88e781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b3cf57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d681334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
