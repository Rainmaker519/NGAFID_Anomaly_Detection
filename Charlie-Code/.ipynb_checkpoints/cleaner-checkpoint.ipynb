{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17017c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.autograd import Variable\n",
    "#import torch.cuda\n",
    "import random\n",
    "from itertools import chain as chain\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "\n",
    "cudaOn = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6507ca8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>faultNumber</th>\n",
       "      <th>simulationRun</th>\n",
       "      <th>sample</th>\n",
       "      <th>xmeas_1</th>\n",
       "      <th>xmeas_2</th>\n",
       "      <th>xmeas_3</th>\n",
       "      <th>xmeas_4</th>\n",
       "      <th>xmeas_5</th>\n",
       "      <th>xmeas_6</th>\n",
       "      <th>...</th>\n",
       "      <th>xmv_2</th>\n",
       "      <th>xmv_3</th>\n",
       "      <th>xmv_4</th>\n",
       "      <th>xmv_5</th>\n",
       "      <th>xmv_6</th>\n",
       "      <th>xmv_7</th>\n",
       "      <th>xmv_8</th>\n",
       "      <th>xmv_9</th>\n",
       "      <th>xmv_10</th>\n",
       "      <th>xmv_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25038</td>\n",
       "      <td>3674.0</td>\n",
       "      <td>4529.0</td>\n",
       "      <td>9.2320</td>\n",
       "      <td>26.889</td>\n",
       "      <td>42.402</td>\n",
       "      <td>...</td>\n",
       "      <td>53.744</td>\n",
       "      <td>24.657</td>\n",
       "      <td>62.544</td>\n",
       "      <td>22.137</td>\n",
       "      <td>39.935</td>\n",
       "      <td>42.323</td>\n",
       "      <td>47.757</td>\n",
       "      <td>47.510</td>\n",
       "      <td>41.258</td>\n",
       "      <td>18.447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25109</td>\n",
       "      <td>3659.4</td>\n",
       "      <td>4556.6</td>\n",
       "      <td>9.4264</td>\n",
       "      <td>26.721</td>\n",
       "      <td>42.576</td>\n",
       "      <td>...</td>\n",
       "      <td>53.414</td>\n",
       "      <td>24.588</td>\n",
       "      <td>59.259</td>\n",
       "      <td>22.084</td>\n",
       "      <td>40.176</td>\n",
       "      <td>38.554</td>\n",
       "      <td>43.692</td>\n",
       "      <td>47.427</td>\n",
       "      <td>41.359</td>\n",
       "      <td>17.194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25038</td>\n",
       "      <td>3660.3</td>\n",
       "      <td>4477.8</td>\n",
       "      <td>9.4426</td>\n",
       "      <td>26.875</td>\n",
       "      <td>42.070</td>\n",
       "      <td>...</td>\n",
       "      <td>54.357</td>\n",
       "      <td>24.666</td>\n",
       "      <td>61.275</td>\n",
       "      <td>22.380</td>\n",
       "      <td>40.244</td>\n",
       "      <td>38.990</td>\n",
       "      <td>46.699</td>\n",
       "      <td>47.468</td>\n",
       "      <td>41.199</td>\n",
       "      <td>20.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.24977</td>\n",
       "      <td>3661.3</td>\n",
       "      <td>4512.1</td>\n",
       "      <td>9.4776</td>\n",
       "      <td>26.758</td>\n",
       "      <td>42.063</td>\n",
       "      <td>...</td>\n",
       "      <td>53.946</td>\n",
       "      <td>24.725</td>\n",
       "      <td>59.856</td>\n",
       "      <td>22.277</td>\n",
       "      <td>40.257</td>\n",
       "      <td>38.072</td>\n",
       "      <td>47.541</td>\n",
       "      <td>47.658</td>\n",
       "      <td>41.643</td>\n",
       "      <td>18.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.29405</td>\n",
       "      <td>3679.0</td>\n",
       "      <td>4497.0</td>\n",
       "      <td>9.3381</td>\n",
       "      <td>26.889</td>\n",
       "      <td>42.650</td>\n",
       "      <td>...</td>\n",
       "      <td>53.658</td>\n",
       "      <td>28.797</td>\n",
       "      <td>60.717</td>\n",
       "      <td>21.947</td>\n",
       "      <td>39.144</td>\n",
       "      <td>41.955</td>\n",
       "      <td>47.645</td>\n",
       "      <td>47.346</td>\n",
       "      <td>41.507</td>\n",
       "      <td>18.461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999995</th>\n",
       "      <td>4999996</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>496</td>\n",
       "      <td>0.23419</td>\n",
       "      <td>3655.3</td>\n",
       "      <td>4461.7</td>\n",
       "      <td>9.3448</td>\n",
       "      <td>27.008</td>\n",
       "      <td>42.481</td>\n",
       "      <td>...</td>\n",
       "      <td>53.670</td>\n",
       "      <td>23.350</td>\n",
       "      <td>61.061</td>\n",
       "      <td>20.719</td>\n",
       "      <td>40.999</td>\n",
       "      <td>38.653</td>\n",
       "      <td>47.386</td>\n",
       "      <td>47.528</td>\n",
       "      <td>40.212</td>\n",
       "      <td>17.659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999996</th>\n",
       "      <td>4999997</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>497</td>\n",
       "      <td>0.26704</td>\n",
       "      <td>3647.4</td>\n",
       "      <td>4540.2</td>\n",
       "      <td>9.3546</td>\n",
       "      <td>27.034</td>\n",
       "      <td>42.671</td>\n",
       "      <td>...</td>\n",
       "      <td>54.650</td>\n",
       "      <td>26.362</td>\n",
       "      <td>60.020</td>\n",
       "      <td>20.263</td>\n",
       "      <td>41.579</td>\n",
       "      <td>33.624</td>\n",
       "      <td>47.536</td>\n",
       "      <td>47.647</td>\n",
       "      <td>41.199</td>\n",
       "      <td>18.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999997</th>\n",
       "      <td>4999998</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>498</td>\n",
       "      <td>0.26543</td>\n",
       "      <td>3630.3</td>\n",
       "      <td>4571.6</td>\n",
       "      <td>9.4089</td>\n",
       "      <td>27.129</td>\n",
       "      <td>42.470</td>\n",
       "      <td>...</td>\n",
       "      <td>54.274</td>\n",
       "      <td>26.521</td>\n",
       "      <td>59.824</td>\n",
       "      <td>20.189</td>\n",
       "      <td>41.505</td>\n",
       "      <td>40.967</td>\n",
       "      <td>52.437</td>\n",
       "      <td>47.802</td>\n",
       "      <td>41.302</td>\n",
       "      <td>23.199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999998</th>\n",
       "      <td>4999999</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>499</td>\n",
       "      <td>0.27671</td>\n",
       "      <td>3655.7</td>\n",
       "      <td>4498.9</td>\n",
       "      <td>9.3781</td>\n",
       "      <td>27.353</td>\n",
       "      <td>42.281</td>\n",
       "      <td>...</td>\n",
       "      <td>53.506</td>\n",
       "      <td>26.781</td>\n",
       "      <td>62.818</td>\n",
       "      <td>20.453</td>\n",
       "      <td>40.208</td>\n",
       "      <td>40.957</td>\n",
       "      <td>47.628</td>\n",
       "      <td>48.086</td>\n",
       "      <td>40.510</td>\n",
       "      <td>15.932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999999</th>\n",
       "      <td>5000000</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>0.27421</td>\n",
       "      <td>3640.4</td>\n",
       "      <td>4474.4</td>\n",
       "      <td>9.3866</td>\n",
       "      <td>27.145</td>\n",
       "      <td>41.985</td>\n",
       "      <td>...</td>\n",
       "      <td>53.800</td>\n",
       "      <td>27.027</td>\n",
       "      <td>59.757</td>\n",
       "      <td>20.157</td>\n",
       "      <td>40.326</td>\n",
       "      <td>36.039</td>\n",
       "      <td>48.885</td>\n",
       "      <td>48.170</td>\n",
       "      <td>41.115</td>\n",
       "      <td>15.752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000000 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  faultNumber  simulationRun  sample  xmeas_1  xmeas_2  \\\n",
       "0                 1            1              1       1  0.25038   3674.0   \n",
       "1                 2            1              1       2  0.25109   3659.4   \n",
       "2                 3            1              1       3  0.25038   3660.3   \n",
       "3                 4            1              1       4  0.24977   3661.3   \n",
       "4                 5            1              1       5  0.29405   3679.0   \n",
       "...             ...          ...            ...     ...      ...      ...   \n",
       "4999995     4999996           20            500     496  0.23419   3655.3   \n",
       "4999996     4999997           20            500     497  0.26704   3647.4   \n",
       "4999997     4999998           20            500     498  0.26543   3630.3   \n",
       "4999998     4999999           20            500     499  0.27671   3655.7   \n",
       "4999999     5000000           20            500     500  0.27421   3640.4   \n",
       "\n",
       "         xmeas_3  xmeas_4  xmeas_5  xmeas_6  ...   xmv_2   xmv_3   xmv_4  \\\n",
       "0         4529.0   9.2320   26.889   42.402  ...  53.744  24.657  62.544   \n",
       "1         4556.6   9.4264   26.721   42.576  ...  53.414  24.588  59.259   \n",
       "2         4477.8   9.4426   26.875   42.070  ...  54.357  24.666  61.275   \n",
       "3         4512.1   9.4776   26.758   42.063  ...  53.946  24.725  59.856   \n",
       "4         4497.0   9.3381   26.889   42.650  ...  53.658  28.797  60.717   \n",
       "...          ...      ...      ...      ...  ...     ...     ...     ...   \n",
       "4999995   4461.7   9.3448   27.008   42.481  ...  53.670  23.350  61.061   \n",
       "4999996   4540.2   9.3546   27.034   42.671  ...  54.650  26.362  60.020   \n",
       "4999997   4571.6   9.4089   27.129   42.470  ...  54.274  26.521  59.824   \n",
       "4999998   4498.9   9.3781   27.353   42.281  ...  53.506  26.781  62.818   \n",
       "4999999   4474.4   9.3866   27.145   41.985  ...  53.800  27.027  59.757   \n",
       "\n",
       "          xmv_5   xmv_6   xmv_7   xmv_8   xmv_9  xmv_10  xmv_11  \n",
       "0        22.137  39.935  42.323  47.757  47.510  41.258  18.447  \n",
       "1        22.084  40.176  38.554  43.692  47.427  41.359  17.194  \n",
       "2        22.380  40.244  38.990  46.699  47.468  41.199  20.530  \n",
       "3        22.277  40.257  38.072  47.541  47.658  41.643  18.089  \n",
       "4        21.947  39.144  41.955  47.645  47.346  41.507  18.461  \n",
       "...         ...     ...     ...     ...     ...     ...     ...  \n",
       "4999995  20.719  40.999  38.653  47.386  47.528  40.212  17.659  \n",
       "4999996  20.263  41.579  33.624  47.536  47.647  41.199  18.741  \n",
       "4999997  20.189  41.505  40.967  52.437  47.802  41.302  23.199  \n",
       "4999998  20.453  40.208  40.957  47.628  48.086  40.510  15.932  \n",
       "4999999  20.157  40.326  36.039  48.885  48.170  41.115  15.752  \n",
       "\n",
       "[5000000 rows x 56 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tepLoc = \"C:/Users/Charlie/Desktop/TEP_Data/\"\n",
    "tepTrain = tepLoc + \"TEP_Faulty_Training.csv\"\n",
    "tepTest = tepLoc + \"TEP_Faulty_Testing.csv\"\n",
    "\n",
    "#data = pd.read_csv('c172_file_1.csv')\n",
    "data = pd.read_csv(tepTrain)\n",
    "dataTest = pd.read_csv(tepTest)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf7e59bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           1\n",
      "1           1\n",
      "2           1\n",
      "3           1\n",
      "4           1\n",
      "           ..\n",
      "9599995    20\n",
      "9599996    20\n",
      "9599997    20\n",
      "9599998    20\n",
      "9599999    20\n",
      "Name: faultNumber, Length: 9600000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = data.drop('Unnamed: 0',axis=1)\n",
    "data = data.drop('faultNumber',axis=1)\n",
    "faultNumbersTest = dataTest.get('faultNumber')\n",
    "dataTest = dataTest.drop('Unnamed: 0',axis=1)\n",
    "dataTest = dataTest.drop('faultNumber',axis=1)\n",
    "\n",
    "print(faultNumbersTest)\n",
    "#numVariables = 31\n",
    "numVariables = 54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ada8c248",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3052/3253604735.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtep_testing_stepped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataTest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3052/3253604735.py\u001b[0m in \u001b[0;36mtep_testing_stepped\u001b[1;34m(data, step_size)\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                 \u001b[0mstep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m                 \u001b[0mind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mind\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1566\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1568\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1570\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[1;34m(self, i, axis)\u001b[0m\n\u001b[0;32m   3377\u001b[0m         \u001b[1;31m# irow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3378\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3379\u001b[1;33m             \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfast_xs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3381\u001b[0m             \u001b[1;31m# if we are a copy, mark as such\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mfast_xs\u001b[1;34m(self, loc)\u001b[0m\n\u001b[0;32m    952\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 954\u001b[1;33m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minterleaved_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\base.py\u001b[0m in \u001b[0;36minterleaved_dtype\u001b[1;34m(dtypes)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfind_common_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mfind_common_type\u001b[1;34m(types)\u001b[0m\n\u001b[0;32m   1812\u001b[0m     \u001b[1;31m# workaround for find_common_type([np.dtype('datetime64[ns]')] * 2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1813\u001b[0m     \u001b[1;31m# => object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1814\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_dtype_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1815\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfirst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1816\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1812\u001b[0m     \u001b[1;31m# workaround for find_common_type([np.dtype('datetime64[ns]')] * 2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1813\u001b[0m     \u001b[1;31m# => object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1814\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_dtype_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1815\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfirst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1816\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\common.py\u001b[0m in \u001b[0;36mis_dtype_equal\u001b[1;34m(source, target)\u001b[0m\n\u001b[0;32m    609\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mis_dtype_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def tep_testing_stepped(data,step_size):\n",
    "    res = []\n",
    "    ind = 0\n",
    "    for i in range(0,int((len(data)/step_size))):\n",
    "        if ind + step_size < len(data):\n",
    "            step = []\n",
    "            for j in range(step_size):\n",
    "                step.append(data.iloc(0)[ind])\n",
    "                ind = ind + 1\n",
    "            res.append(step)\n",
    "    res = np.array(res)\n",
    "    return res\n",
    "\n",
    "t = tep_testing_stepped(dataTest,3)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ec85e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split and reshape the data set by step_size , use min-max or stanrdardlize method to rescale the data\n",
    "def Splitting_dataset(data, step_size, scale=True, scaler_type=MinMaxScaler):\n",
    "        l = len(data) \n",
    "        data = scaler_type().fit_transform(data)\n",
    "        Xs = []\n",
    "        Ys = []\n",
    "        for i in range(0, (len(data) - step_size)):\n",
    "            Xs.append(data[i:i+step_size])\n",
    "            Ys.append(data[i:i+step_size])\n",
    "        train_x, test_x, train_y, test_y = [np.array(x) for x in train_test_split(Xs, Ys)]\n",
    "        assert train_x.shape[2] == test_x.shape[2] == (data.shape[1] if (type(data) == np.ndarray) else len(data))\n",
    "        return  (train_x.shape[2], train_x, train_y, test_x, test_y)\n",
    "    \n",
    "def get_batch(x, batch_size):\n",
    "    \"\"\"Made with taking test_x or XX as input\"\"\"\n",
    "    t = 0\n",
    "    while t >= 0:\n",
    "        x_mod = len(x) % batch_size\n",
    "        start = random.random() * (len(x)-x_mod)\n",
    "        start = int(start)\n",
    "        if start + batch_size < len(x):\n",
    "            t = t-1\n",
    "    batch = x[start:(start+batch_size)]\n",
    "    #print(batch.shape)\n",
    "    return batch\n",
    "\n",
    "def to_var(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x)\n",
    "\n",
    "def loss_fn(recon_x, x, mu, logvar):\n",
    "        BCE = F.binary_cross_entropy(recon_x, x, size_average=False)\n",
    "    \n",
    "        # see Appendix B from VAE paper:\n",
    "        # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "        # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mu**2 -  logvar.exp())\n",
    "        return BCE + KLD\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6b2b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_size=784, h_dim=27, z_dim=31, n_flow_steps=1):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(image_size, h_dim),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(h_dim, z_dim*2) #is it saying its getting a mu and a var for each z dim out?\n",
    "            \n",
    "            #how can I represent the encoder as a distribution acting as the prior?\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(z_dim, h_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h_dim, image_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_() \n",
    "        esp = to_var(torch.randn(*mu.size()))\n",
    "        z = mu + std * esp\n",
    "        return z\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu, logvar = torch.chunk(h, 2, dim=1)\n",
    "        #print(mu.shape)\n",
    "        #print(logvar.shape)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        #print(z.shape)\n",
    "        #z = z.float()\n",
    "        z = model(z)\n",
    "        #print(z)\n",
    "        tensorZ = z[0]#torch.tensor(z[0])\n",
    "        #print(tensorZ.shape)\n",
    "        #print(z[0])\n",
    "        return self.decoder(tensorZ), mu, logvar\n",
    "    \n",
    "\n",
    "class stacked_NVP(nn.Module):\n",
    "    def __init__(self, d, k, hidden, n):\n",
    "        super().__init__()\n",
    "        self.bijectors = nn.ModuleList([\n",
    "            R_NVP(d, k, hidden=hidden) for _ in range(n)\n",
    "        ])\n",
    "        self.flips = [True if i%2 else False for i in range(n)]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        log_jacobs = []\n",
    "\n",
    "        for bijector, f in zip(self.bijectors, self.flips):\n",
    "            x, log_pz, lj = bijector(x, flip=f)\n",
    "            log_jacobs.append(lj)\n",
    "        \n",
    "        return x, log_pz, sum(log_jacobs)\n",
    "    \n",
    "    def inverse(self, z):\n",
    "        for bijector, f in zip(reversed(self.bijectors), reversed(self.flips)):\n",
    "            z = bijector.inverse(z, flip=f)\n",
    "        return z\n",
    "    \n",
    "class R_NVP(nn.Module):\n",
    "    def __init__(self, d, k, hidden):\n",
    "        super().__init__()\n",
    "        self.d, self.k = d, k\n",
    "        self.sig_net = nn.Sequential(\n",
    "                    nn.Linear(k, hidden),\n",
    "                    nn.LeakyReLU(),\n",
    "                    nn.Linear(hidden, d - k))\n",
    "\n",
    "        self.mu_net = nn.Sequential(\n",
    "                    nn.Linear(k, hidden),\n",
    "                    nn.LeakyReLU(),\n",
    "                    nn.Linear(hidden, d - k))\n",
    "\n",
    "    def forward(self, x, flip=False):\n",
    "        x1, x2 = x[:, :self.k], x[:, self.k:] \n",
    "\n",
    "        if flip:\n",
    "            x2, x1 = x1, x2\n",
    "        \n",
    "        # forward\n",
    "        sig = self.sig_net(x1)\n",
    "        z1, z2 = x1, x2 * torch.exp(sig) + self.mu_net(x1)\n",
    "        \n",
    "        if flip:\n",
    "            z2, z1 = z1, z2\n",
    "        \n",
    "        z_hat = torch.cat([z1, z2], dim=-1)\n",
    "\n",
    "        log_pz = base_dist.log_prob(z_hat)\n",
    "        log_jacob = sig.sum(-1)\n",
    "        \n",
    "        return z_hat, log_pz, log_jacob\n",
    "    \n",
    "    def inverse(self, Z, flip=False):\n",
    "        z1, z2 = Z[:, :self.k], Z[:, self.k:] \n",
    "        \n",
    "        if flip:\n",
    "            z2, z1 = z1, z2\n",
    "        \n",
    "        x1 = z1\n",
    "        x2 = (z2 - self.mu_net(z1)) * torch.exp(-self.sig_net(z1))\n",
    "        \n",
    "        if flip:\n",
    "            x2, x1 = x1, x2\n",
    "        return torch.cat([x1, x2], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a6c8460",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 3\n",
    "batch = 512\n",
    "index_step_length = numVariables\n",
    "epochs = 10\n",
    "\n",
    "d = 2\n",
    "k = 1\n",
    "\n",
    "base_mu, base_cov = torch.zeros(2), torch.eye(2)\n",
    "\n",
    "base_mu = base_mu.double()\n",
    "base_cov = base_cov.double()\n",
    "\n",
    "base_dist = MultivariateNormal(base_mu, base_cov)\n",
    "#---------------------------------------------------------------------------------------------------------------------------------\n",
    "labels, X, Y, XX, YY = Splitting_dataset(data, step_size)\n",
    "#XX.cuda()\n",
    "demo = VAE(index_step_length,h_dim=7,z_dim=2)\n",
    "model = stacked_NVP(d, k, hidden=512,n=1)\n",
    "demo.double()\n",
    "model.double()\n",
    "\n",
    "if torch.cuda.is_available() & cudaOn:\n",
    "    demo.cuda()\n",
    "    print(\"demo done\")\n",
    "    model.cuda()\n",
    "    print(\"model done\")\n",
    "    \n",
    "#next set of tests should be with n=3, last set was with n=1\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-3)\n",
    "optimizer2 = torch.optim.RMSprop(demo.parameters(), lr=1e-3)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d71db30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charlie\\anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/10] Loss: 0.216\n",
      "Epoch[1/10] Loss: 0.213\n",
      "Epoch[1/10] Loss: 0.213\n",
      "Epoch[1/10] Loss: 0.212\n",
      "Epoch[1/10] Loss: 0.212\n",
      "Epoch[2/10] Loss: 0.212\n",
      "Epoch[2/10] Loss: 0.212\n",
      "Epoch[2/10] Loss: 0.211\n",
      "Epoch[2/10] Loss: 0.222\n",
      "Epoch[2/10] Loss: 0.211\n",
      "Epoch[3/10] Loss: 0.212\n",
      "Epoch[3/10] Loss: 0.209\n",
      "Epoch[3/10] Loss: 0.211\n",
      "Epoch[3/10] Loss: 0.210\n",
      "Epoch[3/10] Loss: 0.212\n",
      "Epoch[4/10] Loss: 0.218\n",
      "Epoch[4/10] Loss: 0.223\n",
      "Epoch[4/10] Loss: 0.212\n",
      "Epoch[4/10] Loss: 0.209\n",
      "Epoch[4/10] Loss: 0.206\n",
      "Epoch[5/10] Loss: 0.211\n",
      "Epoch[5/10] Loss: 0.212\n",
      "Epoch[5/10] Loss: 0.212\n",
      "Epoch[5/10] Loss: 0.212\n",
      "Epoch[5/10] Loss: 0.209\n",
      "Epoch[6/10] Loss: 0.215\n",
      "Epoch[6/10] Loss: 0.213\n",
      "Epoch[6/10] Loss: 0.212\n",
      "Epoch[6/10] Loss: 0.211\n",
      "Epoch[6/10] Loss: 0.213\n",
      "Epoch[7/10] Loss: 0.214\n",
      "Epoch[7/10] Loss: 0.216\n",
      "Epoch[7/10] Loss: 0.212\n",
      "Epoch[7/10] Loss: 0.218\n",
      "Epoch[7/10] Loss: 0.212\n",
      "Epoch[8/10] Loss: 0.211\n",
      "Epoch[8/10] Loss: 0.212\n",
      "Epoch[8/10] Loss: 0.212\n",
      "Epoch[8/10] Loss: 0.212\n",
      "Epoch[8/10] Loss: 0.212\n",
      "Epoch[9/10] Loss: 0.211\n",
      "Epoch[9/10] Loss: 0.213\n",
      "Epoch[9/10] Loss: 0.212\n",
      "Epoch[9/10] Loss: 0.212\n",
      "Epoch[9/10] Loss: 0.212\n",
      "Epoch[9/10] Loss: 0.212\n",
      "Epoch[10/10] Loss: 0.213\n",
      "Epoch[10/10] Loss: 0.213\n",
      "Epoch[10/10] Loss: 0.212\n",
      "Epoch[10/10] Loss: 0.212\n",
      "Epoch[10/10] Loss: 0.213\n",
      "<class 'numpy.ndarray'>\n",
      "1250000\n",
      "(1250000, 3, 54)\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "\n",
    "anomaly_history = []\n",
    "loss_history = []\n",
    "avgSum = 0\n",
    "avgCount = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    b = get_batch(X,batch)\n",
    "    #print(range(batch))\n",
    "    for i in range(batch):\n",
    "        #localX = torch.tensor(b[i].cuda())\n",
    "        localX = to_var(torch.tensor(b[i]))\n",
    "        recon, mu, logvar = demo(localX)\n",
    "        loss = loss_fn(recon, localX, mu, logvar) #doing kl-divergence loss correctly\n",
    "        \"\"\"This bound (kl loss) provides a unified objective function for \n",
    "        op-timization of both the parameters θ and φ of the model and variational approximation, respectively.\"\"\"\n",
    "        optimizer.zero_grad()\n",
    "        optimizer2.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer2.step()\n",
    "        scheduler.step()\n",
    "        idx = idx + 1\n",
    "\n",
    "        avgSum = avgSum + torch.mean(loss/batch)\n",
    "        avgCount = avgCount + 1\n",
    "        anomaly_score = torch.mean(localX/recon)\n",
    "\n",
    "        if idx%30 == 0:\n",
    "            loss_history.append(avgSum/avgCount)\n",
    "            anomaly_history.append(anomaly_score)\n",
    "            avgSum = 0\n",
    "            avgCount = 0\n",
    "\n",
    "        if idx%100 == 0:\n",
    "            print(\"Epoch[{}/{}] Loss: {:.3f}\".format(epoch+1, epochs, loss.data.item()/batch))\n",
    "            \n",
    "p1 = plt.figure()\n",
    "plt.plot(loss_history,'g-',label='h 10,z 2')\n",
    "\n",
    "\n",
    "step_start = 0\n",
    "anomalies = []\n",
    "print(type(XX))\n",
    "print(len(XX))\n",
    "print(XX.shape)\n",
    "for step in XX:\n",
    "    if step_start + step_size < len(XX):\n",
    "        step = torch.tensor(XX[step_start:step_start+step_size])[0]\n",
    "        recon,_,_ = demo(step)\n",
    "        anom = torch.mean(localX/recon)\n",
    "        anomalies.append(anom)\n",
    "        step_start = step_start + 1\n",
    "        \n",
    "p3 = plt.figure()\n",
    "plt.plot(anomalies, 'g-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e516dea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
