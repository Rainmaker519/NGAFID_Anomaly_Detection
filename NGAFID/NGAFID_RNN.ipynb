{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NGAFID_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0laBdydQo_r"
      },
      "source": [
        "# SETUP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "088mMzSVOq0_"
      },
      "source": [
        "#solve the dataset will be changed after the training process\n",
        "\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import tensorflow as tf\n",
        "import gc \n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_probability as tfp\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn import preprocessing\n",
        "import matplotlib as plt\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "tfpl = tfp.layers\n",
        "tfd = tfp.distributions\n",
        "\n",
        "\n",
        "gc.collect() \n",
        "\n",
        "pd.options.mode.chained_assignment = None"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-i1wEAxZQmXo",
        "outputId": "80474a6c-89cb-4cef-cf22-c8b0f518e39c"
      },
      "source": [
        "#TPU\n",
        "\n",
        "import os\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "# Detect hardware, return appropriate distribution strategy\n",
        "try:\n",
        "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
        "    # set: this is always the case on Kaggle.\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TPU address is grpc://10.55.94.122:8470\n",
            "Running on TPU  grpc://10.55.94.122:8470\n",
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.55.94.122:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.55.94.122:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REPLICAS:  8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6qUuTklSyZq"
      },
      "source": [
        "# HYPER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ2J7rVBS0sJ"
      },
      "source": [
        "BASE_SEQ_LEN = 1000\n",
        "NUM_VAR = 31\n",
        "INPUT_SEQ_LEN = 32 \n",
        "OUTPUT_SEQ_LEN = 1 \n",
        "BATCH_SIZE = 128"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxSWs-yuQt3o"
      },
      "source": [
        "# READ DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y95pBl8_R_fh"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/Rainmaker519/NGAFID_Anomaly_Detection/main/NGAFID_dataset/c172_file_2.csv'\n",
        "dataset = pd.read_csv(url)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "yzF1XEUNG1iK",
        "outputId": "8b1f9235-008a-4432-9e68-79f86b873410"
      },
      "source": [
        "dataset.describe()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AltAGL</th>\n",
              "      <th>AltB</th>\n",
              "      <th>AltGPS</th>\n",
              "      <th>AltMSL</th>\n",
              "      <th>BaroA</th>\n",
              "      <th>E1_CHT1</th>\n",
              "      <th>E1_CHT2</th>\n",
              "      <th>E1_CHT3</th>\n",
              "      <th>E1_CHT4</th>\n",
              "      <th>E1_EGT1</th>\n",
              "      <th>E1_EGT2</th>\n",
              "      <th>E1_EGT3</th>\n",
              "      <th>E1_EGT4</th>\n",
              "      <th>E1_FFlow</th>\n",
              "      <th>E1_OilP</th>\n",
              "      <th>E1_OilT</th>\n",
              "      <th>E1_RPM</th>\n",
              "      <th>FQtyL</th>\n",
              "      <th>FQtyR</th>\n",
              "      <th>GndSpd</th>\n",
              "      <th>IAS</th>\n",
              "      <th>LatAc</th>\n",
              "      <th>NormAc</th>\n",
              "      <th>OAT</th>\n",
              "      <th>Pitch</th>\n",
              "      <th>Roll</th>\n",
              "      <th>TAS</th>\n",
              "      <th>VSpd</th>\n",
              "      <th>VSpdG</th>\n",
              "      <th>WndDr</th>\n",
              "      <th>WndSpd</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4467.000000</td>\n",
              "      <td>4467.000000</td>\n",
              "      <td>4467.000000</td>\n",
              "      <td>4467.000000</td>\n",
              "      <td>4467.000000</td>\n",
              "      <td>4467.000000</td>\n",
              "      <td>4467.000000</td>\n",
              "      <td>4467.000000</td>\n",
              "      <td>4467.000000</td>\n",
              "      <td>4467.000000</td>\n",
              "      <td>4467.000000</td>\n",
              "      <td>4467.000000</td>\n",
              "      <td>4467.000000</td>\n",
              "      <td>4467.000000</td>\n",
              "      <td>4467.000000</td>\n",
              "      <td>4467.000000</td>\n",
              "      <td>4467.000000</td>\n",
              "      <td>4467.000000</td>\n",
              "      <td>4467.000000</td>\n",
              "      <td>4467.000000</td>\n",
              "      <td>4467.000000</td>\n",
              "      <td>4467.000000</td>\n",
              "      <td>4467.000000</td>\n",
              "      <td>4467.000000</td>\n",
              "      <td>4467.000000</td>\n",
              "      <td>4467.000000</td>\n",
              "      <td>4467.000000</td>\n",
              "      <td>4467.000000</td>\n",
              "      <td>4467.000000</td>\n",
              "      <td>4467.000000</td>\n",
              "      <td>4467.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>621.904634</td>\n",
              "      <td>1447.365413</td>\n",
              "      <td>1354.174905</td>\n",
              "      <td>1443.162077</td>\n",
              "      <td>30.003956</td>\n",
              "      <td>282.680786</td>\n",
              "      <td>306.380663</td>\n",
              "      <td>309.696344</td>\n",
              "      <td>322.298849</td>\n",
              "      <td>1271.838117</td>\n",
              "      <td>1240.913891</td>\n",
              "      <td>1269.034569</td>\n",
              "      <td>1242.800405</td>\n",
              "      <td>8.043550</td>\n",
              "      <td>63.439507</td>\n",
              "      <td>166.060369</td>\n",
              "      <td>1923.664607</td>\n",
              "      <td>13.878471</td>\n",
              "      <td>16.101974</td>\n",
              "      <td>78.021084</td>\n",
              "      <td>76.867974</td>\n",
              "      <td>-0.012691</td>\n",
              "      <td>0.024941</td>\n",
              "      <td>21.816835</td>\n",
              "      <td>2.927833</td>\n",
              "      <td>-2.875534</td>\n",
              "      <td>79.852026</td>\n",
              "      <td>-15.005946</td>\n",
              "      <td>-15.201948</td>\n",
              "      <td>61.420081</td>\n",
              "      <td>5.150486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>430.763101</td>\n",
              "      <td>419.003121</td>\n",
              "      <td>422.684410</td>\n",
              "      <td>422.680796</td>\n",
              "      <td>0.009185</td>\n",
              "      <td>23.679792</td>\n",
              "      <td>26.798223</td>\n",
              "      <td>24.313926</td>\n",
              "      <td>26.057577</td>\n",
              "      <td>113.993135</td>\n",
              "      <td>151.593224</td>\n",
              "      <td>114.742380</td>\n",
              "      <td>110.930938</td>\n",
              "      <td>4.633955</td>\n",
              "      <td>7.356695</td>\n",
              "      <td>5.454409</td>\n",
              "      <td>597.475491</td>\n",
              "      <td>2.211355</td>\n",
              "      <td>1.415391</td>\n",
              "      <td>26.455299</td>\n",
              "      <td>28.560461</td>\n",
              "      <td>0.029323</td>\n",
              "      <td>0.103672</td>\n",
              "      <td>1.108857</td>\n",
              "      <td>3.980810</td>\n",
              "      <td>12.151214</td>\n",
              "      <td>29.889523</td>\n",
              "      <td>488.473980</td>\n",
              "      <td>517.127489</td>\n",
              "      <td>103.837486</td>\n",
              "      <td>3.116676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>825.500000</td>\n",
              "      <td>739.300000</td>\n",
              "      <td>828.500000</td>\n",
              "      <td>29.990000</td>\n",
              "      <td>197.340000</td>\n",
              "      <td>201.590000</td>\n",
              "      <td>219.090000</td>\n",
              "      <td>225.070000</td>\n",
              "      <td>990.490000</td>\n",
              "      <td>797.260000</td>\n",
              "      <td>993.090000</td>\n",
              "      <td>957.750000</td>\n",
              "      <td>1.710000</td>\n",
              "      <td>42.950000</td>\n",
              "      <td>150.220000</td>\n",
              "      <td>767.800000</td>\n",
              "      <td>8.330000</td>\n",
              "      <td>9.790000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.420000</td>\n",
              "      <td>-1.120000</td>\n",
              "      <td>19.200000</td>\n",
              "      <td>-22.420000</td>\n",
              "      <td>-58.460000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-3850.600000</td>\n",
              "      <td>-4169.300000</td>\n",
              "      <td>-179.900000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>218.000000</td>\n",
              "      <td>1057.900000</td>\n",
              "      <td>960.900000</td>\n",
              "      <td>1050.150000</td>\n",
              "      <td>29.990000</td>\n",
              "      <td>267.375000</td>\n",
              "      <td>290.080000</td>\n",
              "      <td>292.560000</td>\n",
              "      <td>304.485000</td>\n",
              "      <td>1176.890000</td>\n",
              "      <td>1123.615000</td>\n",
              "      <td>1181.035000</td>\n",
              "      <td>1155.965000</td>\n",
              "      <td>2.475000</td>\n",
              "      <td>55.340000</td>\n",
              "      <td>163.085000</td>\n",
              "      <td>1237.900000</td>\n",
              "      <td>11.960000</td>\n",
              "      <td>15.230000</td>\n",
              "      <td>70.080000</td>\n",
              "      <td>69.390000</td>\n",
              "      <td>-0.030000</td>\n",
              "      <td>-0.020000</td>\n",
              "      <td>21.500000</td>\n",
              "      <td>0.525000</td>\n",
              "      <td>-3.440000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>-318.070000</td>\n",
              "      <td>-330.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.530000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>705.000000</td>\n",
              "      <td>1529.900000</td>\n",
              "      <td>1432.900000</td>\n",
              "      <td>1522.100000</td>\n",
              "      <td>30.010000</td>\n",
              "      <td>289.760000</td>\n",
              "      <td>314.860000</td>\n",
              "      <td>317.460000</td>\n",
              "      <td>330.750000</td>\n",
              "      <td>1322.650000</td>\n",
              "      <td>1327.840000</td>\n",
              "      <td>1322.010000</td>\n",
              "      <td>1302.580000</td>\n",
              "      <td>8.780000</td>\n",
              "      <td>67.290000</td>\n",
              "      <td>167.760000</td>\n",
              "      <td>2225.200000</td>\n",
              "      <td>13.540000</td>\n",
              "      <td>16.100000</td>\n",
              "      <td>81.390000</td>\n",
              "      <td>79.290000</td>\n",
              "      <td>-0.010000</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>2.320000</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>-9.520000</td>\n",
              "      <td>-3.900000</td>\n",
              "      <td>101.900000</td>\n",
              "      <td>5.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>814.500000</td>\n",
              "      <td>1642.400000</td>\n",
              "      <td>1540.850000</td>\n",
              "      <td>1629.850000</td>\n",
              "      <td>30.010000</td>\n",
              "      <td>299.965000</td>\n",
              "      <td>322.860000</td>\n",
              "      <td>327.235000</td>\n",
              "      <td>341.645000</td>\n",
              "      <td>1346.820000</td>\n",
              "      <td>1347.425000</td>\n",
              "      <td>1353.805000</td>\n",
              "      <td>1322.390000</td>\n",
              "      <td>10.575000</td>\n",
              "      <td>68.660000</td>\n",
              "      <td>169.865000</td>\n",
              "      <td>2406.500000</td>\n",
              "      <td>15.650000</td>\n",
              "      <td>17.150000</td>\n",
              "      <td>97.520000</td>\n",
              "      <td>97.245000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>22.800000</td>\n",
              "      <td>4.905000</td>\n",
              "      <td>1.310000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>220.415000</td>\n",
              "      <td>216.500000</td>\n",
              "      <td>148.100000</td>\n",
              "      <td>7.730000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1365.000000</td>\n",
              "      <td>2203.500000</td>\n",
              "      <td>2089.900000</td>\n",
              "      <td>2178.800000</td>\n",
              "      <td>30.010000</td>\n",
              "      <td>319.640000</td>\n",
              "      <td>351.060000</td>\n",
              "      <td>348.560000</td>\n",
              "      <td>360.260000</td>\n",
              "      <td>1416.460000</td>\n",
              "      <td>1394.960000</td>\n",
              "      <td>1394.470000</td>\n",
              "      <td>1359.690000</td>\n",
              "      <td>15.520000</td>\n",
              "      <td>75.490000</td>\n",
              "      <td>173.800000</td>\n",
              "      <td>2618.100000</td>\n",
              "      <td>21.830000</td>\n",
              "      <td>21.090000</td>\n",
              "      <td>123.300000</td>\n",
              "      <td>126.200000</td>\n",
              "      <td>0.180000</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>22.550000</td>\n",
              "      <td>31.890000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>3669.790000</td>\n",
              "      <td>3858.300000</td>\n",
              "      <td>179.900000</td>\n",
              "      <td>12.560000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            AltAGL         AltB  ...        WndDr       WndSpd\n",
              "count  4467.000000  4467.000000  ...  4467.000000  4467.000000\n",
              "mean    621.904634  1447.365413  ...    61.420081     5.150486\n",
              "std     430.763101   419.003121  ...   103.837486     3.116676\n",
              "min       0.000000   825.500000  ...  -179.900000     0.000000\n",
              "25%     218.000000  1057.900000  ...     0.000000     2.530000\n",
              "50%     705.000000  1529.900000  ...   101.900000     5.250000\n",
              "75%     814.500000  1642.400000  ...   148.100000     7.730000\n",
              "max    1365.000000  2203.500000  ...   179.900000    12.560000\n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_Du3PqjQmx7"
      },
      "source": [
        "#cut the dataset to 1000 in the mid point\n",
        "data = dataset[(int(len(dataset)/2)-499):(int(len(dataset)/2)+501)]"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "yAq9ZBb2XowI",
        "outputId": "8bb4766b-4ae4-4769-bfea-7399c71323c6"
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AltAGL</th>\n",
              "      <th>AltB</th>\n",
              "      <th>AltGPS</th>\n",
              "      <th>AltMSL</th>\n",
              "      <th>BaroA</th>\n",
              "      <th>E1_CHT1</th>\n",
              "      <th>E1_CHT2</th>\n",
              "      <th>E1_CHT3</th>\n",
              "      <th>E1_CHT4</th>\n",
              "      <th>E1_EGT1</th>\n",
              "      <th>E1_EGT2</th>\n",
              "      <th>E1_EGT3</th>\n",
              "      <th>E1_EGT4</th>\n",
              "      <th>E1_FFlow</th>\n",
              "      <th>E1_OilP</th>\n",
              "      <th>E1_OilT</th>\n",
              "      <th>E1_RPM</th>\n",
              "      <th>FQtyL</th>\n",
              "      <th>FQtyR</th>\n",
              "      <th>GndSpd</th>\n",
              "      <th>IAS</th>\n",
              "      <th>LatAc</th>\n",
              "      <th>NormAc</th>\n",
              "      <th>OAT</th>\n",
              "      <th>Pitch</th>\n",
              "      <th>Roll</th>\n",
              "      <th>TAS</th>\n",
              "      <th>VSpd</th>\n",
              "      <th>VSpdG</th>\n",
              "      <th>WndDr</th>\n",
              "      <th>WndSpd</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.00000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1.000000e+03</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.00000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.00000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>561.461000</td>\n",
              "      <td>1390.146000</td>\n",
              "      <td>1290.12030</td>\n",
              "      <td>1379.260200</td>\n",
              "      <td>3.001000e+01</td>\n",
              "      <td>288.452540</td>\n",
              "      <td>313.248960</td>\n",
              "      <td>314.742510</td>\n",
              "      <td>327.743290</td>\n",
              "      <td>1282.929330</td>\n",
              "      <td>1266.607850</td>\n",
              "      <td>1288.068020</td>\n",
              "      <td>1261.800910</td>\n",
              "      <td>8.222110</td>\n",
              "      <td>64.386530</td>\n",
              "      <td>167.96197</td>\n",
              "      <td>1985.525900</td>\n",
              "      <td>13.536750</td>\n",
              "      <td>16.310060</td>\n",
              "      <td>79.746550</td>\n",
              "      <td>77.605200</td>\n",
              "      <td>-0.015680</td>\n",
              "      <td>0.041760</td>\n",
              "      <td>22.035700</td>\n",
              "      <td>2.953630</td>\n",
              "      <td>-4.810890</td>\n",
              "      <td>80.51300</td>\n",
              "      <td>15.046890</td>\n",
              "      <td>14.623800</td>\n",
              "      <td>48.646000</td>\n",
              "      <td>5.19748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>330.752944</td>\n",
              "      <td>324.377129</td>\n",
              "      <td>323.13947</td>\n",
              "      <td>323.082523</td>\n",
              "      <td>6.291450e-13</td>\n",
              "      <td>18.391257</td>\n",
              "      <td>20.713554</td>\n",
              "      <td>18.880194</td>\n",
              "      <td>19.545436</td>\n",
              "      <td>104.343063</td>\n",
              "      <td>127.395336</td>\n",
              "      <td>101.032753</td>\n",
              "      <td>95.315497</td>\n",
              "      <td>4.037312</td>\n",
              "      <td>6.513404</td>\n",
              "      <td>1.26322</td>\n",
              "      <td>513.563468</td>\n",
              "      <td>0.878951</td>\n",
              "      <td>1.000322</td>\n",
              "      <td>23.277238</td>\n",
              "      <td>25.217058</td>\n",
              "      <td>0.030784</td>\n",
              "      <td>0.115575</td>\n",
              "      <td>0.806713</td>\n",
              "      <td>3.644298</td>\n",
              "      <td>14.677612</td>\n",
              "      <td>26.30939</td>\n",
              "      <td>428.135224</td>\n",
              "      <td>458.946867</td>\n",
              "      <td>120.928823</td>\n",
              "      <td>3.17479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>829.900000</td>\n",
              "      <td>740.60000</td>\n",
              "      <td>829.800000</td>\n",
              "      <td>3.001000e+01</td>\n",
              "      <td>251.720000</td>\n",
              "      <td>270.110000</td>\n",
              "      <td>276.990000</td>\n",
              "      <td>287.500000</td>\n",
              "      <td>990.490000</td>\n",
              "      <td>919.110000</td>\n",
              "      <td>1007.920000</td>\n",
              "      <td>984.870000</td>\n",
              "      <td>1.780000</td>\n",
              "      <td>49.060000</td>\n",
              "      <td>164.99000</td>\n",
              "      <td>779.800000</td>\n",
              "      <td>9.600000</td>\n",
              "      <td>13.410000</td>\n",
              "      <td>2.970000</td>\n",
              "      <td>-0.580000</td>\n",
              "      <td>-0.120000</td>\n",
              "      <td>-0.200000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>-5.200000</td>\n",
              "      <td>-58.460000</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-1103.340000</td>\n",
              "      <td>-1169.300000</td>\n",
              "      <td>-179.900000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>230.750000</td>\n",
              "      <td>1074.900000</td>\n",
              "      <td>970.87500</td>\n",
              "      <td>1060.100000</td>\n",
              "      <td>3.001000e+01</td>\n",
              "      <td>273.025000</td>\n",
              "      <td>300.205000</td>\n",
              "      <td>302.092500</td>\n",
              "      <td>314.555000</td>\n",
              "      <td>1285.855000</td>\n",
              "      <td>1264.075000</td>\n",
              "      <td>1281.207500</td>\n",
              "      <td>1259.027500</td>\n",
              "      <td>5.282500</td>\n",
              "      <td>64.232500</td>\n",
              "      <td>167.25750</td>\n",
              "      <td>1924.950000</td>\n",
              "      <td>13.040000</td>\n",
              "      <td>15.700000</td>\n",
              "      <td>73.485000</td>\n",
              "      <td>72.672500</td>\n",
              "      <td>-0.030000</td>\n",
              "      <td>-0.030000</td>\n",
              "      <td>21.500000</td>\n",
              "      <td>0.517500</td>\n",
              "      <td>-10.477500</td>\n",
              "      <td>75.00000</td>\n",
              "      <td>-251.810000</td>\n",
              "      <td>-279.500000</td>\n",
              "      <td>-27.550000</td>\n",
              "      <td>2.55000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>737.000000</td>\n",
              "      <td>1563.900000</td>\n",
              "      <td>1456.85000</td>\n",
              "      <td>1545.950000</td>\n",
              "      <td>3.001000e+01</td>\n",
              "      <td>293.890000</td>\n",
              "      <td>315.900000</td>\n",
              "      <td>317.250000</td>\n",
              "      <td>330.765000</td>\n",
              "      <td>1320.115000</td>\n",
              "      <td>1327.470000</td>\n",
              "      <td>1331.555000</td>\n",
              "      <td>1303.950000</td>\n",
              "      <td>8.680000</td>\n",
              "      <td>67.145000</td>\n",
              "      <td>168.08500</td>\n",
              "      <td>2204.100000</td>\n",
              "      <td>13.570000</td>\n",
              "      <td>16.220000</td>\n",
              "      <td>87.240000</td>\n",
              "      <td>85.385000</td>\n",
              "      <td>-0.020000</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>2.720000</td>\n",
              "      <td>-0.320000</td>\n",
              "      <td>89.00000</td>\n",
              "      <td>16.115000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>5.30000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>793.000000</td>\n",
              "      <td>1616.900000</td>\n",
              "      <td>1514.02500</td>\n",
              "      <td>1603.150000</td>\n",
              "      <td>3.001000e+01</td>\n",
              "      <td>299.407500</td>\n",
              "      <td>323.667500</td>\n",
              "      <td>325.175000</td>\n",
              "      <td>339.372500</td>\n",
              "      <td>1337.792500</td>\n",
              "      <td>1341.317500</td>\n",
              "      <td>1348.705000</td>\n",
              "      <td>1315.287500</td>\n",
              "      <td>9.580000</td>\n",
              "      <td>68.105000</td>\n",
              "      <td>168.80000</td>\n",
              "      <td>2296.900000</td>\n",
              "      <td>14.110000</td>\n",
              "      <td>16.880000</td>\n",
              "      <td>94.940000</td>\n",
              "      <td>93.572500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.072500</td>\n",
              "      <td>22.500000</td>\n",
              "      <td>5.052500</td>\n",
              "      <td>1.712500</td>\n",
              "      <td>97.00000</td>\n",
              "      <td>245.512500</td>\n",
              "      <td>241.175000</td>\n",
              "      <td>143.000000</td>\n",
              "      <td>7.58000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1071.000000</td>\n",
              "      <td>1879.900000</td>\n",
              "      <td>1792.20000</td>\n",
              "      <td>1881.300000</td>\n",
              "      <td>3.001000e+01</td>\n",
              "      <td>317.980000</td>\n",
              "      <td>347.390000</td>\n",
              "      <td>345.990000</td>\n",
              "      <td>358.460000</td>\n",
              "      <td>1415.330000</td>\n",
              "      <td>1391.750000</td>\n",
              "      <td>1393.230000</td>\n",
              "      <td>1358.850000</td>\n",
              "      <td>15.410000</td>\n",
              "      <td>72.030000</td>\n",
              "      <td>170.97000</td>\n",
              "      <td>2488.700000</td>\n",
              "      <td>15.820000</td>\n",
              "      <td>20.170000</td>\n",
              "      <td>110.780000</td>\n",
              "      <td>109.190000</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>23.800000</td>\n",
              "      <td>13.600000</td>\n",
              "      <td>31.890000</td>\n",
              "      <td>113.00000</td>\n",
              "      <td>1168.790000</td>\n",
              "      <td>1232.300000</td>\n",
              "      <td>179.900000</td>\n",
              "      <td>12.56000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            AltAGL         AltB  ...        WndDr      WndSpd\n",
              "count  1000.000000  1000.000000  ...  1000.000000  1000.00000\n",
              "mean    561.461000  1390.146000  ...    48.646000     5.19748\n",
              "std     330.752944   324.377129  ...   120.928823     3.17479\n",
              "min       0.000000   829.900000  ...  -179.900000     0.00000\n",
              "25%     230.750000  1074.900000  ...   -27.550000     2.55000\n",
              "50%     737.000000  1563.900000  ...   100.000000     5.30000\n",
              "75%     793.000000  1616.900000  ...   143.000000     7.58000\n",
              "max    1071.000000  1879.900000  ...   179.900000    12.56000\n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYI3wuYOUgDa"
      },
      "source": [
        "def df_to_np_array(df): \n",
        "    \"\"\" This function will turn the dataframe to numpy array\n",
        "    Parameter: dataframe\n",
        "    Return: Numpy array\n",
        "    \"\"\"\n",
        "    examples = []\n",
        "    examples.append(df.iloc[:, :].values)\n",
        "    \n",
        "    return np.stack(examples)\n",
        "\n",
        "def get_slice_random_segment(length):\n",
        "    \"\"\"This function will acquire a length of slice from the dataset.\n",
        "    Parameter: length, length of the dataset\n",
        "    return: array\n",
        "    \"\"\"\n",
        "    def slice_random_segment(x):\n",
        "      \"\"\"This function will return the specific array\n",
        "      Parameter: x, dataset\n",
        "      return: array\n",
        "      \"\"\"\n",
        "      #minval = min numbers of data points, maxval = max numbers of data points\n",
        "      start = tf.random.uniform(shape=[], minval=0, maxval= BASE_SEQ_LEN-length, dtype=tf.int64)\n",
        "      x = x[start:start+length]\n",
        "      print(x)\n",
        "      #reshape will turn x into the shape of (length, NUM_VAR)\n",
        "      x = tf.reshape(x, (length, NUM_VAR))\n",
        "      print(x)\n",
        "      return x \n",
        "    return slice_random_segment\n",
        "\n",
        "def get_split_xy(y_length):\n",
        "  \"\"\"This will get two specific group of data points.\n",
        "  Parameter: y_length\n",
        "  return: x, y \n",
        "  \"\"\"\n",
        "  def split_xy(x):\n",
        "    \"\"\"\n",
        "    Parameter: dataset\n",
        "    \"\"\"\n",
        "    y = x[-y_length:]\n",
        "    return x[:-y_length], y \n",
        "  return split_xy\n",
        "\n",
        "def get_dataset(train_data, shuffle = False, repeat = False): \n",
        "    train_data = df_to_np_array(train_data)\n",
        "    print(train_data)\n",
        "    ds = tf.data.Dataset.from_tensor_slices(train_data)\n",
        "    print(ds)\n",
        "    ds = ds.map(get_slice_random_segment(length = INPUT_SEQ_LEN + OUTPUT_SEQ_LEN))\n",
        "    ds = ds.map(get_split_xy(y_length=OUTPUT_SEQ_LEN))\n",
        "\n",
        "    #Changing the value of buffer_size affects how uniform the shuffling\n",
        "    ds = ds.shuffle(512) if shuffle else ds \n",
        "    ds = ds.repeat() if repeat else ds.repeat(2)\n",
        "    ds = ds.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "    return ds \n",
        "\n",
        "  \n",
        "def get_detection_xy(df , scaler):\n",
        "    \"\"\"get the testing dataset\n",
        "    Parameter: dataset, number of simulation run, the scaler you use in the training process\n",
        "    return: x:slice of dataset(testing), y:target value\n",
        "    \"\"\"\n",
        "    \n",
        "    scaled = scaler.transform(df.iloc[:, :])\n",
        "\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(BASE_SEQ_LEN - INPUT_SEQ_LEN - OUTPUT_SEQ_LEN):\n",
        "        x.append(scaled[i:i+ INPUT_SEQ_LEN])\n",
        "        y.append(scaled[i+INPUT_SEQ_LEN: i + INPUT_SEQ_LEN + OUTPUT_SEQ_LEN])\n",
        "\n",
        "    x = np.stack(x)\n",
        "    y = np.stack(y)\n",
        "\n",
        "    return x,y \n",
        "    \n",
        "    \n",
        "def get_mse(model, df, scaler):\n",
        "    \"\"\" Get loss value: the mean squared error value\n",
        "    Parameter: dataset, simulation run, model\n",
        "    Return: loss value\n",
        "    \"\"\"\n",
        "    x, y = get_detection_xy(df, scaler) \n",
        "    y_pred_1 = model.predict(x, verbose = True)\n",
        "    mse_1 = tfk.losses.MSE(y, y_pred_1).numpy()\n",
        "    return mse_1.flatten()\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvg0_Hu1y392"
      },
      "source": [
        "def train_model(df, model):\n",
        "  \"\"\"This function is to tain the model\n",
        "  Parameter: df, model\n",
        "  Return: trained model, and trained scaler\n",
        "  \"\"\"\n",
        "  train_df = df[:]\n",
        "\n",
        "\n",
        "  scaler = preprocessing.MinMaxScaler()\n",
        "  scaler.fit(train_df.iloc[:, :].values)\n",
        "\n",
        "  train_df.iloc[:, :] = scaler.transform(train_df.iloc[:, :].values)\n",
        "  train_ds = get_dataset(train_df, shuffle = True, repeat=True)\n",
        "\n",
        "  model.fit(\n",
        "      train_ds, \n",
        "      epochs = 20,\n",
        "      steps_per_epoch = 1000,\n",
        "  )\n",
        "\n",
        "  return model, scaler"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQb-V1Dzy3Q1"
      },
      "source": [
        "def get_result( model, baseline, scaler):\n",
        "  \"\"\"This function is to get and plot the result\n",
        "  Paramter: baseline, simrun, trained model, and trained scaler\n",
        "  \"\"\"\n",
        "\n",
        "  mse_model_1 = get_mse(model, data, scaler)\n",
        "  # mse_model_2 = get_mse(model, faulty_testing, scaler, simrun)\n",
        "  pd.DataFrame({'normal' : mse_model_1, 'baseline': baseline}).plot(ylim = (0.0, 1))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpoMG2kTVwkk"
      },
      "source": [
        "# MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17mCyV75Vxnj"
      },
      "source": [
        "#LSTM\n",
        "def get_model_1():\n",
        "    with strategy.scope():\n",
        "      model = tf.keras.Sequential([\n",
        "                              tf.keras.Input(shape  = (INPUT_SEQ_LEN, NUM_VAR)),\n",
        "                              tfkl.LSTM(64, return_sequences=True), \n",
        "                              tfkl.LSTM(64, return_sequences=False),\n",
        "                              tfkl.RepeatVector(OUTPUT_SEQ_LEN), \n",
        "                              tfkl.LSTM(64, return_sequences=True),\n",
        "                              tfkl.Dense(NUM_VAR, activation = 'relu')\n",
        "\n",
        "      ])\n",
        "\n",
        "      model.compile(optimizer = tfk.optimizers.Adam(learning_rate=1e-4), loss = \"mse\" )\n",
        "\n",
        "      return model "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fK_QybpXJLE"
      },
      "source": [
        "#LSTM\n",
        "def get_model_2():\n",
        "    with strategy.scope():\n",
        "      model = tf.keras.Sequential([\n",
        "                              tf.keras.Input(shape  = (INPUT_SEQ_LEN, NUM_VAR)),\n",
        "                              tfkl.LSTM(64, return_sequences=True), \n",
        "                              tfkl.LSTM(64, return_sequences=True),\n",
        "                              tfkl.LSTM(64, return_sequences=False),\n",
        "                              tfkl.Dropout(0.5),\n",
        "                              tfkl.RepeatVector(OUTPUT_SEQ_LEN), \n",
        "                              tfkl.LSTM(64, return_sequences=True),\n",
        "                              tfkl.Dense(NUM_VAR, activation = 'relu')\n",
        "\n",
        "      ])\n",
        "\n",
        "      model.compile(optimizer = tfk.optimizers.Adam(learning_rate=1e-4), loss = \"mse\" )\n",
        "\n",
        "      return model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRYdT0dDXKkF"
      },
      "source": [
        "#GRU\n",
        "def get_model_3():\n",
        "    with strategy.scope():\n",
        "      model = tf.keras.Sequential([\n",
        "                              tf.keras.Input(shape  = (INPUT_SEQ_LEN, NUM_VAR)),\n",
        "                              tfkl.GRU(64, return_sequences=True), \n",
        "                              tfkl.GRU(64, return_sequences=False),\n",
        "                              tfkl.RepeatVector(OUTPUT_SEQ_LEN), \n",
        "                              tfkl.GRU(64, return_sequences=True),\n",
        "                              tfkl.Dense(NUM_VAR, activation = 'relu')\n",
        "\n",
        "      ])\n",
        "\n",
        "      model.compile(optimizer = tfk.optimizers.Adam(learning_rate=1e-4), loss = \"mse\" )\n",
        "\n",
        "      return model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeTl-WGfXLp9"
      },
      "source": [
        "#GRU\n",
        "def get_model_4():\n",
        "    with strategy.scope():\n",
        "      model = tf.keras.Sequential([\n",
        "                              tf.keras.Input(shape  = (INPUT_SEQ_LEN, NUM_VAR)),\n",
        "                              # tfkl.Conv1D(64, 5, 1),\n",
        "                              tfkl.GRU(64, return_sequences=True), \n",
        "                              tfkl.GRU(64, return_sequences=True),\n",
        "                              tfkl.GRU(64, return_sequences=False),\n",
        "                              tfkl.Dropout(0.5),\n",
        "                              tfkl.RepeatVector(OUTPUT_SEQ_LEN), \n",
        "                              tfkl.GRU(64, return_sequences=True),\n",
        "                              tfkl.Dense(NUM_VAR, activation = 'relu')\n",
        "\n",
        "      ])\n",
        "\n",
        "      model.compile(optimizer = tfk.optimizers.Adam(learning_rate=1e-4), loss = \"mse\" )\n",
        "\n",
        "      return model \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVEOOjUrzpTV"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiXkOhmvGdN-",
        "outputId": "f2b3c92d-ca33-4f52-95d7-dc2d719747e8"
      },
      "source": [
        "model = get_model_1()\n",
        "model, scaler = train_model(data ,model)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0.33239963 0.34666667 0.33919741 ... 0.23280313 0.68788216 0.54219745]\n",
            "  [0.32026144 0.32952381 0.32978319 ... 0.23771652 0.68982768 0.53423567]\n",
            "  [0.31185808 0.32       0.32065424 ... 0.24591939 0.692607   0.52388535]\n",
            "  ...\n",
            "  [0.73762838 0.74380952 0.72613161 ... 0.29018155 0.75541968 0.66321656]\n",
            "  [0.7264239  0.73809524 0.71500571 ... 0.19999167 0.74819344 0.64171975]\n",
            "  [0.7124183  0.72761905 0.70074173 ... 0.11967022 0.7409672  0.61783439]]]\n",
            "<TensorSliceDataset shapes: (1000, 31), types: tf.float64>\n",
            "Tensor(\"strided_slice:0\", shape=(None, 31), dtype=float64)\n",
            "Tensor(\"Reshape:0\", shape=(33, 31), dtype=float64)\n",
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 38s 33ms/step - loss: 0.1247\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0819\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 35s 35ms/step - loss: 0.0792\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.0627\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0441\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0268\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0265\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0262\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0261\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.0259\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.0259\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0258\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 36s 36ms/step - loss: 0.0257\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0157\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.0131\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0131\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0130\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.0129\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0130\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zKt7Huv5EXz",
        "outputId": "9b48c730-3711-4759-9ee5-e24788ccdb5d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 32, 64)            29952     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 1, 64)             0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 1, 64)             33024     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1, 52)             3380      \n",
            "=================================================================\n",
            "Total params: 99,380\n",
            "Trainable params: 99,380\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udkNvGQ94iaN",
        "outputId": "6be8c771-3f03-4e6b-ca38-4e011a266c15"
      },
      "source": [
        "model_2 = get_model_2()\n",
        "model_2, scaler = train_model(fault_free_training ,model_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 22s 9ms/step - loss: 0.0540\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0334\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0298\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0254\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0250\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0248\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0247\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0246\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0245\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0245\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0244\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0244\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0244\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0243\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0243\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0242\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0242\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0240\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0239\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0miziwu-IFFy",
        "outputId": "02c30bb6-e38f-40e7-d0ee-ad604f60fc31"
      },
      "source": [
        "model_2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_3 (LSTM)                (None, 32, 64)            29952     \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 32, 64)            33024     \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "repeat_vector_1 (RepeatVecto (None, 1, 64)             0         \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 1, 64)             33024     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1, 52)             3380      \n",
            "=================================================================\n",
            "Total params: 132,404\n",
            "Trainable params: 132,404\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JADcr2h8sXd",
        "outputId": "c996ae4f-a96f-468f-d45c-8093bd7e4256"
      },
      "source": [
        "model_3 = get_model_3()\n",
        "model_3, scaler = train_model(fault_free_training ,model_3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 15s 8ms/step - loss: 0.1008\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0798\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0701\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0432\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0406\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0401\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0399\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0396\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0393\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0367\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0344\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0343\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0342\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0341\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0340\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0340\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0339\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0339\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0339\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0338\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bHxkaoxJABL",
        "outputId": "75117b35-00b0-4e4f-eef3-4226d7cc1688"
      },
      "source": [
        "model_3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru (GRU)                    (None, 32, 64)            22656     \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 64)                24960     \n",
            "_________________________________________________________________\n",
            "repeat_vector_2 (RepeatVecto (None, 1, 64)             0         \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 1, 64)             24960     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1, 52)             3380      \n",
            "=================================================================\n",
            "Total params: 75,956\n",
            "Trainable params: 75,956\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKuTGtBO9gRb",
        "outputId": "8d4b137f-3015-4a8a-e3da-7def0ea580b0"
      },
      "source": [
        "model_4 = get_model_4()\n",
        "model_4, scaler = train_model(fault_free_training ,model_4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 17s 9ms/step - loss: 0.0501\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0288\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0270\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0265\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0262\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0258\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 0.0250\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0202\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0199\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0197\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0196\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0194\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0192\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0191\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0190\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0188\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0188\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0187\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0187\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5teNnNaJdtE",
        "outputId": "f7f297e9-74e1-42f4-df15-3180c3193222"
      },
      "source": [
        "model_4.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_3 (GRU)                  (None, 32, 64)            22656     \n",
            "_________________________________________________________________\n",
            "gru_4 (GRU)                  (None, 32, 64)            24960     \n",
            "_________________________________________________________________\n",
            "gru_5 (GRU)                  (None, 64)                24960     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "repeat_vector_3 (RepeatVecto (None, 1, 64)             0         \n",
            "_________________________________________________________________\n",
            "gru_6 (GRU)                  (None, 1, 64)             24960     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1, 52)             3380      \n",
            "=================================================================\n",
            "Total params: 100,916\n",
            "Trainable params: 100,916\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8ER43tSKLaE"
      },
      "source": [
        "# Get the result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO3uDBQidyqe"
      },
      "source": [
        "baseline = 0.1\n",
        "run = 1\n",
        "models = [model, model_2, model_3, model_4]\n",
        "\n",
        "\n",
        "for i in range(len(models)):\n",
        "  get_result(models[i], 0.1, scaler, run)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "0Abiny02NA2k",
        "outputId": "0abd3d7f-471a-4f64-8114-8556130972fc"
      },
      "source": [
        "baseline = 0.1\n",
        "run = 1\n",
        "\n",
        "get_result(model, 0.1, scaler)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 3s 59ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD8CAYAAABthzNFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd5hU5dn48e8923tjl7aUpfeiC4KFoqioEbtiiRoTSxJ+RvOm6JtEE6OJJa+JJiaRRGyJGqPvG7GCCogFkUUpUpZeFljY3tvMPL8/5swwu8zuzu5OA+7Pde3FzGlzDrN77vO0+xFjDEoppVRbtnCfgFJKqcikAUIppZRPGiCUUkr5pAFCKaWUTxoglFJK+aQBQimllE9+BQgRmSsihSKyQ0Tu8bH+hyKyWUQ2iMiHIjLIa91NIrLd+rnJa/mpIrLROuaTIiKBuSSllFKBIJ2NgxCRKGAbcC5QBKwBrjXGbPbaZjaw2hhTLyLfBWYZY64RkUygAMgHDLAWONUYUyEiXwB3AquBd4AnjTHvBvwKlVJKdYs/JYipwA5jzC5jTDPwCnCJ9wbGmOXGmHrr7edArvX6fOB9Y0y5MaYCeB+YKyJ9gVRjzOfGFaFeAC4NwPUopZQKkGg/tukP7Pd6XwSc1sH23wbcJQFf+/a3fop8LD+GiNwG3AaQlJR06qhRo/w4ZaWUUm5r164tNcZkd3U/fwKE30TkBlzVSTMDdUxjzEJgIUB+fr4pKCgI1KGVUuqkICJ7u7OfP1VMB4ABXu9zrWVtT2AO8DNgnjGmqZN9D3C0GqrdYyqllAoffwLEGmC4iOSJSCwwH1jsvYGITAaexhUcjnitWgKcJyIZIpIBnAcsMcYcAqpFZJrVe+lG4I0AXI9SSqkA6bSKyRhjF5EFuG72UcAiY8wmEXkAKDDGLAYeA5KBf1u9VfcZY+YZY8pF5Ne4ggzAA8aYcuv194DngARcbRbag0kppSJIp91cI4m2QSh18mhpaaGoqIjGxsZwn8pxIz4+ntzcXGJiYlotF5G1xpj8rh4voI3USikVKEVFRaSkpDB48GB0HG3njDGUlZVRVFREXl5eQI6pqTaUUhGpsbGRrKwsDQ5+EhGysrICWuLSAKGUilgaHLom0P9fGiCUUkr5pAFCKaUi1ODBgyktLQ3b52uAUEqpILDb7eE+hR7TAKGUUu3Ys2cPo0eP5tZbb2Xs2LGcd955NDQ0sG7dOqZNm8aECRO47LLLqKioAGDWrFncdddd5Ofn88QTTzBr1izuvvtu8vPzGT16NGvWrOHyyy9n+PDh/PznP/d8zqWXXsqpp57K2LFjWbhwYbgu9xjazVUpFfF+9eYmNh+sDugxx/RL5f6Lx3a63fbt23n55Zf529/+xtVXX83rr7/Oo48+yh//+EdmzpzJfffdx69+9Sv+8Ic/ANDc3Ix7vNabb75JbGwsBQUFPPHEE1xyySWsXbuWzMxMhg4dyt13301WVhaLFi0iMzOThoYGpkyZwhVXXEFWVlZAr7c7tAShlFIdyMvLY9KkSQCceuqp7Ny5k8rKSmbOdOUkvemmm1i5cqVn+2uuuabV/vPmzQNg/PjxjB07lr59+xIXF8eQIUPYv9+V7PrJJ59k4sSJTJs2jf3797N9+/ZQXFqntAShlIp4/jzpB0tcXJzndVRUFJWVlR1un5SU5HN/m83W6lg2mw273c6KFSv44IMPWLVqFYmJicyaNStiRo9rCUIppbogLS2NjIwMPv74YwBefPFFT2miO6qqqsjIyCAxMZGtW7fy+eefB+pUe0xLEEop1UXPP/88d9xxB/X19QwZMoRnn32228eaO3cuf/3rXxk9ejQjR45k2rRpATzTntFkfUqpiLRlyxZGjx4d7tM47vj6f+tusj6tYlJKKeWTBgillFI+aYBQSinlkwYIpZRSPmmAUEop5ZNfAUJE5opIoYjsEJF7fKyfISJfiohdRK70Wj5bRNZ5/TSKyKXWuudEZLfXukmBuyyllFI91WmAEJEo4CngAmAMcK2IjGmz2T7gZuAl74XGmOXGmEnGmEnA2UA9sNRrkx+71xtj1nX/MpRSKvD27NnDuHHjgnLsFStW8I1vfAOAxYsX8/DDDwflc3rCn4FyU4EdxphdACLyCnAJsNm9gTFmj7XO2cFxrgTeNcbUd/tslVLqBDRv3jxPzqZI4k8VU39gv9f7ImtZV80HXm6z7CER2SAivxeROF87KaVUONntdq6//npGjx7NlVdeSX19PQ888ABTpkxh3Lhx3HbbbbgHHD/55JOMGTOGCRMmMH/+fADq6uq45ZZbmDp1KpMnT+aNN9445jOee+45FixYAMDNN9/MnXfeyemnn86QIUN47bXXPNs99thjTJkyhQkTJnD//fcH/dpDkmpDRPoC44ElXovvBYqBWGAh8FPgAR/73gbcBjBw4MCgn6tSKgK9ew8UbwzsMfuMhws6r9YpLCzkmWee4YwzzuCWW27hz3/+MwsWLOC+++4D4Jvf/CZvvfUWF198MQ8//DC7d+8mLi7Ok9TvoYce4uyzz2bRokVUVlYydepU5syZ0+FnHjp0iE8++YStW7cyb948rrzySpYuXcr27dv54osvMMYwb948Vq5cyYwZM3r+f9EOf0oQB4ABXu9zrWVdcTXwf8aYFvcCY8wh49IEPIurKusYxpiFxph8Y0x+dnZ2Fz9WKaV6ZsCAAZxxxhkA3HDDDXzyyScsX76c0047jfHjx7Ns2TI2bdoEwIQJE7j++uv5xz/+QXS06/l76dKlPPzww0yaNMmTqXXfvn0dfuall16KzWZjzJgxHD582HOcpUuXMnnyZE455RS2bt0a9LTg/pQg1gDDRSQPV2CYD1zXxc+5FleJwUNE+hpjDomIAJcCX3fxmEqpk4UfT/rB4rpFtX7/ve99j4KCAgYMGMAvf/lLT3rut99+m5UrV/Lmm2/y0EMPsXHjRowxvP7664wcObLVcdw3fl+804K7q6+MMdx7773cfvvtgbq0TnVagjDG2IEFuKqHtgCvGmM2icgDIjIPQESmiEgRcBXwtIhscu8vIoNxlUA+anPof4rIRmAj0At4sOeXo5RSgbVv3z5WrVoFwEsvvcSZZ54JQK9evaitrfW0ETidTvbv38/s2bN55JFHqKqqora2lvPPP58//vGPnhv9V1991a3zOP/881m0aBG1tbUAHDhwgCNHjvT08jrkVxuEMeYd4J02y+7zer0GV9WTr3334KNR2xhzdldOVCmlwmHkyJE89dRT3HLLLYwZM4bvfve7VFRUMG7cOPr06cOUKVMAcDgc3HDDDVRVVWGM4c477yQ9PZ1f/OIX3HXXXUyYMAGn00leXh5vvfVWl8/jvPPOY8uWLUyfPh2A5ORk/vGPf5CTkxPQ6/Wm6b6VUhFJ0313j6b7VkopFXQaIJRSSvmkAUIpFbGOpyrwSBDo/y8NEEqpiBQfH09ZWZkGCT8ZYygrKyM+Pj5gxwzJSGqllOqq3NxcioqKKCkpCfepHDfi4+PJzfXZobRbNEAopSJSTEwMeXl54T6Nk5pWMSmllPJJA4RSSimfNEAopZTySQOEUkopnzRAKKWU8kkDhFJKKZ80QCillPJJA4RSSimfNEAopZTySQOEUkopnzRAKKWU8kkDhFJKKZ/8ChAiMldECkVkh4jc42P9DBH5UkTsInJlm3UOEVln/Sz2Wp4nIqutY/5LRGJ7fjlKKaUCpdMAISJRwFPABcAY4FoRGdNms33AzcBLPg7RYIyZZP3M81r+CPB7Y8wwoAL4djfOXymlVJD4U4KYCuwwxuwyxjQDrwCXeG9gjNljjNkAOP35UBER4GzgNWvR88Clfp+1UkqpoPMnQPQH9nu9L7KW+SteRApE5HMRcQeBLKDSGGPv7Jgicpu1f4FOHKKUUqETigmDBhljDojIEGCZiGwEqvzd2RizEFgIkJ+fr3MPKqVUiPhTgjgADPB6n2st84sx5oD17y5gBTAZKAPSRcQdoLp0TKWUUsHnT4BYAwy3eh3FAvOBxZ3sA4CIZIhInPW6F3AGsNm4ZiFfDrh7PN0EvNHVk1dKKRU8nQYIq51gAbAE2AK8aozZJCIPiMg8ABGZIiJFwFXA0yKyydp9NFAgIutxBYSHjTGbrXU/BX4oIjtwtUk8E8gLU0op1TPiepg/PuTn55uCgoJwn4ZSSh1XRGStMSa/q/vpSGqllFI+aYBQSinlkwYIpZRSPmmAUEop5ZMGCKWUUj5pgFBKKeWTBgillFI+aYBQSinlkwYIpZRSPmmAUEop5ZMGCKWUUj5pgFBKKeWTBgillFI+aYBQSinlkwYIpZRSPmmAUEop5ZMGCKWUUj5pgFBKKeWTXwFCROaKSKGI7BCRe3ysnyEiX4qIXUSu9Fo+SURWicgmEdkgItd4rXtORHaLyDrrZ1JgLkkppVQgRHe2gYhEAU8B5wJFwBoRWWyM2ey12T7gZuBHbXavB240xmwXkX7AWhFZYoyptNb/2BjzWk8vQimlVOB1GiCAqcAOY8wuABF5BbgE8AQIY8wea53Te0djzDav1wdF5AiQDVSilFIqovlTxdQf2O/1vsha1iUiMhWIBXZ6LX7Iqnr6vYjEtbPfbSJSICIFJSUlXf1YpZRS3RSSRmoR6Qu8CHzLGOMuZdwLjAKmAJnAT33ta4xZaIzJN8bkZ2dnh+J0lVJK4V+AOAAM8Hqfay3zi4ikAm8DPzPGfO5ebow5ZFyagGdxVWUppZSKEP4EiDXAcBHJE5FYYD6w2J+DW9v/H/BC28Zoq1SBiAhwKfB1V05cKaVUcHUaIIwxdmABsATYArxqjNkkIg+IyDwAEZkiIkXAVcDTIrLJ2v1qYAZws4/urP8UkY3ARqAX8GBAr0wppVSPiDEm3Ofgt/z8fFNQUBDu01BKqeOKiKw1xuR3dT8dSa2UUsonDRBKKaV80gChlFLKJw0QSimlfNIAoZRSyicNEEoppXzyJ1mfUkoFzFsbDrJ6VzmXTu7HsJwU0hJiwn1Kqh0aIJRSIdPY4mDBS18B8OLne/nGhL786bpTunycD7ccJjcjkZF9UgJ9isqLBgilVMh8sOVwq/eHqhq7dZxvP+8aMLvn4Yt6fE6qfdoGoZQKmSWbXAFixY9mkRofjTGGnmRzOJ4yQRyPNEAopUKiscXBkk3F3DR9EIN7JfGds4bw5b5K/mfpts53bkd1oz2AZ6ja0gChlAqJL3aX02x3MmtkDgALZg/j7FE5PP/ZHprsjm4ds7S2KZCnqNrQAKGUComFK3eREBPF1LxMAGw24ZvTBlHTZGfVzrJuHbO4m20Yyj8aIJRSQedwGgr2lnNVfi5JcUf7xriDxaaD1d06bmFxTUDOT/mmAUIpFXS7SmppbHEyMTe91fKkuGj6psWz80htl46XFBsFwNbi7gUW5R8NEKpDO0tq+WxHabhPQx3nvj5YBcDY/qnHrBuSncTOkq4FCKfVeWnrcVSC2HywGqfz+Op1pQFCdegbT37CdX9frd0JI9ju0jrueX0DjS3da+gNhU0HqomNtjE0O/mYdUOzk9lVUtel3zGntW1hcQ12hzNg5xksW4urufDJjzn39x+F+1S6RAPECa7J7mB3aV23e4k0WDedfeX1gTwtFUD/+Hwvr6zZz4ur9ob7VNpVeLiGEb2TiYk69pYzPCeZmiY7h6v975HkNIY+qfE02Z3sKYv83831+ysB2FlSx4rCI2E+G//5FSBEZK6IFIrIDhG5x8f6GSLypYjYReTKNutuEpHt1s9NXstPFZGN1jGfFBHp+eWotn762gZm/24F33zmi26VAtITXXlySmubA31qKkAG90oCYOX2kjCfSfvK65rJSYn3uW5Eb1e6jIK95X4fz2lgTD9XddXx0A7x+pcHPK9vfnYN2w8fH1VjnQYIEYkCngIuAMYA14rImDab7QNuBl5qs28mcD9wGjAVuF9EMqzVfwFuBYZbP3O7fRWqXRsPuOp+v9hdTlFFQ5f3T4hxNQbWN+uApIhlBf5Iro+vamhpNynfpIHp5GYk8I/P/S8BOY1heG9XddXOI3UBOcdg2VtWxxe7y7n1rDwWzB4GwLeeWxPRVYJu0tlTpYhMB35pjDnfen8vgDHmtz62fQ54yxjzmvX+WmCWMeZ26/3TwArrZ7kxZpSv7dqTn59vCgoKunB5lnfvgeKNXd/vOGcwfLG7nNSEGKoaWhiWnUyv5LguHWNdUSWNLQ5G5KSQmRQbpDNVPVFc3cieMtdN8rS8TITIK4yv2VtOdnIcg7OSfK7fX1HPgcoGThmYQayPaihvBsPq3eXkpidwsKqR3qlxDMr0fdxwq2u2s+VQNca4GugTY6KpqG+m0CpBTBmcSVQnlSeNdgf7Y4fS+5o/kBrfvcy3IrLWGJPf1f38qWLqD+z3el9kLfNHe/v2t153ekwRuU1ECkSkoKQkcovQbsXVjRFT5G1scWKArKRYYqNslNV1fdSpzfrddWgjdcQyHP1u6psj76nUYHA4DVG29m+E7geXg5VdKOUKRIngiOCeQZX1LdidrtJOYoxr/EdG4tEHrYq6zqtuaxvtfLy9lCNdaKMJlIjP5mqMWQgsBFcJolsHueDhQJ5Sh6bd8zYAu++5kHA3q6zcVMztL67lP5edwUuf72X51iMU3DynS+f1q798xtq9Ffx6yji+OW1QEM9WddfbH+/iwbe3APDriZH3PR2pbmT+bz7k/tPG8K0z8nxukwC8+X8b+efqfTx57mTmTezX7vHsDifzf/YuP5o4gn+vLWLSgHSemD85SGffM4+8/BVrmyr49Htnt1qefKCKb/zxEy7v3Z/Hr57U4TE+/qqIB/61nuUdBNhg8acEcQAY4PU+11rmj/b2PWC97s4xjwu1TeGvs99hDT4amp3ExNw0yuqaOdCVJzS82iAi4HpOJsYYVm4r8aue2rtwdzgCU0+s2eNqfD5lYEaH2/3iG2OYMjiDO1/+iu//80uq6lt8bufu4ioiJMZGU9cUeaUmt22Ha3zOWTGufxqXTe7PB5sP02zvuJuu01rdWVVUMPgTINYAw0UkT0RigfnAYj+PvwQ4T0QyrMbp84AlxphDQLWITLN6L90IvNGN849YR2rCn0Rs55Fa+qTGkxIfwwRrBOuGoqouHSMu2vUrUheBVRcnquKqRvLufYcbF33BXa+s63RwlfuGmRof3e35FYLJnS+pvfYHt/iYKH5z2XgA3t54iNe+LPK5nTsgRtmE5Lgo6iL04aXF4WRnSa2nl1ZbM0dkU91oZ195x43sDk9ADPgpdqrTAGGMsQMLcN3stwCvGmM2icgDIjIPQESmiEgRcBXwtIhssvYtB36NK8isAR6wlgF8D/g7sAPYCbwb0CsLk/7pCQDsLgl/z4odJbUMy3H19BjVN4XYKJunP7a/3DefluNgMBLAntI6jlRH3k2yK/615miz3Xubinlzw8EOt3ffQEb2SeGrfRURN6ixor6ZKJuQEt95jfbw3ik8f8tUAPa3M/bG3eZgE1wliAjtYbentI4Wh2Fkn2MHBwIMyEwEOh9j5P4+O2rDCRa/xkEYY94xxowwxgw1xjxkLbvPGLPYer3GGJNrjEkyxmQZY8Z67bvIGDPM+nnWa3mBMWacdcwFJtJ+q7tplFWc7G7ysUDaXVLH0GzXU1tcdBSTBqazbOuRLo5Ydf3b0kkxONzsDiePLdnKrN+tYOpvPuTxpYURd6P0R2OLgxdW7WHywHR2/eZCslPiWPTJ7g5LEe7LvOKUXHaV1nHKr99nXwQNHiuvayEjMQabnze4mSOyGdE7mY+2lfgcJe1+aLGJkJEYQ0V9ZI7RcacPGZbtuwSRZ41f2Xa44zQj7v8CW4RWMakuiLfq7LvUGyMImuwOaprsZKcc7dZ68cR+bD9Sy9biGr9vnsdLCWLx+oM8tXwn4Oq19eSyHbyzsTjMZ9V1SzYVU1bXzJzRvbHZhP86dwTri6r45xf72t3HHTwuPyWX608bSEV9C48tLQzVKXeqoq65Vc8df9w4fTC7S+v460c7j1nnjpUiQu/UeA5XN0Xkw4B7ZHjfdN8DBDOTYhmQmcDv39/WYU8sdwnRFoa7tQaIAHN/0cVhruaotBr40r3+MC8a3xeAC574mNH3vccb6zrvF+AOEM2OyPsDdFu29TD/9e/1DM1OovDBuXzxszmkxEfz2c7jL8ng1weqiLIJt80YAsBV+QMY1SeFV9fsb3cf9w0k2iY8eOk4Lhrfl6/2VYTkfP1RXt9MRhfH0NwwbRDThmTyto8gb8zRKqbeqfE0251UtNOgHU6HqxuJtgmZHQTHWSNyaLI7OdzB/cJTxaQliOOf+4ba0RceCu5it/eTW2ZSLBdNcAWJxhYnP3hlHQ2dND67e1BEckK0F1btpU9qPC/dOo246CiibEKv5LjjcjrKTQerGdsv1ZOzKMomXJ0/gI0Hqni5nVKE++HTZhNEhJzUuHZ7AIVDZX1zhzfJ9kzNy6KwuPqYHoHuh7Aom5CV7DpuJFYzFVc1kp0S12HV2pwxvQE67F14tM1FA8Rxz/PEHeY6+4o61w0iI7H1yMtHr5jAJz+dzeWTXeMSO0tvEOlVTDuO1LCisITx/dPonXq0KO8ePX48McZYASKt1fIbpw9idN/Udr8rYwze96DkuGhqm+0RU+1SXtfS5RIEwCkD03EaKNjTOkeTdxVTsjX5UCT2ZNpbXs9AqyG6PbkZrk4tRRXttxl5PwCEmgaIAPM06jrDe0M9UuMqweSktk6tkRQXTW5GIr+7aiLDcpL5uJO5Htz3mJYIrWL691pXV8hLJ7ceiJ8aH91ugFi6qZjB97xNSQR0Rfa2p6yeqoYWxvZrPWdCdJSNK07pz6aD1T57oTmcptXTZVJcNMZExqhqYwwV9c1kJnU9RcS0IVlkJcXyakHr6jXvKib37HS1EVha3Fdez6CsjgOEu9djUXn7JQinV6+tUNMAEWDuJ25HmG+oBytdAaJPWoLP9TabcMbQLNbsLu9wUJ/D0wYRmSWIvaX1DMtJ5kKrfcUtLSGGqnaqHdw3nC8jqJ5+T2kds3+3AuCYAAFw1akD6JUcyx8+2HbMOqdp/XSZFEFP1dWNdhxO0+VGanB1+Jgzujef7mg9X7XnidqrBFETAdfaVm2jvd0EhW7xMVFkp8Sx+VD7vR6dkd7NVfnPXV/YEsb8ME12B+9sPERmUqznD8iXy07JpaHFwfyFq9rdJtKrmEprm8j2kYBwSHYy+8rrfdbFu29W/uTBCZWfvL7B83pUn2MDRFpiDDdMG8TywpJj2reOrWJy9aSLhNH87v/j7iZ67J0WT3VjS6tuvg6vRlv32IpILEE0O5zERnd+i71ofF/e21Tc/rgPo20QJwx3lUw4E4it3VPBxgNV/Pj8kR1uN2mAa3T11weq262OcV+GPUKrmEpqm+iVcmyAmDYkE6dxZaNty32zKo+ghs0BGa6qiJ/MHUmCNd9yW1MGZwKuWdS8ta1iSo5zPbVGQgqKch+dJboiNd5VXeZdQnAHCxGOtkFE2GA5h9OVoDA2yvd36e22GUOIibJx1qPLufPlr45Jr+LURuoThzswhLPXjzvdwvQhWZ1u++gVE4CjeZvacv9yRmIV096yOooqGhiYeWw1mruh9+sDx6YWcWcOXb3L/wlqgq3Z4SSvVxLfmzWs3W3cQeTGRa0nf3Ka1l0gk6wSRE1T+Bvp3SWI9MTupalOtapoqr0eYIx3FZNVgqiJsBKEu5OKPyWIfukJ/PDcEYBrPE/b7tnuhzStYjoBuKtk7GEsQbjHYPRJ8z1Ax9s0K4jsOOJ7splIrmJ64sPt2MRVP99WWkIMAzMT2XTw2ADh/kP7aFsJu0o6HsUaCtWNLby5/mCH1YEA/TMSPFVJP/r30SoppzGt8vQc7dkT/hJEk3WjbK9U1Bn3/AfVjUcDhNNr4FhcdBQxURIR1WneuhIgAO6YOZS757iCxPY2I6sd2kh94nA/3YQzQByqaiAjMcYzqrsj/TMSiI+xHfNL6ebplRVhAaK4qpG3Nxzi4on9PFNutjU+N42v9lUe093T6fX+051lbXcLuceXuhqeN/oo7XiLsgnbHrwAgO1eAd1pTMQ2UnvGLHSzesRd8ijzmvK2bZ18clx0xLVBNDlcwdnfAAHwgznDyUiMOSY3k7EeAMIxfYAGiABz//KGtYqpsrHd3kttRdmEEb1T2u1F4b65RsLTqLelm4tpsjv57syh7W4zY3gvDlU1srzNJPHeAaKmMbzVMB9vL+GFVXsAmDK443TY4OryevHEfq2qXJzGtLoBu0sQkfBUffRpv3s3t9FWg/3avUd7nJm2ASI+OiKCoTd3CSKuk9nx2uqfkcDavRWtxlE52ny/oaQBIsDcfxBOQ6dpmoPlUFUj/fyoXnKbNCCdz3aW+ZxI3f0EuLu0LqJGU3+2o4z+6QkMbyeVMsBlk3NJjI1iRWHrmQi9LyPcddfPfrqHjMRYPvnpbF789ml+7ZOVFEuZVw8sp2n9dBmRAaKbN7i0xBjOGJbFP1fv9ZRivbu5gqtRPtK6uXa1isltWHYyW4truOCJlZ7GaoczPA3UoAEi4Hx1xwu14upGv9of3O6YOZSYKOF7//zymKDm/bR9wzOrA3aOPeF0GlbvLvO0n7QnNtrGuH5pfLK9tFV3V/c1hbtqorHFwUfbSrji1FxyMxL9qhIE6JsWT02j3ZOewels3c01MTYKkUipYnL925Mn4FvOyKO0tplXrHxUR4OOa31yXFTEVTG5O3V0NUD8ZO4ohuUks7OkzvNgY4wJS6I+0AARcN7313B0DW1scVBe10zfLgSIfukJ/Oi8kWw/Usv6Nt1CjYELxvUB4PNd5ZTWhn/08fYjtVTUtzBtSGan294wfRC7Sus469FlNNndT2Su7yUtISasVUzldc04nIYh7bShtOec0TkAfGqNgnea1vM9iwgpcdGtqqHCxdNFswd3mrNH5dAvLZ4vdrt6nTk83Vy92iAiIBh685QguljF1C89gdfumE5aQgyPLdmKMdZ83lqCODF4j3+whyHdhruLq79tEG5nj3LddN5Yd7BNF0pDbLSNR690dYftLLlfKBTsdSN8ltcAACAASURBVN0oTsvrvBvvvIn9mD9lANWNdg5UuJ643d9RZpuqmlArtz67q3mKBmUlYZOjE+r4qoJIS3TlojLGhK2qE7wGtfWgC46IMLZ/Guv3uzoceM8oB5AcHxMRpSVv3a1iAlcG5ttnDmFnSR01TXbXSHkNECcG7yqZcAyWc7cjuCcK8leu1cf+uc/28Nt3t3qWO4xrEFai1U2xwY85koPNnUOpf4Z/QfDyU1zTn++1JtFxdwsd1z+Vdfsrw9ZDyx0gsroYIGKibAzMTOSjbe1XQaQnxLK/ooHJv36fH722PiDn2x097cXkNntkDvvK69l8qNoTDI5WMUVHXhuE9TsV08UShFs/6wHvSHXTMb3UQkkDRBc4nIYH39rMt579ot30vN7NDuFIcLfdGvDW3jy47UmIjeL2ma45CBau3MWhKnf9tuvpJcGqH4+EEkRVQwspcdF+P5WO6ptCSlw0z6/aA1jdQkWYM7o3NY123t98OHgn2wF3dV130lBclT+ADUVVlNY2ea7HW1pCDGv3VlBZ38L/ftn5vB/B0tNeTG7nj+1NlE149tM9/L+XvwLwJMJLiY+8bq7uyoPulpxyrOwA/7O00BopH6gz6xq/AoSIzBWRQhHZISL3+FgfJyL/stavFpHB1vLrRWSd149TRCZZ61ZYx3SvywnkhQXaa2uLuPnZL/j7J7tZXljCQh8zXUHrhulwlCBKappIiYv29IXvinsvGM2im/OBo1VV7jw/ngARASWI6ga7Z4StP1LjY7hj1lBWFJbw2JKtOJyuJ9pZI3Pon57gafwMNXeVV7/0rlUHAuQPcnWJLdhTjsNHFUSOV/qRKJuErZQUqDQRWclxnD40i9fWFnGkpolRfVIYluN6CEqKjaahxcGiT3b3+HwDpadVa+7eee9+XcynO0vDMooa/AgQIhIFPAVcAIwBrhWRMW02+zZQYYwZBvweeATAGPNPY8wkY8wk4JvAbmPMOq/9rnevN8YcIUJtLa7mR/9ez8fbXY2C/dMT2k2T7V3FFI4/yrK6Zs8kKt2Rk+Jq3D5iTZformKKswJE2zwx4VDd2NKlAAFww2mDAHh97QGryO76471wfB9W7SwNSx12UUUD2Slxfvde8nbKoAzSEmJYvrXEKkG0Xn/xxH6e1w6n8QSjUHMXogPRyOqdW8zdUA+Qaf2+P/DW5ohpi3BYRYju3tizU+JYctcMAHaV1EV0G8RUYIcxZpcxphl4BbikzTaXAM9br18DzpFjh/1da+173GlbRJ8/ZQC7Suo8cy54824QPOvR5Zz+2w9DOj91aU2TJ9dQd7h7P+0pqwOOppJOiKAAUVnfTGp810pIaYkx/PLiMRRXN7KrpNZzwxrVJ5UWh2Hs/UvY5mMcSDAdrmmkT6r/vc28xUTZmJCbxhd7yn1mpXV3AXZPDLXb+j5DLRC9mNwm5Kaz6zcX8u87pnvSUgBccUp/5lkBMRJ62UFguvcOzU7yBP5IDhD9Ae8yeJG1zOc2xhg7UAW07WJyDfBym2XPWtVLv/ARUAAQkdtEpEBECkpKSnxtEnR7y+oY0TuZH547gkeuGM9ZI7IBPN3uvDnN0UlAAA5WNXY6a1ugOJ2GrcXV7aae8EdWchxj+qaydJNrLmBPFVOENFIbY9hxpJYhXWyEBzh7lGt6xw+2HMEdxk8ddHT08medTJ4UaOV1zd1Ogw1w1vBe7C6t47OdZewsaR0AEmKj2PPwRdx74WgA9paGJ0AEoheTN5tNmDI4k2ivxt/E2GguP8V1S4qUSaC8p0Xtrugom+dhL2KrmAJBRE4D6o0xX3stvt4YMx44y/r5pq99jTELjTH5xpj87OzsEJztsaobXBN/3HnOcK6ZMpBx/VJJio3ymQ3UaQynDsrwpNIGVxExFEpqm6iob2Gi12d3xwXj+vDlvkq+2ldBTaO9VSN1uGcpK6lxXePILjbCAwzMSmRCrivLq/s6BvdKYvdvLyQ1PvqYm2ywldU2d7kHk7dvnzmESyb163CbXsmxJMVGsaes/SktgylU8ym7q0a3tZNTLNQCESDgaAeGMBUg/AoQBwDvdJm51jKf24hINJAGeGdBm0+b0oMx5oD1bw3wEq6qrIhU3djiySoJrsh+yqAM1uzxESCcrnED//n+GSy9ewZpCTEhy1XvbvOI60bfa2+zRrrqdy/782c02Z3YBE9a5XD3Fim0qoFG9Ol6gAC454JRxywTEfqkxfusMgymnpYgomzCE/Mnd7iNiDC4V5KnyjDUnAG6UXZmZJ8UxvVP5fH3CyOimuloyalnx3EnK4zkEsQaYLiI5IlILK6b/eI22ywGbrJeXwksM9ZoKxGxAVfj1f4gItEi0st6HQN8A/iaCOWrUXTK4Ey2Ftewr6yeD7y6SXrn5h/RO4Xx/dNC9tTtDEC9J7iyoHo3ckbZbCTFRmGT1mmXw8H9hNjVbrxu3oHeW+/UeA5Xh+7G0tDsoKHF4WlgDabBWUnsCVMVU9u8ScESZRPumTua0trmiJjn42hg7FmEcE+0FLEjqa02hQXAEmAL8KoxZpOIPCAi86zNngGyRGQH8EPAuyvsDGC/MWaX17I4YImIbADW4SqB/K3HVxMk1Q32YxpF3SOPZzy2nO+8UMBu6w/Q0WbQUmJsVMh6VrhHbkdH9fyX6cn5k5g71pVi4+opuYgIqQkxYU9ut/1wDZlJsd1uiE9pp3G7f3pCu1M+BkNZnSsY9aSKyW39/efx1S/ObXf94F6JFFU0hKVX3dHU3MH/rPFW9aF7DE9lfTNLNhW3O1tiMNkDNEAw2+qu3J0R2YHgV1cQY8w7wDttlt3n9boRuKqdfVcA09osqwNO7eK5hoXTaajxUYIY1z+NSyf14z/rDgJwsLKBnJQ4q1H36C9FYmxUyBp2e5o505uI8KfrJtNod3qyg6bEhze/jzGGVbvKGN8/rdvHSGmnBDEsJ5lX1uyntLZnvcD8Ve6Zq7nnn5XWSZffQVlJ2J2Gg5UNDMrqfgeG7nAnEgzFXAap8dEkxkZxsLKR4qpGrvv75+wqqWNM31Te/H9nhrSaJlC9twZmugYDnjW8V09PqVu6PprqJFPX7MqF4qtq4tErJzK6byq/fXcr1/99NTZxFam9n1gS46JDNpeCo4ejN9uKjrKR7FWJmhofE9bcRTVNdvaW1XPd1IHdPkZ7JYjB1o3zQEVDiANE96bi7Io8q1fbrpK6kAcIR5tEgsEkIvRNi2fRp7tZ9OluYqNtJMdFs/lQNX9ctp27vLrGBpu75BTdwwhxVf4AKuqbO5yKNpg01UYnqq0qldSEY28ssdE2vnPWEC6e2I8pgzO41OpznufVzTQpNor6EDVSu6uYglXfO2VwJqt3l4ctA6p7VrHslO7fwNvLjdPLOmaoGjjdDw3JccEPEKP6pCACq3aFfvY8VwkidE/u3iX9v1x/Cht/eR5zRufw7Kd7QjqGxx6gEkRaQgw/Pn9UtzIjBIIGiE64q1Taa9yMsgl/vHYy/77jdB6/ehJf/eJc7jxnuGd9Ymw09c2OkGTUdDdSRwfpie3iif1otjtZvP6gz/XBbsAud9fbB+EJ390WEKoA4X5oSOzmXM1dkRIfw5nDevH8Z3tC3sOnbSryYHOn2P/TdZM5Z3RvRISbTh9MVUMLK7eFbhyVM0BtEOGmAaITngDhZ2qHjKTYVk+pocyCGuhBSW2dMjCdiblpPL50GyU1Ta3Sgm85VM2EXy5l8D1v8+SH24Py+aW13ct+6g93qSRUA63cvw8JIQgQAPdfPJYmu5NZj63gva8PheQzIfSzof328vFMHJDO1MFH5wqZMjiT2CgbBV7TlgZboMZBhJsGiE54qpjaKUF0JtE9gXwIqpnc+V+ClRpYRLj3wtGU1TUz5aEPyLv3HX791maAVmNCHn9/W1ASFR6ttw98gIiPiaJXciz7y0OTFsXd9TkUJQhwNcLfe8EoapvsPP7+tpB8JuAzT1QwjeufxhvfP4McrxQm8TFRjM9N8zluKVg0QJwkjpYgulcHmBQbujTZjiBXMYErx8+MEUdHtD/zyW4+21nK1uIa0hJi+Olc10C0wuLA5zUKZoAAV4+RveWhGS9Qb3V9jo8OTYAAuH3mUH5+0Wi2Ha5tN119oDmcoa1ias8ZQ7NYv78yZIMhg12aDxUNEJ1w16t3uwQRa5UgQtCTKVRpDV64ZSp7Hr6ITb86n7xeSdy06AteWr2PMX1T+caEvgBBqcYorW0iOS66W9lPvf3gnOHcMO3YnlCDspLYF6KUFPXNDhJiokI+EcxMK7h/HKL6+FD2YurItKFZOA3sOBKaVByh+lsMNg0QnahucD3ptdc9sjNJce4cRqGoYgrtU0tSXDR/vynfMzHSmH6p5GYkMGd0Dn9duYtVOwPba6airpmMAHQLvfvcETx46fhjlg/MTORQdaNn7upgqm9xhKx6yduwnGSSYqPYGoQSni+h7sXUHnfX5fIQddN2N1IHszQfChogOlHd2EJSbFSr7JFd4b4J1IWiiikMxdqh2cmeKqex/VIRER6+YgKDMhP5zvNrAtq1sMVhujwJfFcMykrEGELSDtFid4ZldKyIMDQnmZ0loXmSDnUvpva4qyVDFSDs2gZxcqhu6PrkNN7cVUz1IUi30dNJSrrrO2fmcfaoHOaOc6Xm6JUcx20zhlDX7OBwdeDqfINdn+2ewnJfCNohwlk3PyAjMWQTCIW6F1N7MhJjETnaEy7Y3POeh2IEeTBpgOhEdWNLp6kMOpLkDhAhbKQOdd/rGSOyWXTzFE8wBO+BZ4H7g3T4mHs5kNyjqbeHIGW0w5iwVT/0SYvnUFVjq27KweJwOiPiKTrKJqQnxHjG0gSbwxm+7zeQNEB0wpWorwcliBO4DaIj2cmBH5ncNs9VoGUlxzEsJ5lPQjBxkN1pQt5A7dY3LZ6GFoenfS2YGlucxMdExm0mKzkuZFVMjghpe+mpyPjmIpgr1Xf3h7mHtA0iggJEMOp8Q1EtM3NENqt3lQc9oDvD+ITpGRRYG/wun412R497nQVKZlKsJ11LsKzfX8mP/r2eJntklJx6SgNEJ9pOFtRV8dFRiISoDSJAk5QEgrvdJpDZXx0meIMA3WaNzKbZ4eTTHcHNW2R3mh7PFdBd7h49JTXBf5puaI6cAJGVFBv0EsQfl23ntbVFPPfZnoi57p6IgFtJ5DLGUFLT1KOBWTabkBgTFZISRKAmKQmEpNgoomwS0Fz8TqchAFNddOi0vCx6p8bxrzX7gvo5rtJQUD+iXb2CUP3Xnka7M2JulJlJsUHNRvzqmv18sOWI572v2QuPN+G/k0SwsrpmGluc5GYk9Og4iXHRIZmqM1CTlASCiJCWEBPQBH6hqGKKjbYxZ3RvPttZFtRBc46wliBCl5iwsdlBQgS1QVTUNwclDUx1Yws/eX0DAJdM6sf6+87j6vwBnewV+SLjm4tQB610BP3SexYgBmUmsiME/c4DNUlJoKTGR1MVwIbQYPdicvvWGYMxBn7xRvBmwXWEoDTUnozEWKJsEqISRGRVMRnjmmku0J7/dA8AixecwRPzJ5OWGPw07qEQIbeSyOSur8zq4bzBEwek8/WBqqBP+RioSUoCJS0hJqBtEM4QjR0YlpPCt84YzEfbSnj6o53Yg/C92Z3OsH1PNpuQlRRLaYjaIBIiJED0SXMl8NsVhPm51+6rYEzfVCbkpgf82OHk12+oiMwVkUIR2SEi9/hYHyci/7LWrxaRwdbywSLSICLrrJ+/eu1zqohstPZ5UiJwRIm7/rwn4yAAJg1Ip8nuZNPB6kCcVrsCNUlJoKQmxAS0DSKUeX0umeSa/Om3727l+VV7A358pzO8vc2yU+IoDuAgxvY0tkROCWL60CxiooT3Nx8GYO3eioCN9C+rbSYnNfgzEYZap7cSEYkCngIuAMYA14rImDabfRuoMMYMA34PPOK1bqcxZpL1c4fX8r8AtwLDrZ+53b+M4DgaIHpWgjhreC9io228vraIX7+1mYUrdwbi9I7hsJ50I6ENAlwBItAliFD1LR/ZJ8Xz+u0NvidI6gl7mAeQje2Xyrr9lTTbg1eq3VtWR3Wj3TOvcrilxsdw1vBs/vfLItbuLeeKv3zGt55dE5Bjh2ou81Dz51lzKrDDGLPLGNMMvAJc0mabS4DnrdevAed0VCIQkb5AqjHmc+MazvkCcGmXzz7IquoDU4JIT4zlwnF9ePHzvTzzyW5+885WNh2sCsQpttJsBYi4CHliC3gjdYjz+jxzUz4pcdF8ua8y4LmLHCa8JYiLJvSjqqGFR9/bymNLtvJpEAYHfrWvEoAzhvUK+LG766bTB1Na28wVf1kFuKZh3X64Z4kLG5odlNY29Wgq3EjlT4DoD+z3el9kLfO5jTHGDlQBWda6PBH5SkQ+EpGzvLYv6uSYAIjIbSJSICIFJSWhmzIQXCWIxNiogCRV+85ZQ0iMjWJE72T6pMZz1yvrAp7qwP00GMyEdl2RZlUxBeo6Q53X55zRvfnwRzOJtgmvfBHYbq8OpzOsqRhmDO/FJZP68fdPdvPU8p1c//fVAWtraWh2sLOklrv+tQ5oPUd7uJ0+NKtVr8Rom/CHD3o2A+JH20pocRjOjKBAGCjBvpMcAgYaYyYDPwReEpHUrhzAGLPQGJNvjMnPzs7ufIcAqmzoWR4mb+P6p7Hh/vNYctcM7poznO1Hains4ZNLW+4AEROu7jFtDM5KpMVhWqX9bnE4+e27W7qVl98ZhrEDOSnxnDM6h//76kBAG6vtjvCl2gBXN+TfXz2JMX2P/jm+sa7nVWl2h5Orn17FOf/zEeBKkx+OrLXtiYmysfxHs3j2W1N46TunccuZeby3qZiiiu53aV629TBpCTGclpfZ+cbHGX++uQOAd4feXGuZz21EJBpIA8qMMU3GmDIAY8xaYCcwwto+t5Njhl1VAAMEQHSUDRFh5kj3pC2BLdY3OVwppCOlvf/0oa4nquv+vprbXiigtsnOxgNVPP3RLuY8/hF1XRxdHq7JZy4/JZfS2mY+3h6478sZxmR9bjab8M/vnMaim/MZ3TeVPy3f0eMg+Ma6g2w8cLT69P27Z/b0NAMuJsrG7JE5nD6sF9dMcd3anv5oV7eOVVbbxBvrDpI/KKPbUwJEMn+uaA0wXETyRCQWmA8sbrPNYuAm6/WVwDJjjBGRbKuRGxEZgqsxepcx5hBQLSLTrLaKG4E3AnA9AVVVH9gA4dY3LYHhOcms3B7YKrOmFidxEfS0NiAzkZe+cxpT8zJZuvkw1zy9iv/78uhzwNLNxV06Xrgmn5k9Mof0xBj+96vAPcOEM1mft4ykWM4e1ZsfnDOc3aV1vP5lUec7dWBvmasL6ap7z2b9/ed5upZGqqHZycwakc3H3fxb/OOyHbQ4nNxyZl6AzywydHo3sdoUFgBLgC3Aq8aYTSLygIjMszZ7BsgSkR24qpLcXWFnABtEZB2uxus7jDHumcO/B/wd2IGrZPFugK4pYAJdgvB21vBsvthdHrBudtWNLTTZHREVIABOH9aLV2+fzq/mjWXTwWpe/Hwv4/unkRwXzRe7uzaJvDNEA+Xaio22cfGEfizdVMzByoYefWfldc2c8z8r2FVSF/YShLfzxvRmbL9U7ntjU4+qW0pqm8lKiqVvWkLQ/nYC7azhvdhTVt+tkfMfby9h1siciGqIDyS/7ibGmHeMMSOMMUONMQ9Zy+4zxiy2XjcaY64yxgwzxkw1xuyylr9ujBlrdXE9xRjzptcxC4wx46xjLjChSE7fRY324E0LedaIXjTZnazZ07WbpC9Op2HCL5fy8hf7I6aBuq0bpw/ipumDyB+UwQu3TGVqXqZfAeKNdQd4e4Nrfutwzm9861lDaHE4Of3hZcx8bDll3RyF/OGWw+wscT1lR1K2T5tNePLayTQ7nLy2tnulCGMMe8vqjrvunmdZMyJ+sOWwz/WltU0cqDx2giVjDAcqGxiaHTmN8IEWmXeTCNFidwatXvG0vExio2ws39rzaqZKr7EGkdQg6E1E+NUl43jtu6eTkRTL1LxMdpbUdZru4QevrOP7L33J1uJqnGGcnWxgViJ3njOcc8f0pryumT8t3wG4bhKvry2ixs/uvN6PQZEyXsVtaHYyUwdnsnDlLjYWVXUp8+naveUM/9m7fLazjNmjcoJ4loE3pFcSkwaks+jT3a3Ghdzz+gbG3vce+Q9+wBkPL+O9rw+12q+myU5ji5OclMiuRuuJyLybRIhmhyEmSAEiMTaa2aOy+c+6AzTZe1bN5P00G6opFXtqxnDXU9sLn+3xuf7xpYWMu3+J5/2j7xWGNQMqwF1zRvC3G/M5c1gvPiosYUXhEfLufYf/+vd6vvfPL/06hsMrQkRHSG8zbz+/aAyNLQ4u/tMnzP3DSr/TwyxcuQu70/Dw5eP56dyRQT7LwBIR7j53BEUVDbxsdWcur2vmlTX7qWt2kD8oA4C/f7y71X6Hq1wj0U/EEdRuGiA6YHc6iQ3iH/EN0wZRXtfMe193rbHWW01jCz94ZZ3nfW0I5p0IhDH9Ujl/bG9e+HzvMYPpVhQe4cllO6htsjN/ygAun9yfVTvLaHFExiQsE3LT2V1Wx6sFR4cHfby9lLV7Kzrcb3dpHff+70bP+0iccWx8bhrv/mAGeb2SOFLTxJedXJPbx9tLuWHaQOZPHRgxvei6YuaIbCYNSOeR97ay40gNKwpdabufvXkKr333dO6YOZSCvRVs9kqX4+6qPaRXcljOORQ0QHQgmFVMAGcM7cWgrER+/p+v2XHk2DERNVbDc0ee+WQ3mw8FN8dTsHx31jBqG+0seOkrz7J9ZfX84JV1DOmVROGDc3n4ignMHJlNQ4uDsrrmiLipjuqTgjHwzsZizhvTm3/fMZ2YKOFvK4/tKlnfbOfJD7ezu7SOX725qdW6SMlR1NbIPim8fOs0AL/G6jS2OKhvdtA3rWdZj8PtJ+e7Sj5zHl/JD19dD7jGLwHcMG0gAJ/tPNrVeUtxDTaB4b01QJyUWpzBq2ICV8Pgby8fT0yUjfkLP29VVbTpYBX5D37A7MdWUFLTfj39ntI6BmQmsPu3F/LJT2ez8sezg3a+gTZpQDp3zRnOym0lFFXUU1rbxK/f3kxVQwt/mD+JuGjXDdQ7Q2YklCDOGd2b4Tmum8JFE/oyZXAm3zrDNeBqQ1Flq21Xbivh8fe3Me9Pn7C7tHUDbk/TyAdT79Q4UuOjKSyuocnuYPnWI5z9uxX84j9fHzN+pTpASS3D7fRhvXjsyomAK5nhn66b7EmfkZuRyJDsJB58ewufWWlJth6qJq9XUsQG+kDQANEOYwwtDmfQRyWfPrQXL986jdLaZk/9J8C7G4tpsjs5WNXIS6vbT/NQVtdMVlIcIkJuRiIDsyIjMZq/zhndG4CXVu9j9u9W8P7mw1x/2sBWQWFwVqLn5hMJJYjYaBuv3j6dx6+eyDcm9ANgwdnDiI2y8c7G1tWFRRWu3i81jXb2ltVz6aR+3HqWq898sHrIBYKIMLJPCoXFNTz76R6+9dwadpXW8eLnexl7/xK++4+1HKlx1cG7O0mknwBzIFw0oS9rfjaHL/77HM936zZvouv9dX9fDcDW4hpG9e1SYojjzkkRIAqLa/hoW9d6CzmcBmMIagnCbWSfFMb2S2Xx+oOeSX+WbT3CKQPTmTggnRXbjrS7b5nV7/x4NbJ3CpMGpPPnFTupabRz5znDuf/isa22EREm5LqK+pFQggDXALPLT8n1nE9qfAxDspOOqSrcfLCaKJvQ3yot9E1P4K45I1gwexiXTOp3zHEjyZTBmazdV8HD724FICEmipG9U+iXFs+7Xxcz9aEPqaxvptQq4WYkHr+/h96yU+J8tqN86wxXYO+TGk9tk5195fWM9sr6eyI6KQLEr97cxH//78YuTTXonlshFAECYP7UgWw7XMuOklpeWLWHzYequWhCP2aOyGbd/kqfjc+V9c3sLauL+NGqHbHZhP++cLTn/TenDfLZVXfaEFfux46q28Itr1cSmw5We9JVVNW38OaGg1w6qT8f/2Q2i27O59qpA0iKi+ZH548kMTY6zGfcsZutmfUArj9tIFt+PZcld8/gs3vP4bLJrtyaq3aWUbC3AhFXCvETWVpCDHfPGcHhmka+2udqvB/Z58S+5pMiQNwwbRAHKhs8PRP84U6dHarEd9OsRF8bi6p4a72rv/Vlk/sz2moQdacwcPvdkkImPfA+dc0Ovjl9UEjOMVim5mXy8OXj+dmFo9tNmXzt1IH0TYtnxojQJmzsiosm9OVQVSOfWHXUSzcX0+Iw3HT6IGw24exRvSM+KHjLSYnnJ1aX1dtnDG217uErxtM3LZ4/r9jJwpW7GNsvlfQTpATRkbH9UjEG/vOVK7HhqBO8BHH8/Lb2wLljepOTEseLn+/11Hl3xu4IbQliSHYyibFRvL/5MF/uq+COmUPJTIr1tCnsLatnbL80z/avrHG1Szx6xQRGnQBPMfOnDuxwfWZSLKvuPSdEZ9M9c0b3JtomfLG7nPH90/jxaxtIjotmfP+0zneOUN+bNYzvzRp2zPK46ChumDaIx5YUAjBrxPE1OK673L2aXv+yiKTYKE/V4YnqpChBxETZmD91ICsKS/j+S1966vk74h4gFKrBTFE2YVz/NN7b5GrkvM66YQ7Kcg3j32OVIBpbHMx8bDmltc38ZO5Irp4ywPcBVcjFx0TRNz2eA5UNvLne9YR54/RBx+W4AH+4G20Bbp85JIxnEjq9U+M42xopnpedFBEJF4PppAgQcPSG+/aGQ/xuaWGn2x+dWyF0/0WnD3XVsw/NTvaUHJLjoumVHMcuK3/PisIS9pbVMygrkatO1eAQaXolx/HGuoP88s3NjO2Xyk/mjgr3KQXNgMxEHr1yAk9eO5mU+OO/B5M/RITfXDae6UOy+NF5x9eI8e44aQJEZKjodQAAChhJREFUn7R4dv3mQuZNdM2idajq2ORb3tyN1KFMfnfj9MFMzctk/tTWN/6peRm8s/EQLQ4nb204SFZSLB/+cOYJOcXh8c49PgLgthkn/lP11fkDWpUkTgZ90uJ5+bZpzBp54lernRRtEG42m/Dj80eyeP1Bpv92GR//ZDYD2plQPdRVTOCqZ3/19unHLD97VG/e2VjM+v2VrNxWwtxxfU7IyUlOBPdfPJaZI3KYPSr7uGqQVsqXk+4uMyAzkWvyXU/ob2041O52LY7QVzG1x91T4rq/raa60X5SPLkcr5LiorloQl8NDuqEEP67Xxg8cuUExvRNZdlW3/nfAVo8vZjC3wg1rn8aKXHRNDuciMCZw0/MyUmUUpHlpAwQAGePyuHLfZXHZBJ1i6QSBMCDl40D4BsT+pF6kjQIKqXC66QtB581vBd/Wr6DVTvLOH9sn2PWe9ogbJERIC6Z1J/pQ7OO+4RoSqnjh193PxGZKyKFIrJDRO7xsT5ORP5lrV8tIoOt5eeKyFoR2Wj9e7bXPiusY66zfkJasT55YAaJsVHHTFbuTpPgrmKKjQ5/FZNbTkq8J8OpUkoFW6cBQkSigKeAC4AxwLUiMqbNZt8GKowxw4DfA49Yy0uBi40x44GbgBfb7He9NV/1JGOM/3kwAiA22sb0IVms3OZKi2CM4U/LtjPsZ++y2SufTqRUMSmlVKj5c/ebCuwwxuwyxjQDrwCXtNnmEuB56/VrwDkiIsaYr4wxB63lm4AEEYmYzvuzR+Wwr7yetzccYsW2En63dBsA/1qzL+KqmJRSKtT8ufv1B/Z7vS+ylvncxhhjB6qArDbbXAF8aYzxTsf5rFW99AsJQz6Ca6YMICsplseWbGWB15zCywqP0ByBVUxKKRVKIXk8FpGxuKqdbvdafL1V9XSW9fPNdva9TUQKRKSgpKRrczp0JibKxqmDMthTVk9ds4Nvn5nHzy8azf7yBg5YE71oCUIpdbLypxfTAcA790OutczXNkUiEg2kAWUAIpIL/B9wozFmp3sHY8wB698aEXkJV1XWC20/3BizEFgIkJ+f7/+EDn6685zhVDe2cNbwbG49a4gnz/vXB6oAiPExN4FSSp0M/AkQa4DhIpKHKxDMB65rs81iXI3Qq4ArgWXGGCMi6cDbwD3GmE/dG1tBJN0YUyoiMcA3gA96fDXdMK5/Gq/cdjS9xUhr1PLbG12jrCNhoJxSSoVDp4/HVpvCAmAJsAV41RizSUQeEJF51mbPAFkisgP4IeDuCrsAGAbc16Y7axywREQ2AOtwBZ6/BfLCuis9MZbpQ442n8RoFZNS6iTl10A5Y8w7wDttlt3n9boRuMrHfg8CD7Zz2FP9P83Q+vaZeazaVQZoFZNS6uSldz8f5ozpzcRc18xRWsWklDpZnbSpNjrzz1unsf1wjY5cVkqdtLQE0Y7kuGgmD8wI92kopVTYaIBQSinlkwYIpZRSPmmAUEop5ZMGCKWUUj5pgFBKKeWTBgillFI+aYBQSinlkwYIpZRSPmmAUEop5ZMGCKWUUj5pgFBKKeWTBgillFI+aYBQSinlkwYIpZRSPmmAUEop5ZMGCKWUUj75FSBEZK6IFIrIDhG5x8f6OBH5l7V+tYgM9lp3r7W8UETO9/eYSimlwqvTACEiUcBTwAXAGOBaERnTZrNvAxXGmGHA74FHrH3HAPOBscBc4M8iEuXnMZVSSoWRPyWIqcAOY8wuY0wz8ApwSZttLgGet16/BpwjImItf8UY02SM2Q3ssI7nzzGVUkqFUbQf2/QH9nu9LwJOa28bY4xdRKqALGv552327W+97uyYAIjIbcBt1ttaESn045x96QWUdnPf451e+8lJr/3k5OvaB3XnQP4EiLAyxiwEFvb0OCJSYIzJD8ApHXf02vXaTzZ67YG5dn+qmA4AA7ze51rLfG4jItFAGlDWwb7+HFMppVQY+RMg1gDDRSRPRGJxNTovbrPNYuAm6/WVwDJjjLGWz7d6OeUBw4Ev/DymUkqpMOq0islqU1gALAGigEXGmE0i8gBQYIxZDDwDvCgiO4ByXDd8rO1eBTYDduD7xhgHgK9jBv7yWulxNdVxTK/95KTXfnIK2LWL60FfKaWUak1HUiullPJJA4RSSimfTooAcSKn9RCRASKyXEQ2i8gmEfmBtTxTRN4Xke3WvxnWchGRJ63/iw0ickp4r6DnrNH5X4nIW9b7PCvlyw4rBUystbzdlDDHIxFJF5HXRGSriGwRkekny/cuIndbv+9fi8jLIhJ/In/vIrJIRI6IyNdey7r8XYvITdb220XkJl+f5e2EDxAnQVoPO/BfxpgxwDTg+9b13QN8aIwZDnxovQfX/8Nw6+c24C+hP+WA+wGwxev9I8DvrdQvFbhSwUA7KWGOY08A7xljRgETcf0fnPDfu4j0B+4E8o0x43B1dJnPif29P4crXZG3Ln3XIpIJ3I9rUPJU4H53UGmXMeaE/gGmA0u83t8L3Bvu8wri9b4BnAsUAn2tZX2BQuv108C1Xtt7tjsef3CNofkQOBt4C5D/387Zs0YRRWH4ORCJGEETixC1SNLYGquIFqISIYi9CIr6B6wEsbIXsRNBsBCxUINFGsGPOmBANKDohohGEpNGBauIr8U9IbObWWTX6LAz54GBuR+wc+a9cPZ+zEv6irSrUX/Sqbn9ft/l/azoGNqMexsw1/j8VdCdNeeGPtdxEjhWdt2BQWCmXa2Bk8DNTH1dv7yr9DMI8q1CdjXp29H41HkEmAL6JS140yLQ7/dlex/XgYvALy/vAL5K+unlbHx1ljDAqiVMJzIELAO3fXntlpn1UAHdJX0GrgIfgQWSjtNUQ/csrWrd8hioQoKoBGa2FXgIXJD0Pdum9HehdOeZzew4sCRpuuhnKYAuYB9wQ9II8IO1JQag1Lr3ksw9h4CdQA/rl18qxb/SugoJovS2Hma2iZQc7kqa8OovZjbg7QPAkteX6X0cAE6Y2QeSI/Bh0rr8drd8gfr4mlnCdCLzwLykKS8/ICWMKuh+FJiTtCxpBZggjYUq6J6lVa1bHgNVSBCltvUwMyN9yf5G0rVMU9b+5Axpb2K1/rSfdBgFvmWmqR2FpEuSdksaJOn6TNIp4DnJ8gXWx55nCdNxSFoEPpnZHq86QnIsKL3upKWlUTPb4uN/NfbS695Aq1o/BsbMrNdnYWNe15yiN17+0+bOOPAOmAUuF/08GxzbQdLU8hXw0q9x0hrrU+A98ATo8/5GOtU1C7wmnQQpPI4NeA+HgEm/HyZ5ftWA+0C312/2cs3bh4t+7r+MeS/wwrV/BPRWRXfgCvAWmAHuAN1l1h24R9pvWSHNHs+3ozVwzt9DDTj7p98Nq40gCIIglyosMQVBEARtEAkiCIIgyCUSRBAEQZBLJIggCIIgl0gQQRAEQS6RIIIgCIJcIkEEQRAEufwG/Y/sgw9jogsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMtCI8ghFbu4"
      },
      "source": [
        "# Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPA-KyKOd1zE"
      },
      "source": [
        "#cross validation\n",
        "for train_split, val_split in KFold().split([i+1 for i in range(500)]):\n",
        "    train_df = fault_free_training[fault_free_training.simulationRun.isin(train_split)]\n",
        "    val_df = fault_free_training[fault_free_training.simulationRun.isin(val_split)]\n",
        "\n",
        "  \n",
        "    scaler = preprocessing.MinMaxScaler()\n",
        "    scaler.fit(train_df.iloc[:, 3:].values)\n",
        "\n",
        "    train_df.iloc[:, 3:] = scaler.transform(train_df.iloc[:, 3:].values)\n",
        "    val_df.iloc[:, 3:] = scaler.transform(val_df.iloc[:, 3:].values)\n",
        "\n",
        "    train_ds = get_dataset(train_df, shuffle = True, repeat=True)\n",
        "    val_ds = get_dataset(val_df)\n",
        "\n",
        "\n",
        "    model = get_model_1() \n",
        "\n",
        "\n",
        "    model.fit(\n",
        "        train_ds, \n",
        "        epochs = 20,\n",
        "        steps_per_epoch = 1000,\n",
        "        validation_data= val_ds,\n",
        "        \n",
        "    )\n",
        "\n",
        "    break\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}