{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TEP_DNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqh6bW0_Ea25"
      },
      "source": [
        "#pip install rpy2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcw1d9NpqsgP",
        "outputId": "750bae69-3fc9-491c-c6a2-5f85cd506509"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYji3iz5qt3n",
        "outputId": "c6936293-c2d9-4181-fa57-fec9a5ed5764"
      },
      "source": [
        " !pip install pyreadr"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyreadr in /usr/local/lib/python3.7/dist-packages (0.4.2)\n",
            "Requirement already satisfied: pandas>0.24.0 in /usr/local/lib/python3.7/dist-packages (from pyreadr) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>0.24.0->pyreadr) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>0.24.0->pyreadr) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>0.24.0->pyreadr) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>0.24.0->pyreadr) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYg5D5odEi46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ba07312-a1cb-42cf-9ac6-3af894aa9584"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pyreadr as py \n",
        "import tensorflow as tf\n",
        "import gc \n",
        "import itertools\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "gc.collect() \n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTRhw19eErTW"
      },
      "source": [
        "Load RData as Pandas DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ9s0MiFrjqq"
      },
      "source": [
        "a1 = py.read_r(\"drive/MyDrive/TEP_dataset/TEP_FaultFree_Training.RData\")\n",
        "fault_free_training = a1['fault_free_training']\n",
        "a1 = None \n",
        "a2 = py.read_r(\"drive/MyDrive/TEP_dataset/TEP_Faulty_Training.RData\")\n",
        "faulty_training = a2['faulty_training']\n",
        "a2 = None\n",
        "a3 = py.read_r(\"drive/MyDrive/TEP_dataset/TEP_FaultFree_Testing.RData\")\n",
        "fault_free_testing = a3['fault_free_testing']\n",
        "a3 = None \n",
        "a4 = py.read_r(\"drive/MyDrive/TEP_dataset/TEP_Faulty_Testing.RData\")\n",
        "faulty_testing = a4['faulty_testing']\n",
        "a4 = None "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsk9vh6PrnMY",
        "outputId": "7a46db74-e1ec-48e4-b3b5-bc704ae4421e"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4zgKpBSq-KQ"
      },
      "source": [
        "Get Data Stream Iterator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqM0vJvqrA5I"
      },
      "source": [
        "def get_input_fn(data_set, num_epochs = None, shuffle=True):\n",
        "    return tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
        "        x = data_set.drop(['faultNumber', 'simulationRun', 'sample'], axis=1),\n",
        "        y = data_set['faultNumber'],\n",
        "        num_epochs = num_epochs,\n",
        "        shuffle = shuffle\n",
        "        )\n",
        "\n",
        "def get_feature_cols(data_set):\n",
        "    return [tf.feature_column.numeric_column(key=k)\n",
        "           for k in data_set.drop(['faultNumber', 'simulationRun', 'sample'], axis=1).keys()]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTSXH8NmrF2Q"
      },
      "source": [
        "Simple Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymhhEE2urDz6"
      },
      "source": [
        "train_df = faulty_training.copy(deep=False)\n",
        "test_df = faulty_testing.copy(deep=False)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ww9Afd7rH1W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "914c0edc-274d-4f06-c36f-bbb173f21e53"
      },
      "source": [
        "regressor = tf.estimator.DNNRegressor(feature_columns=get_feature_cols(train_df), hidden_units=[20, 20])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp40_t2wf7\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp40_t2wf7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "np_TxP8prJ-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3014bb6-9bf6-42fb-ae08-367d9213b352"
      },
      "source": [
        "regressor.train(get_input_fn(train_df, 10), steps=500)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp40_t2wf7/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 52419.69, step = 0\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 61 vs previous value: 61. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 84 vs previous value: 84. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 60.7597\n",
            "INFO:tensorflow:loss = 105.44116, step = 100 (1.649 sec)\n",
            "INFO:tensorflow:global_step/sec: 94.768\n",
            "INFO:tensorflow:loss = 8.168355, step = 200 (1.054 sec)\n",
            "INFO:tensorflow:global_step/sec: 96.3569\n",
            "INFO:tensorflow:loss = 24.307144, step = 300 (1.040 sec)\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 396 vs previous value: 396. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "INFO:tensorflow:global_step/sec: 90.3152\n",
            "INFO:tensorflow:loss = 54.23652, step = 400 (1.106 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 500...\n",
            "INFO:tensorflow:Saving checkpoints for 500 into /tmp/tmp40_t2wf7/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 500...\n",
            "INFO:tensorflow:Loss for final step: 1.9018006.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn.DNNRegressorV2 at 0x7f5a2635d7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAmefaearLbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "237d136d-fffa-47c7-dc6e-3d93f6e3ff72"
      },
      "source": [
        "y = regressor.predict(input_fn = get_input_fn(test_df[:10], num_epochs=1, shuffle=False))\n",
        "predictions = list(p[\"predictions\"] for p in itertools.islice(y, 10))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp40_t2wf7/model.ckpt-500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6Xpbl4YrM3Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7195e79f-7d64-404b-8b34-92c627da3861"
      },
      "source": [
        "print (\"Prediction:\" + str([int(i[0]) for i in predictions]))\n",
        "print (\"Actual:\" + str(test_df['faultNumber'][:10].values))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction:[8, 9, 9, 9, 9, 8, 9, 9, 9, 9]\n",
            "Actual:[1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    }
  ]
}