{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TEP_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0laBdydQo_r"
      },
      "source": [
        "# SETUP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSqWdN-p6mdR",
        "outputId": "bef5a888-f3f8-415a-93dd-8df435421721"
      },
      "source": [
        "#link to the google drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0Go5LlWR96A",
        "outputId": "b0bb3617-a176-4dec-bfc6-93ed94a5f56e"
      },
      "source": [
        " #Check the package pyreadr.\n",
        " !pip install pyreadr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyreadr\n",
            "  Downloading pyreadr-0.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (409 kB)\n",
            "\u001b[K     |████████████████████████████████| 409 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>0.24.0 in /usr/local/lib/python3.7/dist-packages (from pyreadr) (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>0.24.0->pyreadr) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>0.24.0->pyreadr) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>0.24.0->pyreadr) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>0.24.0->pyreadr) (1.15.0)\n",
            "Installing collected packages: pyreadr\n",
            "Successfully installed pyreadr-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "088mMzSVOq0_"
      },
      "source": [
        "import pandas as pd \n",
        "import pyreadr as py \n",
        "import numpy as np \n",
        "import tensorflow as tf\n",
        "import gc \n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_probability as tfp\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn import preprocessing\n",
        "import matplotlib as plt\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "tfpl = tfp.layers\n",
        "tfd = tfp.distributions\n",
        "\n",
        "\n",
        "gc.collect() \n",
        "\n",
        "pd.options.mode.chained_assignment = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-i1wEAxZQmXo",
        "outputId": "ce4080db-dd31-4fb0-e8bd-aa8e896ffffb"
      },
      "source": [
        "#TPU\n",
        "\n",
        "import os\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "# Detect hardware, return appropriate distribution strategy\n",
        "try:\n",
        "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
        "    # set: this is always the case on Kaggle.\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TPU address is grpc://10.88.52.98:8470\n",
            "Running on TPU  grpc://10.88.52.98:8470\n",
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.88.52.98:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.88.52.98:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REPLICAS:  8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6qUuTklSyZq"
      },
      "source": [
        "# HYPER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ2J7rVBS0sJ"
      },
      "source": [
        "BASE_SEQ_LEN = 500\n",
        "NUM_VAR = 52\n",
        "INPUT_SEQ_LEN = 32 \n",
        "OUTPUT_SEQ_LEN = 1 \n",
        "BATCH_SIZE = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxSWs-yuQt3o"
      },
      "source": [
        "# READ DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y95pBl8_R_fh"
      },
      "source": [
        "a1 = py.read_r(\"drive/MyDrive/TEP_dataset/TEP_FaultFree_Training.RData\")\n",
        "fault_free_training = a1['fault_free_training']\n",
        "a1 = None \n",
        "a2 = py.read_r(\"drive/MyDrive/TEP_dataset/TEP_Faulty_Training.RData\")\n",
        "faulty_training = a2['faulty_training']\n",
        "a2 = None\n",
        "a3 = py.read_r(\"drive/MyDrive/TEP_dataset/TEP_FaultFree_Testing.RData\")\n",
        "fault_free_testing = a3['fault_free_testing']\n",
        "a3 = None \n",
        "a4 = py.read_r(\"drive/MyDrive/TEP_dataset/TEP_Faulty_Testing.RData\")\n",
        "faulty_testing = a4['faulty_testing']\n",
        "a4 = None "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4HuxdOdQLVy",
        "outputId": "36c7ec1c-d66b-4fa3-8901-d55398a7cdc9"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL5aYpYvMkW4"
      },
      "source": [
        "for col in fault_free_training.columns: \n",
        "    fault_free_training.loc[: , col] = fault_free_training.loc[: , col].astype('float32')\n",
        "\n",
        "for col in faulty_training.columns: \n",
        "    faulty_training.loc[: , col] = faulty_training.loc[: , col].astype('float32')\n",
        "\n",
        "for col in fault_free_testing.columns: \n",
        "    fault_free_testing.loc[: , col] = fault_free_testing.loc[: , col].astype('float32')\n",
        "\n",
        "for col in faulty_testing.columns: \n",
        "    faulty_testing.loc[: , col] = faulty_testing.loc[: , col].astype('float32')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BkqQupghw10",
        "outputId": "68e6c963-1de2-4600-fc2c-b24a2f503e30"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "238"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYI3wuYOUgDa"
      },
      "source": [
        "def df_to_np_array(df = fault_free_training): \n",
        "    \"\"\" This function will turn the dataframe to numpy array, only use for faulty free dataset\n",
        "    Parameter: dataframe\n",
        "    Return: Numpy array\n",
        "    \"\"\"\n",
        "    examples = []\n",
        "    for i in df.simulationRun.unique():\n",
        "        examples.append(df[df.simulationRun == i].iloc[:, 3:].values)\n",
        "    \n",
        "    return np.stack(examples)\n",
        "\n",
        "\n",
        "def get_slice_random_segment(length):\n",
        "    \"\"\"This function will acquire a length of slice from the dataset.\n",
        "    Parameter: length, length of the dataset\n",
        "    return: array\n",
        "    \"\"\"\n",
        "    def slice_random_segment(x):\n",
        "      \"\"\"This function will return the specific array\n",
        "      Parameter: x, dataset\n",
        "      return: array\n",
        "      \"\"\"\n",
        "      #minval = min numbers of data points, maxval = max numbers of data points\n",
        "      start = tf.random.uniform(shape=[], minval=0, maxval= BASE_SEQ_LEN-length, dtype=tf.int64)\n",
        "      x = x[start:start+length]\n",
        "      #reshape will turn x into the shape of (length, NUM_VAR)\n",
        "      x = tf.reshape(x, (length, NUM_VAR))\n",
        "      return x \n",
        "    return slice_random_segment\n",
        "\n",
        "def get_split_xy(y_length):\n",
        "  \"\"\"This will get two specific group of data points.\n",
        "  Parameter: y_length\n",
        "  return: x, y \n",
        "  \"\"\"\n",
        "  def split_xy(x):\n",
        "    \"\"\"\n",
        "    Parameter: dataset\n",
        "    \"\"\"\n",
        "    y = x[-y_length:]\n",
        "    return x[:-y_length], y \n",
        "  return split_xy\n",
        "\n",
        "def get_dataset(train_data, shuffle = False, repeat = False): \n",
        "    train_data = df_to_np_array(train_data)\n",
        "    ds = tf.data.Dataset.from_tensor_slices(train_data)\n",
        "    ds = ds.map(get_slice_random_segment(length = INPUT_SEQ_LEN + OUTPUT_SEQ_LEN))\n",
        "    ds = ds.map(get_split_xy(y_length=OUTPUT_SEQ_LEN))\n",
        "\n",
        "    #Changing the value of buffer_size affects how uniform the shuffling\n",
        "    ds = ds.shuffle(512) if shuffle else ds \n",
        "    ds = ds.repeat() if repeat else ds.repeat(2)\n",
        "    ds = ds.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "    return ds \n",
        "\n",
        "\n",
        "def get_detection_xy(df , simrun):\n",
        "    \"\"\"get the testing dataset\n",
        "    Parameter: dataset, number of simulation run\n",
        "    return: x:slice of dataset(testing), y:target value\n",
        "    \"\"\"\n",
        "    scaled = scaler.transform(df[df.simulationRun == simrun].iloc[:500, 3:])\n",
        "\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(BASE_SEQ_LEN - INPUT_SEQ_LEN - OUTPUT_SEQ_LEN):\n",
        "        x.append(scaled[i:i+ INPUT_SEQ_LEN])\n",
        "        y.append(scaled[i+INPUT_SEQ_LEN: i + INPUT_SEQ_LEN + OUTPUT_SEQ_LEN])\n",
        "\n",
        "    x = np.stack(x)\n",
        "    y = np.stack(y)\n",
        "\n",
        "    return x,y \n",
        "    \n",
        "def get_mse(df, simrun, model):\n",
        "    \"\"\" Get loss value: the mean squared error value\n",
        "    Parameter: dataset, simulation run, model\n",
        "    Return: loss value\n",
        "    \"\"\"\n",
        "    x, y = get_detection_xy(df, simrun) \n",
        "    y_pred_1 = model.predict(x, verbose = True)\n",
        "    mse_1 = tfk.losses.MSE(y, y_pred_1).numpy()\n",
        "    return mse_1.flatten()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpoMG2kTVwkk"
      },
      "source": [
        "# MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17mCyV75Vxnj"
      },
      "source": [
        "#CNN\n",
        "def get_model_1():\n",
        "    with strategy.scope():\n",
        "      model = tf.keras.Sequential([\n",
        "                              tf.keras.Input(shape  = (INPUT_SEQ_LEN, NUM_VAR)),\n",
        "                              tfkl.Conv1D(128, 5, 1), \n",
        "                              tfkl.MaxPool1D(2),\n",
        "                              tfkl.RepeatVector(OUTPUT_SEQ_LEN), \n",
        "                              tfkl.Dense(NUM_VAR, activation = 'relu')\n",
        "\n",
        "      ])\n",
        "\n",
        "      model.compile(optimizer = tfk.optimizers.Adam(learning_rate=1e-4), loss = \"mse\" )\n",
        "\n",
        "      return model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFUBEA3o6i7g"
      },
      "source": [
        "def train_model(df, model):\n",
        "  # train_df = fault_free_training\n",
        "  train_df = df\n",
        "\n",
        "  scaler = preprocessing.MinMaxScaler()\n",
        "  scaler.fit(train_df.iloc[:, 3:].values)\n",
        "\n",
        "  train_df.iloc[:, 3:] = scaler.transform(train_df.iloc[:, 3:].values)\n",
        "  train_ds = get_dataset(train_df, shuffle = True, repeat=True)\n",
        "\n",
        "  model.fit(\n",
        "      train_ds, \n",
        "      epochs = 20,\n",
        "      steps_per_epoch = 1000,\n",
        "  )\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQGCxcKmbhkg"
      },
      "source": [
        "model = get_model_1()\n",
        "model = train_model(fault_free_training, model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rffxPqc9bjvB"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8ER43tSKLaE"
      },
      "source": [
        "# Get the result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07UV9KE1DSkt"
      },
      "source": [
        "def get_result(model, baseline, simrun):\n",
        "  mse_model_1 = get_mse(fault_free_testing, simrun, model)\n",
        "  mse_model_2 = get_mse(faulty_testing, simrun, model)\n",
        "  pd.DataFrame({'normal' : mse_model_1, 'with_fault' : mse_model_2, 'baseline': baseline}).plot(ylim = (0.0, 1.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHyqH84nbZgo"
      },
      "source": [
        "baseline = 0.1\n",
        "run = 1\n",
        "models = [model, model_2, model_3, model_4]\n",
        "\n",
        "\n",
        "for i in range(len(models)):\n",
        "  get_result(models[i], 0.1, run)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SCbTKejI_CL"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uqDmXQlwxxZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}